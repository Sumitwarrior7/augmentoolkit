

Post 65
ID: https://www.asyncapi.com/blog/release-notes-2.3.0?utm_source=rss
Title: AsyncAPI Spec 2.3.0 Release Notes
Link: https://www.asyncapi.com/blog/release-notes-2.3.0?utm_source=rss
Summary: AsyncAPI 2.3 is now released. This brings enhancements allowing new ways of structuring AsyncAPI documents and support for describing Solace APIs.
Content:
"""
The new version of the AsyncAPI specification - 2.3.0 - is now available.This is a minor release, and it doesn't bring any breaking changes. You can switch to it by modifying the following value in your AsyncAPI fileasyncapi: '2.2.0'intoasyncapi: '2.3.0'Servers and channels can now be defined as reusable componentsTo allow for more flexibility in how AsyncAPI documents are structured and enable content to be reused,serversandchannelscan now be defined as reusable components.For example:1asyncapi:2.3.02servers:3production:4$ref:'#/components/servers/myserver'5channels:6some/events:7$ref:'#/components/channels/myChannel'8components:9servers:10myserver:11url:"http://localhost:5000/ws"12protocol:ws13channels:14myChannel:15description:"mychannel"These are added to the many other aspects of the AsyncAPI specification which can be declared as reusable components. You can see the full list in theComponents Object section of the AsyncAPI specification.This new feature was contributed bySergio Moya. For more detail, see thispull requestand theGitHub issue where this change was discussed.New protocol bindingsThe specification is now extended to support another custom protocol through the bindings feature:Solace, thanks toMichael Davis.
For more details, check out thispull requestandbinding definition.Other enhancementsRegular expressions are now Unicode-compliant. This enhancement to the specification fromSergio Moyameans that regular expressions (found inpatternandpatternPropertiesfields) are now Unicode-compliant (according to ECMA-262).This improves compatibility with some JSON Schema parsers. For more details, check out thepull request.DeprecationsThe$reffield inChannel Item Objectis now deprecated from AsyncAPI 2.3.0.The current plan is that the$reffield will be removed fromChannel Item Objectin AsyncAPI 3.0, and replaced withReference Object.For more detail, you can see thediscussion about this issue in GitHub.Tooling supportThe following official AsyncAPI tools are already updated to support 2.3.0 version of the specification:JSON Schema that supports validation of AsyncAPI documents is updated inthisrepository. Also@asyncapi/specspackage has been updated on NPM to version 2.13.0, and it contains the 2.3.0 JSON Schema.JavaScript Parseruses latest@asyncapi/specspackage and can be used to parse and validate 2.3.0 documents. Upgrade to 1.14.0 version.HTML templateuses the latest@asyncapi/react-componentpackage. Upgrade to 0.24.7 version.JavaScript Converterenables conversion from any AsyncAPI version into the 2.3.0 version of the spec. Upgrade to 0.7.0 version.Modelinanow also accepts AsyncAPI documents valid against the 2.3.0 version of the spec. Upgrade to 1.46.0 version.Generatoruses the latest @asyncapi/parser package, so while generating output, it can validate 2.1.0 documents. Upgrade to 1.9.0 version.
Last but not least is the AsyncAPI Studio. Check new studio withthis example.Big thanks toMaciej UrbanczykandJonas Lagonifor updating most relevant tooling.Look aheadWe aim to have a regular cadence of releases of the AsyncAPI specification, four times a year. For more information about when to expect future releases, you can see ourrelease process document.We're also working on the next major release of the AsyncAPI specification: 3.0.0. If you'd like to contribute, or just follow the discussions, you can see themilestone on GitHub.Photo byAndrew RidleyonUnsplash
"""
--------------------------------------------------------------------------------


Post 66
ID: https://www.asyncapi.com/blog/asyncapi-and-apicurio-for-asynchronous-apis?utm_source=rss
Title: AsyncAPI and Apicurio for Asynchronous APIs
Link: https://www.asyncapi.com/blog/asyncapi-and-apicurio-for-asynchronous-apis?utm_source=rss
Summary: This post originally appeared on https://novatec-gmbh.de



The OpenAPI specification has already established itself in many project and application areas. It can be applied to describe HTTP APIs in a
Content:
"""
This post originally appeared onhttps://novatec-gmbh.deTheOpenAPIspecification has already established itself in many project and application areas. It can be applied to describe HTTP APIs in a standardized way, understandable for humans and computers. While OpenAPI is mainly intended for synchronous interfaces, asynchronous communication places new demands on the interface definition.Asynchronous architectures can build on different types of protocols, e.g., Kafka, AMQP, or MQTT. Additionally, communication often includes a messaging broker, which maintains several topics or channels. Another difference is the communication style: OpenAPI only allows specifying one-to-one connection links. In contrast to that, asynchronous communication often involves multiple communication partners. Therefore, common patterns like publish/subscribe require a new approach to defining APIs.AsyncAPIwas developed as an extension of OpenAPI to meet these new requirements of asynchronous communication and interfaces.This articlehighlights the differences between OpenAPI and AsyncAPI in more detail.As another aspect, large projects usually include multiple teams working and developing together. Therefore, standardized development of APIs is a central aspect of cross-team application development. At the same time, the API definitions need to be available and easy to access for all teams. These demands are also addressed byApicurio Registry. It supports registering different document formats, e.g., OpenAPI, AsyncAPI, GraphQL, Apache Avro, or Protobuf.Since AsyncAPI is developing quite fast, we want to have a look at what the specification and corresponding tools currently cover. Additionally, we will shortly examine how Apicurio and AsyncAPI can work together at the moment. Nevertheless, there are many new tools and features for AsyncAPI on the roadmap. For this reason, this article can only be a snapshot. So stay tuned until the end of this post to get an outlook on what is next to come.Elements of an AsyncAPI DocumentComing to the basics of AsyncAPI: How does an AsyncAPI definition look? AsyncAPI allows using YAML or JSON for document definition. A document consists of the following elements:In practice, the definition can become quite long. Consider the below example from AsyncAPI’s GitHub to get an impression of how such a definition can look:asyncapi: '2.2.0'
info:
title: Streetlights Kafka API
version: '1.0.0'
description: |
The Smartylighting Streetlights API allows you to remotely manage the city lights.
license:
name: Apache 2.0
url:https://www.apache.org/licenses/LICENSE-2.0servers:
test:
url: test.mykafkacluster.org:8092
protocol: kafka-secure
description: Test broker
security:saslScram: []defaultContentType: application/jsonchannels:
smartylighting.streetlights.1.0.event.{streetlightId}.lighting.measured:
description: The topic on which measured values may be produced and consumed.
parameters:
streetlightId:
$ref: '#/components/parameters/streetlightId'
publish:
summary: Inform about environmental lighting conditions of a particular streetlight.
operationId: receiveLightMeasurement
message:
$ref: '#/components/messages/lightMeasured'components:
messages:
lightMeasured:
name: lightMeasured
title: Light measured
summary: Inform about environmental lighting conditions of a particular streetlight.
contentType: application/json
payload:
$ref: "#/components/schemas/lightMeasuredPayload"schemas:
lightMeasuredPayload:
type: object
properties:
lumens:
type: integer
minimum: 0
description: Light intensity measured in lumens.
sentAt:
$ref: "#/components/schemas/sentAt"
sentAt:
type: string
format: date-time
description: Date and time when the message was sent.securitySchemes:
saslScram:
type: scramSha256
description: Provide your username and password for SASL/SCRAM authenticationparameters:
streetlightId:
description: The ID of the streetlight.
schema:
type: stringIf you want to look at it in a more readable way, you can copy and paste the definition to theAsyncAPI Studioor theAsyncAPI playground(Remark: AsyncAPI Playground will soon be archived and replaced by AsyncAPI Studio). More examples are available onGitHub.I do not want to dive too deep into the exact details of the specification because thedocumentationis already helpful enough for this. But I want to highlight some parts of the specification that could be the icing on the cake when considering it.Besides some general information about the API, like the title and the description, the "Info" object can contain a"Contact" object. Especially when thinking about multiple groups working together, the responsible team and how to reach them can be linked at this place. In the example from above, this would look like this:asyncapi: '2.2.0'
info:
title: Streetlights Kafka API
version: '1.0.0'
description: |
The Smartylighting Streetlights API allows you to remotely manage the city lights.
contact:
name: API Support
url:https://www.asyncapi.org/supportemail:support@asyncapi.orglicense:
...The fixed structure defined by the specification might not be sufficient for all use cases. Therefore, it is possible to link external documentation for nearly every object in the AsyncAPI definition. Additionally, user-defined properties can be set toextend the specification. This can be done by simply prepending an "x-" at the field name. For example, we could add the internal team or project name:...
contact:
name: API Support
url:https://www.asyncapi.org/supportemail:support@asyncapi.orgx-project-name: Future-Light-X10
x-team-name: Kafka Streetlights Team
...For long and detailed API definitions, the document can become messy fast. As an improvement for this, it is possible to include references to internal and external resources (using the $ref field). They enable us to reuse objects, add schemas and add definitions from external sources.As another use case, let’s assume there are already event-driven applications using an Avro schema for their messages. For example, the schema is registered at Confluent Schema Registry or Apicurio Registry. Using $ref, it is possible to reference this Avro schema within a message object in the AsyncAPI definition:...
messages:
lightMeasured:
name: lightMeasured
title: Light measured
summary: Inform about environmental lighting conditions of a particular streetlight.
contentType: avro/binary
schemaFormat: application/vnd.apache.avro+json;version=1.9.0
payload:
$ref: 'http://schema-registry:8081/subjects/topic/versions/1/#LightMeasuredPayload'
...AsyncAPI also offers anAvro schema parserwhich collects local Avro references or remote files from Confluent Schema Registry and inserts them into the definition.Kafka, AMQP, MQTT or HTTP: Protocol-Specific PropertiesAs already mentioned at the beginning of this post, asynchronous communication can involve different types of protocols. As this is a fundamental aspect of your API definitions, AsyncAPI supports adding protocol-specific properties.These protocol-specific properties can be necessary on different levels: server level, channel level, operation level, and message level. For these levels, AsyncAPI allows defining protocol-specific objects, so-called bindings. Thisrepositoryprovides a complete list of all bindings and their specification details.For example, it is possible to add a key for Kafka messages:...
channels:
smartylighting.streetlights.1.0.event.{streetlightId}.lighting.measured:
description: The topic on which measured values may be produced and consumed.
parameters:
streetlightId:
$ref: '#/components/parameters/streetlightId'
publish:
summary: Inform about environmental lighting conditions of a particular streetlight.
operationId: receiveLightMeasurement
message:
bindings:
kafka:
key:
type: string
enum: ['Germany', 'Austria', 'Switzerland']
bindingVersion: '0.1.0'
$ref: '#/components/messages/lightMeasured'
...Unfortunately, for many protocols, there are a lot of binding objects which are not specified yet. E.g., for Kafka, there are no specifications for the Server and Channel Binding objects. In the case of Kafka, relevant but missing properties could be the number of partitions or the delivery guarantee. These properties would be a good use case forspecification extensionsthatcurrently cannot be used in binding objects.In addition, someconventionsfor the specification of bindings are on the roadmap. As protocol-specific bindings are still in the alpha version, this feature will become mature with continuous development.AsyncAPI and Apicurio: A Match?In contrast to theConfluent Schema Registry, Apicurio is not limited tomessage schemas but also supports API specifications. Apicurio could therefore also replace the Confluent Schema Registry.However, this is probably only true if the architecture does not mainly base on a Confluent ecosystem. But depending on the use case, Apicurio can be a helpful addition to the Schema Registry due to the additionally supported formats.Apicurio Registry allows registering AsyncAPI definitions, which can then be searched and browsed. At the moment, unfortunately, AsyncAPI documents are not rendered to make them more readable. External references (like in the example above) are currently not resolved automatically either. Orientation for this could be theAsyncAPI playground, where this is already possible. However, Apicurio Studio already offers this functionality for OpenAPI, and support for AsyncAPI in Apicurio Studiois already planned.At the same time, Apicurio also offers theData Models Library, which allows reading, writing, and modifying AsyncAPI and OpenAPI documents. TheDereferencer-classresolves external references to other documents and inserts them into the definition. It is also possible to add your implementations of theIReferenceResolverinterface for custom resolution of references.When testing the library, I noticed that it cannot resolve all references in a document yet: The AsyncAPI specification also allows references in the payload object of a message (as shown in the example above). The library only checks objects for links that also implement theIReferenceNodeinterface. However, thepayload objectdoes not yet implement this interface, and therefore, references in this object remain unresolved.There already is aGitHub issuewhich will hopefully resolve this soon.For Avro schemas, Apicurio Registry supports schema validation and a compatibility check. However, this seems to be still missing for AsyncAPI, even when the user interface suggests the opposite (see screenshot below). I tested this feature with syntactically invalid AsyncAPI definitions (which were classified as invalid by AsyncAPI playground), which were not recognized as wrong by Apicurio Registry. Also, definition updates, including breaking changes, were not recognized as so. Nevertheless, thisGitHub issuesuggests that support is planned.The Data Models Library of Apicurio and Apicurio Registry gives a first idea of what can be done with AsyncAPI. Nevertheless, the functionalities and use cases are still limited. When I tested the Data Models Library, I hoped for more features that could be used at runtime. In fact, it is currently cumbersome to extract message schemas from the AsyncAPI definition. Therefore, I would not recommend the library for this use case.However, one possibility would be to use Confluent Schema Registry or Apicurio Registry for Avro schemas. Messages could be serialized and deserialized with the schemas from there. The AsyncAPI definition can then reference these schemas. In addition, Apicurio Registry can be used as an API catalog. Developers could then use this catalog to work on new services or to mock applications.Besides these aspects, you should consider that Apicurio has little to no competition. At least I could not find another established open-source registry on the market that supports both schemas and APIs and so many formats. Feel free to leave a comment if you know more about this!As an alternative, it is also possible to build your own AsyncAPI catalog to support missing features. E.g., you could use existing AsyncAPI libraries and modules like theAsyncAPI React componentto render definitions. If you want to know how this could look, have a look atthis repositorywhere I implemented this myself. In this prototype, I used the React component with Angular. In case you feel more comfortable with other frameworks, it is also possible to integrate it in Vue or NextJS.If you want to test how Apicurio works, check out this smallquick start guide. It starts an Apicurio container and deploys some AsyncAPI example files.The Roadmap: What is Next to ComeIf you take a closer look at theGitHub repositoriesof AsyncAPI, you will quickly notice that a lot is happening here right now. There are many exciting and promising ideas, and the community seems to grow steadily. For example, anevent gatewayis currently being developed that will make it possible to validate and modify messages even before they arrive at the broker. Another idea is theGlee framework, which ensures that AsyncAPI definition and code match. At first glance, an unexpected project is theAsyncAPI Chatbot. It helps to create an AsyncAPI document without having to know the specification yourself.Besides these innovative ideas, there are also tools to enable validation and compatibility checks. TheCLItool validates AsyncAPI files. Also, theDifftool points out breaking changes to ensure backward compatibility. A combination of these projects would be helpful, as it is already requested onGitHub. These two tools could also be integrated into Apicurio Registry to add missing features.The AsyncAPI website also lists toolsdeveloped by the community. Many of these and several tools by the core team mainly support JavaScript - so ideally, you should not have a problem with that. Nevertheless, it is to be hoped that other programming languages will be supported in the future. This would make it easier for the community to access them.Many other official projects of the AsyncAPI team are still in the alpha or beta phase. Therefore, most of them cannot yet be used to their full potential. But since companies like eBay and Slack already use AsyncAPI, we can expect a lot more to come.If you want to dive a bit deeper, I recommend having a look at the recording of the AsyncAPI conference in November 2021. There were many interesting talks on how AsyncAPI can be used in projects and with other tools. For more details on how to use schemas, schema registries, and API registries with AsyncAPI, listen to my conference talk below.
"""
--------------------------------------------------------------------------------


Post 67
ID: https://www.asyncapi.com/blog/july-december-2021-at-asyncapi?utm_source=rss
Title: 2nd half of 2021 at AsyncAPI
Link: https://www.asyncapi.com/blog/july-december-2021-at-asyncapi?utm_source=rss
Summary: It has been a while since the last update on the things at AsyncAPI Initiative. Lots of things have happened since June. You better have a read or listen to the podcast.
Content:
"""
Around August, I communicated that because vacation is a dead season (in Poland we call it cucumber time) I will not do my monthly updates or write a single vacation summary.Well, the thing is that vacations were not as quiet as I expected. In September, a carousel started that was impossible to stop.I started writing status updates bi-weekly in early 2020. These were about simple improvements in specific libraries, very detailed on libraries release level. Back then, I basically knew every single new thing happening in the initiative. This year I switched to monthly updates as there was simply too much happening, and I could not really do those bi-weekly. I also started picking the most important news as there were too many things happening.I submit my official apologies to those awaiting my update-related articles. Honestly, looking at the size of the community and the growth that we are noticing, I don't know how I'll manage to publish these regularly in 2022. Maybe we should start writing those as a collective.What I can promise for sure is that in January 2022, I will write a summary article about AsyncAPI growth in 2021.More regular live-streamsWe started two live streams under the AsyncAPI brand:Thinking Out Loudis hosted by AsyncAPI Founder (Fran Mendez). He invites different community members to talk about AsyncAPI specification. All recordings are availablein the official YouTube playlist. Fran plans to continue doing them in 2022 as well.Contributor-firstis strictly targeted at new or existing contributors. Any AsyncAPI Technical Steering Committee member can volunteer as a host and talk about specific contribution-related topics. We aim to have it as frequently as possible, at least once a week. All recordings are availablein the official YouTube playlist. Based on the community feedback, the live stream will be renamed toLet's talk about contributingin 2022.Hosting these live streams is all possible thanks to the great support from theRestream.iofolks who gave us free access to the tool that enables us to live stream directly to all our social media channels.All official meetings are always listed in our:Community repositoryofficial Google CalendarThe best way to learn about a new event is to joinour official Google Groupthat we use as a mailing list for invites.Solving publish/subscribe confusion aka possible AsyncAPI 3.0 release in 2022It was hard to find someone in the community that was not confused by the semantics related to thepublishandsubscribeoperations when learning about the AsyncAPI specification. Many people were asking in Slack. People were also opening pull requests to fix our documentation, assuming we mixed things up by accident.There are cases where education is not enough. You can have great docs and education materials. Still, some stuff just needs to be improved and cannot be fixed by documentation.At the beginning of my tech career, I learned a sentence from an experienced developer: "documented bugs become features". Sometimes you do not have a chance to learn from the best😅This is causing too much confusion and needs to be solved in 2022. It is probably not possible without a breaking change in the specification.Please join us and help us improve not only the specification but also update the tooling:Proposal to solve publish/subscribe confusionThe many meanings of an AsyncAPI fileGoogle Summer of Code SummaryWe closed holidays 2021 with massive success of theGoogle Summer of Codeparticipants. All participants not only finished their projects, but they also became members of AsyncAPI Technical Steering Committee and also got a chance to present their work at the 2021 AsyncAPI Conference.Aayush SahucreatedDiffKhuda Dad NomanicreatedOptimizerArjun GargcreatedCupidElegbede Azeez Wahab aka AcecreatedChatbotNektarios FifescreatedSimulator. He could not unfortunately join us at the AsyncAPI Conference to talk about his work, but I'm sure he will be open to answer any of your questions asked through GitHub Issues.It was a pleasure to work with these folks and see them staying with us after GSoC ends. I, thereforeproposed we do it again in 2022 on a larger scale.Technical Steering Committee members setupAfter joining theLinux Foundation (LF)and applying theopen governance model, it was time for us to start setting up a Technical Steering Committee (TSC).So here we are, 9 months after joining LF, we already have 24 members. Check out thecomplete list of all the TSC members. Pay attention to those that are marked asAvailable for hire. Don't let folks work for free. Pay them to work on open-source. Be good humans.Do you want to be on that list? Watch the following👇presentation.There are many things still missing, such as a TSC list synchronization, voting process automation, and more. Other things still need a lot of work. If you want to contribute to the project and you are a fan of automation, this is the right topic to help with.Welcome Studio and Goodbye PlaygroundWe released a new application that you can use to work on your AsyncAPI files.Before, you could use the AsyncAPI Playground, but now we are redirecting traffic to a new, beautiful👉AsyncAPI Studio👈The new Studio has a bright future, and you should expect lots of new features coming there. I definitely recommend checking outStudio's GitHub repository.The cool stuff is that it is also integrated with theAsyncAPI CLI:1#install CLI2npm install -g @asyncapi/cli3#create new file using an example4asyncapi new --file-name=asyncapi.yml --example=default-example.yaml --no-tty5#start studio that picks up asyncapi.yml file from the context it runs in6asyncapi start studioRepository withPlayground source codewill most probably be archived and moved toorganization with old archived projects.HackathonThis year, we hosted our firstAsyncAPI Hackathon. Even though we did not have a dedicated marketing campaign, and even though AsyncAPI is not trivial and requires experience to build tools for it, we received 9 submissions.Souvik Dewon first prize withAsyncAPI Bundler. Check out Souvik talking about the AsyncAPI Bundler at AsyncAPI Conference.We also had 2 folks that tied in 2nd place:AcesubmittedAsyncAPI BlocksGreg MeldrumsubmittedEvent Discovery AgentCongrats to all of you folks!Check outthis discussion to get more details on the Hackathon voting process.P.S. During the Hackathon, we also had a lot of people engaging with us because of Hacktoberfest. We got30 issues resolved and merged.ConferenceCOVID-19 is still here. Thus, we decided to host the 2021 AsyncAPI Conference this year only in online mode. It was a three-day event with lots of great content, and most importantly, with the 1st day dedicated to contributors only.The conference was live-streamed. Full-day recordings were released immediately, and individual talk recordings will follow. All will be listed under thededicated Conference playlist.Check out the current sum of people that watched it during the conference and after as recordings:Day 1:YouTube: 1119Twitch: 89 (during event only, later Twitch removes old videos)LinkedIn: 148Twitter: 692Total:2048Day 2:YouTube: 737Twitch: 56 (during event only, later Twitch removes old videos)LinkedIn: 49Twitter: 283Total:1125Day 3:YouTube: 521Twitch: 26 (during event only, later Twitch removes old videos)LinkedIn: 29Twitter: 312Total:888These numbers are great if we compare them against a total of 600 registrations!Personally, the best number that I discovered was when I started listing the names of all the people who helped during the hackathon and conference organization. I think 62 is now my favorite number❤️Picture showing names of all people that helped in event organization.What about 2022? People during the conference voted for a hybrid approach:Picture showing that out of 25 voters, 18 (72%) voted for a hybrid conference that is both online and in-person.Joinrelated discussion and help organize it.Photo byIan SchneideronUnsplash
"""
--------------------------------------------------------------------------------


Post 68
ID: https://www.asyncapi.com/blog/changes-coming-docs?utm_source=rss
Title: Change is coming to our AsyncAPI Developer Documentation
Link: https://www.asyncapi.com/blog/changes-coming-docs?utm_source=rss
Summary: Did you know that you can contribute Docs to AsyncAPI as well? Code isn't the only way to contribute to OSS; Dev Docs are a huge help that benefit the entire OSS ecosystem.
Content:
"""
🦄Hola, soy Quetzalli Writes¡Hola!😄AsyncAPI community, it's an absolute pleasure to meet you. My name is Quetzalli. I was born and raised in México🇲🇽, so my first language is Spanish.I’m a Senior Technical Writer👩🏻‍💻recently hired by Postman to focus solely on the Open-Source (OSS)AsyncAPI initiativeas primary owner for our AsyncAPI Dev Docs 📄 .I also recentlyjoined our initiative's Technical Steering Committee (TSC)! The TSC is responsible for the oversight of the AsyncAPI Initiative, helping make decisions on a higher level, or when maintainers cannot find a consensus.By the second day, I was already working on community Pull Requests (PRs) and getting to know more of our community members. This direct engagement with community feels amazing, because I reallydowant to help as much as I can. I'm excited to listen what our OSS community thinks needs to be documented first.Before I tell you more details about upcoming changes to the Docs and how you can contribute to them, I also want to share more granular details about my work here within our OSS community.👩🏻‍💻What I do for AsyncAPI DocsOwn the docs for the AsyncAPI feature set— documenting this specific area of our Open Technologies function and driving all docs efforts around it.Plan documentation in conjunction with OSS community feedback— working with open-source communities to learn about a feature from specifications and user research.Collaborate closely with Developer Relations to ensure docs, educational, and learning materials align with community needs:this includes assisting with documentation, tutorials, and all education efforts within AsyncAPI.Conduct editorial reviews on community doc drafts— providing constructive and kind feedback that helps colleagues to grow.Liaise with stakeholdersacross the AsyncAPI Initiative to establish and address docs needs.MaintainAsyncAPI Docs GitHub Discussions.💄AsyncAPI Docs are getting a makeover!Now that I've introduced myself, my role, and high-level goals, I wanted to tell you more about some of the cool stuff coming up for AsyncAPI Docs. Pretty big changes are coming to our Dev Docs; in fact, our first "big" item to tackle will be giving the Information Architecture (IA) a makeover!😭Why do we need to make so many changes?The current docs and repo READMEs were(are) made with much care and love, but with growth comes change, and with change comes improvements!In our case, we need to add...Conceptual docsthat explain our spec terminology in more detail that includeengineering diagrams: people often learn visually!Many more tutorials.(i.e. Websocket tutorial)CLI docsunder aReferencecontent bucket.Atools section! Currently we have documentation for our tools in individual tools' GitHub repos, under a/docsdirectory. Those should still remain there and continue to be maintained, but they also need to be documented in our Docs in a less informal way than what you see in aREADME.UsecasesandTroubleshooting Guides, under a newHow-Tosection.🪣Agnostic Content Buckets, coming right upEngineering Documentation can and should be divided intoagnosticcontent buckets.Currently, our documentation has the following content buckets:Getting StartedTutorialsSpecificationCommunityIn upcoming months, the plan is to change it to the following content buckets instead:ConceptsTutorialsReferenceHow-ToToolsWhy, you wonder?It was important (and exciting!) to me to introduce best practices from theDiátaxis Frameworkfor our new content buckets.Photo fromDiátaxisonDiátaxis frameworkThe Diátaxis engineering documentation system classifies content under 4 mainagnosticbuckets. This approach for Information Architecture (IA) and User Flows in dev docs is currently upheld widely within the tech industry.(i.e. One current live example is GatsbyJS, which also uses the Diátaxis system for their Dev Docs. If you want to see a longer list of companies using it, go overhere.)The Diátaxis 4-Part Classification System:concepts:Defining concepts within a technology's features and capabilities.how-to:Solve a problem or advanced use case by doing.tutorial:Learn a beginner process or concept by doing.reference:Learn how to set up your development environment, CLI, APIs, etc.💁🏻‍♀️How does the Diátaxis system apply to an actual technology?Let’s take a look at the following Mind Map.Here we see that the AsyncAPICLIandSpecfall under theReferencebucket. TheConceptsbucket details AsyncAPI's specification concepts and terms that deserve to be covered in more detail. But when it comes to understanding the difference between what fits under aTutorialvs. aHow-Tobucket, it feels harder to understand.Let’s make the subtle difference between the audiences forTutorialandHow-Tobuckets clearer.The Tutorial bucketThink of a Tutorial as something that you need to teach a user that is new to your technology.A first-time AsyncAPI user.A user who is new to APIsANDAsyncAPI.The How-To bucketThink of a How-To as the bucket to address problems and advanced scenarios that you already know your users will encounter. These problems tend to fall under unique usecases or advanced troubleshooting guides that a more active user would encounter.How to generate documentation from an AsyncAPI fileHow to generate a standalone static website with documentationHow to generate documentation in a component that you can embed in an existing websiteHow to generate markdownHow to generate PDFsHow to reuse schema definitions from an OpenAPI file with an AsyncAPI fileOrganising your AsyncAPI filesGenerating documentation from your AsyncAPI filesDescribing WebSocket APIs with AsyncAPI👉🏽How to contribute to AsyncAPI DocsDid you know that you can contribute Docs to AsyncAPI as well?Code isn't the only way to contribute to OSS; Dev Docs are ahugehelp that benefit the entire OSS ecosystem. At AsyncAPI, we value Doc contributions as much as every other type of contribution.❤️To get started as a Docs contributor:Familiarize yourself with ourproject's Contribution Guideand ourCode of Conduct.Head over to ourAsyncAPI Docs Board.Pick an issue you would like to contribute to and leave a comment introducing yourself. This is also the perfect place to leave any questions you may have on how to get started.If there is no work done in that Docs issue yet, feel free to open a PR and get started!Docs contributor questionsDo you have a documentation contributor question and you're wondering how to tag me into a GitHub discussion or PR? Never fear!Tag me in your AsyncAPI Doc PRs orGitHub Discussionsvia my GitHub handle,quetzalliwrites🐙.🙂Talk to meI want and need to listen👂🏽to all of your perspectives and ideas. Please don't be shy to express to me what you think needs to be documented first or what is missing.📝There's a lot of good work ahead, butyoudetermineour content roadmapbecause the OSS community needs should always come first.✨
"""
--------------------------------------------------------------------------------


Post 69
ID: https://www.asyncapi.com/blog/asyncapi-discovery-intro?utm_source=rss
Title: Align Production Reality and Event Documentation with the AsyncAPI Discovery Tool
Link: https://www.asyncapi.com/blog/asyncapi-discovery-intro?utm_source=rss
Summary: The idealized world of AsyncAPI is neat and tidy:

Interface definitions show developers exactly what events are exchanged amongst producers and consumers.
Event contracts only change when permitted b
Content:
"""
The idealized world of AsyncAPI is neat and tidy:Interface definitions show developers exactly what events are exchanged amongst producers and consumers.Event contracts only change when permitted by well-defined governance processes.Bindings fill in the implementation details for open-source brokers like Kafka (including Confluent) and RabbitMQ along with closed-source brokers like IBM MQ and Solace.The real world is often messier.This postAlign Production Reality and Event Documentation with the AsyncAPI Discovery Toolappeared first onSolace.In the decades-long absence of an asynchronous API spec, teams adopted (or didn’t adopt, or chose to ignore) different API definitions and governance. The result is a twisted mess of event producers, consumers, data paths, and multiple broker technologies, from on-premises to cloud connections.Oftentimes, removing an event topic or queue requires nerves of steel, for fear it might disrupt key functionality. Many a middleware engineer has found religion during a production broker clean-up.Thankfully, the AsyncAPI Discovery Tool offers a better way.How the AsyncAPI Discovery Tool WorksThe AsyncAPI Discovery Tool analyzes event traffic passing through brokers like Kafka, RabbitMQ, IBM MQ, Solace, and more. After learning how the broker distributes events, the AsyncAPI Discovery Tool generates a correspondingAsyncAPI specification. The generated spec can be used for code generation, documentation, visualization, infrastructure deployment, and more.It’s a great starting point for getting events catalogued and governed.It’s not perfect (more on that later), and there’s a lot more work to be done, but the AsyncAPI Discovery Tool helps your enterprise align production reality with AsyncAPI documentation. And perhaps relieve some tension for middleware engineers.Getting Started with AsyncAPI Discovery ToolGetting started means a trip to theSolaceLabs GitHub, where you can find detailed instructions and documentation. (While Solace created the AsyncAPI Discovery Tool, it’s open-source with an Apache 2.0 license.)The AsyncAPI Discovery Tool runs as a stand-alone Java Jar, so getting it running requires only Java and Maven. Once it’s up and running, AsyncAPI has its own self-contained UI, offering fill-in-the-blanks configuration. You can read more details about the UI (here).Here’s an example for Kafka:Just fill in the configuration, asking your friendly local administrator for help if needed, and then click the “Start Scan” button. After grinding away, the AsyncAPI Discovery Tool returns a consolidated spec file. The AsyncAPI file describes the channels and schemas of events passing through the broker. From there, the world is your oyster: generate code, create infrastructure, or start governing your events.The Future of the AsyncAPI Discovery ToolThe most obvious place to improve the AsyncAPI Discovery Tool is to expand the number of supported brokers. Right now, it supports:Apache KafkaSolace PubSub+NATSRabbitMQHiveMQFortunately, the tool was built with extensibility in mind. There is a documented plug-in architecture just itching to have more brokers added. If you’re interested, the people who maintain the tool welcome pull requests.The confusingpublishandsubscribeverbs in the output.The requirement that a single file must represent a single application makes it tough to get a high-level understanding of the architecture.As the spec matures, the tooling will hopefully be close behind.ConclusionIn the meantime, the AsyncAPI Discovery Tool can be a huge help to enterprises that are new to AsyncAPI but experienced with event-driven architecture and messaging. The AsyncAPI Discovery Tool can start you down the road from a tangled event mess to a well-organized, fully documented, tightly governed architecture.If you have more questions or want to share your experience with these standards, you can let us know in theAsyncAPI Slackor theSolace Community Forum.
"""
--------------------------------------------------------------------------------


Post 70
ID: https://www.asyncapi.com/blog/the-reference-rabbit-hole?utm_source=rss
Title: The Reference Rabbit Hole
Link: https://www.asyncapi.com/blog/the-reference-rabbit-hole?utm_source=rss
Summary: Sergio and I went down a bit of a rabbit hole the last couple of days while discussing Fran's proposal to solve the publish/subscribe confusion; I thought I would share the journey. 

A lot of this ca
Content:
"""
Sergioand I went down a bit of a rabbit hole the last couple of days while discussingFran's proposal to solve the publish/subscribe confusion; I thought I would share the journey.A lot of this can be seen as nitpicking... And I totally get this, as we need to venture deep into the specifications to fully understand the differences.I'm going to try to not use any complex words and explanations so that everyone can understand the problems, whether you're a novice or an experienced AsyncAPI user.So let's split up the understanding of what references are, where references can be used, and what's down this rabbit hole.AsyncAPI referencesIn AsyncAPI, we have something called aReference Object, which simply enables reusability in your AsyncAPI documents. This is possible through the simple keyword$ref. If we take a look at thestreetlight tutorial, to utilize reusability, we could changethe documentto:1asyncapi:'2.2.0'2...3channels:4light/measured:5publish:6summary:Informaboutenvironmentallightingconditionsforaparticularstreetlight.7operationId:onLightMeasured8message:9$ref:'#/components/messages/LightMeasured'10components:11messages:12LightMeasured:13name:LightMeasured14payload:15$ref:'#/components/schemas/LightMeasurement'16schemas:17LightMeasurement:18# Ignore the specifics here for now.Here you can see that we simply reference where the definition of messages and payload schema is located.Schema Object referencesAs seen in the streetlight example, to define your message payloads in AsyncAPI, we use aSchema Object, which is a superset ofJSON Schema draft 7.Whatsupersetmeans is we follow the JSON Schema draft 7 specification, but with a few modifications and additions to keywords.The messageLightMeasured, contains a keyword calledpayload, which is by default defined as aSchema Object.This is where the confusion starts, what behavior does the$refkeyword follow? More precisely, which specification?The confusion creeps inLet's take a closer look at theSchema Objectto see if we can figure out the answer.Further information about the properties can be found in JSON Schema Core and JSON Schema Validation. Unless stated otherwise, the property definitions follow the JSON Schema specification as referenced here.So what this means is that unless stated otherwise in theSchema Object, it should follow the official JSON Schema draft 7 specification. So let's try to read further, to see if anything is stated about references.Alternatively, any time a Schema Object can be used, aReference Objectcan be used in its place. This allows referencing definitions in place of defining them inline.Okay... So that must mean that if we ever encounter a reference, we follow theReference Objectdescription.Well, that was easy; I see no rabbit hole here, Jonas!?Welcome to the rabbit holeDuring the discussion, Sergio brought up that Fran was using an illegal reference, as he, in one of the examples, was using aReference Objectfor a server, which was not allowed.  More specifically, it was this example where he references themosquittoserver:1...2servers:3mosquitto:4$ref:'common.asyncapi.yaml#/components/servers/mosquitto'My immediate reaction was "wait... It's not?!"I had always used$refquite extensively in my AsyncAPI documents and specifically used a reference for servers. And I knew that the tooling had no problems with the$refas long as it was a valid reference.But Sergio was absolutely right; a second look at the specification showed thatserversare defined using theServers Object, which is defined by using a map ofServer Objects.NOTServer Object | Reference Objectas I expected.After that, we started to realize that there is quite a big difference between when and whereReference Objects are allowed. For the full list of discrepancies, check outspec #650.But... Why did I think it was allowed to do so?Discrepancies in AsyncAPI ToolingSo back to my own experience, why was I so sure that the tooling allowed for me to useReference Objects for servers?Well, as it turns out, it's because theJS parserdereferences before it validates the AsyncAPI document. This means that if I defined my AsyncAPI document as follows:1asyncapi:'2.2.0'2...3servers:4test-server:5$ref:'./servers/testServer.yaml'6...Together withtestServer.yaml:1url:ws://mycompany.com/ws2protocol:wsValidating the AsyncAPI document using a tool such asajvagainst theJSON Schema representation for 2.2.0, it would reject it.However, because the parser dereferences first, the document that is being validated is this:1asyncapi:'2.2.0'2...3servers:4test-server:5url:ws://mycompany.com/ws6protocol:ws7...Checkoutparser-js #405for more information.What about$idkeywordOne of the key differences between ourReference Object, and how$refis resolved in JSON Schema Draft 7, is the$id keyword. This allows you to define a URI that is used as a base URI. This means that for example a message such as this:1asyncapi:'2.2.0'2...3channels:4test/channel:5publish:6message:7schemaFormat:application/schema+json;version=draft-078payload:9$id:https://example.com/schemas/test10type:object11properties:12address:13$ref:"address"14...This will result in the reference for theaddressproperty, to be looked up athttps://example.com/schemas/address, because it uses the Base URI in$idfrom the parent schema (https://example.com/schemas).I tried a little test in thenew Studio tool(Studio uses the parser, so it could be used for an easy test),which showed that this was not supported by the parser. The library tries to resolve the reference athttps:///addresswhen it should have tried to resolve it fromhttp://example.com/schemas/address. Seeparser-js #403for more information.What about$schema?Before getting into$schemaI first need to mention a keyword in AsyncAPI calledschemaFormat which is part of the Message Object. What this keyword is used for is to change what format the payload is defined with. By defining it withapplication/vnd.aai.asyncapi+yaml;version=2.2.0it is the same as the default format.In JSON Schema Draft 7, and in theSchema Object, there exists a keyword, similar to whatschemaFormatis for AsyncAPI, that can be used to define what version of JSON SchemaLightMeasurementfollows.So what if both are defined at the same time, and they contradict each other?1asyncapi:'2.2.0'2...3components:4messages:5LightMeasured:6name:LightMeasured7schemaFormat:application/vnd.aai.asyncapi+yaml;version=2.2.08payload:9$ref:'#/components/schemas/LightMeasurement'10schemas:11LightMeasurement:12$schema:'http://json-schema.org/draft-04/schema#'13...With such contradicting information, how should tooling handle this? This sparkedspec #655.What about extra keywords?Following that, by taking a closer look at theJSON referencespecification theReference Objectfollows, we find thesentence:Any members other than "$ref" in a JSON Reference object SHALL be ignored.What this means, is that if we have a reference defined such as:1...2components:3messages:4LightMeasured:5payload:6type:boolean7$ref:'#/components/schemas/LightMeasurement'8schemas:9LightMeasurement:10type:stringThetypeproperty for the message payload, should be completely ignored. So let's try and see what happens when we try this inStudio.Once the schema is parsed, all that remains istype: boolean, and not the expectedtype: stringfrom the referenced schema. This is clearly the opposite of what the specification defines. For more information seeparser-js #404.We then asked ourselves, what about JSON Schema, does it define a different behavior? The answer to this question can be foundhere:All other properties in a "$ref" object MUST be ignored.Luckily, they both match the same behavior in terms of extra keywords. Both Reference Object and JSON Schema should ignore extra keywords.But, what if I use one of the newer JSON Schema versions, what then?Upgrading to JSON Schema draft 2020-12We started to correlate the findings with the feature request fromMaciejabout updating AsyncAPI Schema Object to point towardsJSON Schema Draft 2020-12.What would this mean for our little$refkeywords?OpenAPI have in its most recent version 3.1, switched its default JSON Schema version to Draft 2020-12, the exact feature request for AsyncAPI. This, however, introduced a huge change to how you bundle references. I don't want to spend much time on this asBenandMikedescribed this entire change and what it means in terms of bundling in this great blog postBundling simple external resources. Besides this, the release notes for Draft 2020-12 also offers some guidance which can be found here:https://json-schema.org/draft/2020-12/release-notes.htmlBesides having a bunch of new keywords that change the referencing behavior, such as$dynamicRef,$dynamicAnchor,$anchor, one of the key differences is that inJSON Schema draft 2019-09, they changed their behavior of references so that extra keywords are now allowed adjacent to$ref.But what does this mean exactly? Does this mean$refoverwrites any duplicated properties? Or is it the other way around?Well, there is one thing we need to remember about JSON Schema. It is primarily built for validation rules and how a validator can take input data and determine whether that input is valid against the Schema.This means, that if you have a JSON Schema using$refsuch as:{"$ref":"./test.json","minLength":7,"maxLength":12}andtest.jsonis defined as:{"minLength":5,"format":"email"}JSON Schema draft 2019-09, assumes that the references are resolved similar to:{"$ref": {"minLength":5,"format":"email"},"minLength":7,"maxLength":12}This is because in validation, you want to validate that the input data is valid against the referenced schema and shouldnotbe seen as a kind of merging behavior:{"format":"email","minLength":7,"maxLength":12}This behavior is different from what is assumed when using AsyncAPI, as the last option, is more aligned with expected behavior.Furthermore, now, each schema can define it's own$schemathat they follow, instead of ONLY being available at the root...This leaves the question, how can we make sure that we stay consistent and don't introduce more confusion into the AsyncAPI specification? This difference is what triggered the last issue inspec 649.Hard to find toolingThis leaves us with one huge deficit, that there are so many different behaviors for references that tooling mix and matches between the specifications and what they solve.One of the most used tooling for dereferencing stuff in JS, and the one we are using is fromAPIDevTools called json-schema-ref-parser. We actually use this tool to ensureANYencounters of$refare dereferenced, so the tool has direct access to the schema, without it having to look elsewhere for it.However, the tool started out being builtONLYfor dereferencing$refbased on theJSON Reference specification and the JSON Pointer specification.  At least it was, now it's not easy to figure out what it is for, asit allows extra propertiesbut$id is not taken into account.This leaves us in a bit of a struggle, asthere are not many alternatives; JS@hyperjump/json-schema-corelooks promising, but there's no tooling that ourGo parsercan use.And with no official or community tooling, we are left with having to develop it ourselves to adopt the spec... There are luckily efforts being made inJSON Schema to adopt to such a change.Final wordThat concludes the rabbit hole that Sergio and I went down, for a simple$refkeyword... (ONE KEYWORD!😅)If you have any comments or issues with what was described here, please go into the respective issues and make a comment - also if you think we are wrong!In case you are interested, we are also looking for contributors, to help us solve these issues. If you want to take one up, just write a comment in the respective issue.Overview of issues:spec #650, highlights the discrepancies when the Reference Object can be used.spec #649, tries to solve the core issue that$refmeans two different things, depending on when it's used.spec #655, what do you do when encountering$schemaand Message ObjectschemaFormat, especially when they are contradicting.parser-js #405, highlights that the parser accurately validates incorrect AsyncAPI documents, because it bundles references before validating.parser-js #404, highlights that the parser allows for keywords to be defined together with$refand are not being ignored.parser-js #403, highlights that the parser does not care about$idin the Schema Object when it should.Photo byNigel TadyanehondoonUnsplash
"""
--------------------------------------------------------------------------------


Post 71
ID: https://www.asyncapi.com/blog/socketio-part2?utm_source=rss
Title: The journey of documenting a Socket.IO API (Pt 2)
Link: https://www.asyncapi.com/blog/socketio-part2?utm_source=rss
Summary: This post originally appeared on https://dedouss.is



In the opening part of this series we outlined the basics of Socket.IO and discussed the importance of documenting Socket.IO APIs. Now it’s time
Content:
"""
This post originally appeared onhttps://dedouss.isInthe opening part of this serieswe outlined the basics ofSocket.IOand discussed the importance of documenting Socket.IO APIs. Now it’s time to bringAsyncAPIinto play.In this post we’re going to cover:A modelling exercise, in which Socket.IO semantics are mapped to AsyncAPI structuresA tutorial involving the creation of an AsyncAPI specification given an existing Socket.IO APIAsynction, a Socket.IO server framework driven by the AsyncAPI specificationModelling the Socket.IO protocol using AsyncAPIDon’t let the title of this section intimidate you. This modelling exercise ended up being relatively straightforward and I think it makes a great example of how AsyncAPI was designed to fit any event-driven protocol. If you are not interested in the thought process behind this exercise, you may jump straight to theSummaryparagraph of this section, which presents the solution.I will approach this problem by traversing the AsyncAPI object structure, attempting to map each of the objects to a semantic of the Socket.IO client API.The root object of the specification is theAsyncAPI Object. The fields of this object that require special attention arechannelsandservers.ChannelsTheChannels Objectis a map structure that relates a channel path (relative URI) to aChannel Item Object.1channels:2/:{}# Channel Item Object3/admin:{}# Channel Item ObjectChannels are addressable components where messages/events flow through. The specification suggests that a server may support multiple channel instances enabling an application to separate its concerns. This sounds very much like the definition of the Socket.IOnamespace. Namespaces are indeed addressable components that follow the relative URI convention. Since Socket.IO supports multiplexing, a client may emit messages to multiple namespaces over a single shared connection. However, it could also force a separate connection per namespace (using theforceNewoption). Thus, a Socket.IO namespace could either be a virtual or physical channel.Given that connections are established on the namespace level, theChannel Item Objectis the only object of the specification that MAY includebindings. For a Socket.IO API, theChannel Bindings Objectshould only contain thewsfield, in which one can specify the handshake context (HTTP headers and query params) that a client should provide when connecting to that particular channel/namespace.1channels:2/:3publish:{}# Operation object - Ignore this for now4subscribe:{}# Operation object - Ignore this for now5bindings:6ws:7query:8type:object9properties:10token:11type:string12required:[token]Since a single connection (and thus binding) is going to be used across multiple channels, there is no need to repeat the samebindingsobject under each channel/namespace. We can introduce the convention of always including bindings under the main (/) namespace but omitting them under the custom ones. At this point I would also like to propose the following bonus semantic: If a custom namespace includes bindings, then the client should alwaysforce a new connectionwhen connecting to it.You have probably noticed that I chose to stick to theWebSockets Channel Bindingas the only possible binding that a Socket.IO API may define. One could ask why not use anHTTP Channel Bindingobject alongside the WebSockets one, since the protocol could also be implemented via HTTP long-polling. There are 2 answers to this question:The current latest version of theAsyncAPI bindings specificationsdoes not allow HTTP bindings to be defined at the channel level.The HTTP long-polling implementation of Socket.IO is essentially a pseudo WebSocket. It is implemented in such a way to resemble the WebSocket implementation. The same HTTP headers and query params are sent to the server no matter the transport mechanism.Hence, it is safe to use the ws bindings even for the HTTP long-polling fallback. However, in an ideal world, we would have AsyncAPI supporting SocketIO bindings through an explicitsocketiofield. In fact, I have createda github issueto pitch this proposal.Along withbindings, theChannel Item Objectincludes thepublishandsubscribefields, in which one defines the operations that a namespace supports. ThepublishOperation Objectlists all the possible events that the client may emit (socket.emit), while thesubscribeoperation defines the events that the client may listen to (socket.on).A Socket.IO event can be expressed using theMessage Object, where thenamefield describes theeventNameand thepayloadfield describes the schema of theargsthat the client passes as part of thesocket.emitinvocation:socket.emit(eventName[, …args][, ack]). Forsubscribeevents,payloaddefines the structure of the arguments that the event handler callback expects:socket.on(eventName, (...args) => {}).The structure of the payload value depends on the number of arguments expected:ScenarioSender-side codePayload value structureAsyncAPI Message ObjectNo args expectedsocket.emit("hello")n/a — Payload field should be omittedname:helloSingle arg expectedsocket.emit("hello", {foo: “bar”})Anytypeother thantuplename:hellopayload:type:objectproperties:foo:type:stringMultiple args expectedsocket.emit("hello", {foo: “bar”}, 1)Tuple typename:hellopayload:type:arrayprefixItems:-type:objectproperties:foo:type:string-type:numberTo account for multiple events (Message Objects) per namespace, themessagefield of eachOperation Objectallows theoneOfarray structure. For example, in the message of the publish operation of the/adminnamespace, theoneOfarray lists all the availableeventNameandargspayload pairs that a client can pass to theadminNamespace.emitcall:1channels:2/admin:3publish:4message:5oneOf:6-$ref:"#/components/messages/MessageOne"7-$ref:"#/components/messages/MessageTwo"Now, let’s move on to the acknowledgement semantics of the protocol: The basic unit of information in the Socket.IO protocol is the packet. There are 7 distinctpacket types. The payloads of the publish and subscribe Message Objects described above correspond to theEVENTandBINARY_EVENTpacket types. These are essentially the packets that are transmitted when the Socket.IO sender invokes theemitAPI function of the Socket.IO library (regardless of implementation). In turn, the Socket.IO event receiver handles the received event using theonAPI function of the Socket.IO library. As part of theonhandler, the receiver may choose to return an acknowledgement of the received message. This acknowledgement is conveyed back to the sender via theACKandBINARY_ACKpacket types. The ack data is passed as input to the callback that the message sender has provided through theemitinvocation.Socket.IO ack sequence diagramIn order to express the above semantics, the Message Object (eventName and args payload pair) should be linked to an optional acknowledgement object. Since the specification in its current form does not support such a structure, I am proposing the followingSpecification Extension:Message Objects MAY include thex-ackfield. The value of this field SHOULD be aMessage Ack Object.Components ObjectMAY include thex-messageAcksfield. The value of this field should be of type:Map[string, Message Ack Object | Reference Object].Message Ack ObjectField NameTypeDescriptionargsSchema ObjectSchema of the arguments that are passed as input to the acknowledgement callback function. In the case of multiple arguments, use the array type to express the tuple.In the case of apublishmessage, thex-ackfield informs the client that it should expect an acknowledgement from the server, and that this acknowledgement should adhere to the agreed schema. Likewise, forsubscribemessages thex-ackfield encourages the client to send a structured acknowledgement, for each message it receives.ServersTheServers Objectis – surprise surprise – a map of Server Objects. EachServer Objectcontains aurlfield from which the client may infer the custom path to the Socket.IO server. This custom path should then be provided via thepathoption upon theinitialisation of the Socket.IO connection manager, alongside theurlarg. Theprotocolfield of theServer Objectis also required, and specifies the scheme part of thaturlarg. Its value should equal any of thews,wss,httporhttpsprotocols. For a Socket.IO client, it does not really matter whether the scheme is http or ws, due to the upgrade mechanism. Thus, for Socket.IO APIs, the only purpose of theprotocolfield is to indicate the use (or absence) of SSL.SummaryWe made it to the end of the modelling exercise the outcome of which is the following table, relating Socket.IO semantics to AsyncAPI structures.Socket.IOAsyncAPINamespaceChannel(described through theChannel Item Object)IO optionsWebSockets Channel BindingnamespaceSocket.emit(eventName[, …args][, ack])Operation Objectdefined under thepublishfield of aChannel Item Object. The availableeventName&argspairs for thisemitinvocation are listed under themessagefield, through theoneOfarray structure.namespaceSocket.on(eventName, callback)Operation Objectdefined under thesubscribefield of aChannel Item Object. The availableeventName&callbackargument pairs for thisoninvocation are listed under themessagefield, through theoneOfarray structure.EventMessage(described through theMessage Object)eventNameThenamefield of theMessage Object)EventargsThepayloadfield of theMessage ObjectackThex-ackfield of theMessage Object. Requires anextension of the specification. The field may be populated for bothpublishandsubscribemessages.Custom path (pathoption)Theurlfield of theServer ObjectUse of TLS (regardless of transport mechanism)Theprotocolfield of theServer ObjectIn practiceWith the modelling exercise out of the way, I’m now going to guide you through the process of creating an AsyncAPI spec from scratch given an existing Socket.IO API. For the purposes of this simple tutorial, let’s usethis minimal chat application, which is one of the get-started demos featured in the Socket.IO website.Below is the source of our Socket.IO server:1// Setup basic express server2constexpress =require("express");3constapp = express();4constpath =require("path");5constserver =require("http").createServer(app);6constio =require("socket.io")(server);7constport = process.env.PORT ||3000;89server.listen(port,() =>{10console.log("Server listening at port %d", port);11});1213// Chatroom14letnumUsers =0;1516io.on("connection",(socket) =>{17letaddedUser =false;1819// when the client emits 'new message', this listens and executes20socket.on("new message",(data) =>{21// we tell the client to execute 'new message'22socket.broadcast.emit("new message", {23username: socket.username,24message: data,25});26});2728// when the client emits 'add user', this listens and executes29socket.on("add user",(username, cb) =>{30if(addedUser) {31cb({error:"User is already added"});32return;33}3435// we store the username in the socket session for this client36socket.username = username;37++numUsers;38addedUser =true;39socket.emit("login", {40numUsers: numUsers,41});42// echo globally (all clients) that a person has connected43socket.broadcast.emit("user joined", {44username: socket.username,45numUsers: numUsers,46});47cb({error:null});48});4950// when the client emits 'typing', we broadcast it to others51socket.on("typing",() =>{52socket.broadcast.emit("typing", {53username: socket.username,54});55});5657// when the client emits 'stop typing', we broadcast it to others58socket.on("stop typing",() =>{59socket.broadcast.emit("stop typing", {60username: socket.username,61});62});6364// when the user disconnects.. perform this65socket.on("disconnect",() =>{66if(addedUser) {67--numUsers;6869// echo globally that this client has left70socket.broadcast.emit("user left", {71username: socket.username,72numUsers: numUsers,73});74}75});76});7778// Admin7980io.of("/admin").on("connection",(socket) =>{81lettoken = socket.handshake.query.token;82if(token !=="admin") socket.disconnect();8384socket.emit("server metric", {85name:"CPU_COUNT",86value:require("os").cpus().length,87});88});I’ve slightly tweaked the original source located athttps://github.com/socketio/socket.io/tree/master/examples/chatto include acknowledgments and bindings, so that I can showcase the full spectrum of the AsyncAPI specification.Let’s start by defining the version of the specification as well as the info object which provides metadata about the service:1asyncapi:2.2.023info:4title:Socket.IOchatservice5version:1.0.06description:|7This is one of the get-started demos listed in the socket.io website:https://socket.io/demos/chat/Moving on to the servers section, where one should provide connectivity information for all the instances of their service. In the case of our simple chat application, there is only one demo server accessible atsocketio-chat-h9jt.herokuapp.com:1servers:2demo:3url:socketio-chat-h9jt.herokuapp.com/socket.io4protocol:wssThings get a bit more interesting when it comes to channels. Skimming through the server code we find 2 namespace instances (default and /admin), which means that the channel mapping should consist of 2 entries:1channels:2/:{}3/admin:{}Within each namespace connection block, there are multiplesocket.on, andsocket.emitreferences. For each unique reference, we need to append a Message Object under the publish and subscribe operations respectively:1channels:2/:3publish:4message:5oneOf:6-$ref:"#/components/messages/NewMessage"7-$ref:"#/components/messages/Typing"8-$ref:"#/components/messages/StopTyping"9-$ref:"#/components/messages/AddUser"10subscribe:11message:12oneOf:13-$ref:"#/components/messages/NewMessageReceived"14-$ref:"#/components/messages/UserTyping"15-$ref:"#/components/messages/UserStopTyping"16-$ref:"#/components/messages/UserJoined"17-$ref:"#/components/messages/UserLeft"18-$ref:"#/components/messages/LogIn"19/admin:20subscribe:21message:# No need to use `oneOf` since there is only a single event22$ref:"#/components/messages/ServerMetric"From the server code, we can also see that the connection handler of the admin namespace applies some very sophisticated authorization based on thetokenquery parameter. The spec should hence document that the API requires the presence of a valid token query param upon the handshake:1channels:2/:3publish:4# ...5subscribe:6# ...7/admin:8subscribe:9# ...10bindings:11$ref:"#/components/channelBindings/AuthenticatedWsBindings"Putting everything together into a single document:1asyncapi:2.2.023info:4title:Socket.IOchatdemoservice5version:1.0.06description:|7This is one of the get-started demos presented in the socket.io website: https://socket.io/demos/chat/89servers:10demo:11url:socketio-chat-h9jt.herokuapp.com/socket.io12protocol:wss1314channels:15/:16publish:17message:18oneOf:19-$ref:"#/components/messages/NewMessage"20-$ref:"#/components/messages/Typing"21-$ref:"#/components/messages/StopTyping"22-$ref:"#/components/messages/AddUser"23subscribe:24message:25oneOf:26-$ref:"#/components/messages/NewMessageReceived"27-$ref:"#/components/messages/UserTyping"28-$ref:"#/components/messages/UserStopTyping"29-$ref:"#/components/messages/UserJoined"30-$ref:"#/components/messages/UserLeft"31-$ref:"#/components/messages/LogIn"32/admin:33subscribe:34message:# No need to use `oneOf` since there is only a single event35$ref:"#/components/messages/ServerMetric"36bindings:37$ref:"#/components/channelBindings/AuthenticatedWsBindings"3839components:40messages:41NewMessage:42name:newmessage43payload:44type:string45Typing:46name:typing47StopTyping:48name:stoptyping49AddUser:50name:adduser51payload:52type:string53x-ack:# Documents that this event is always acknowledged by the receiver54args:55type:object56properties:57error:58type:[string,"null"]59NewMessageReceived:60name:newmessage61payload:62type:object63properties:64username:65type:string66message:67type:string68UserTyping:69name:typing70payload:71type:object72properties:73username:74type:string75UserStopTyping:76name:stoptyping77payload:78type:object79properties:80username:81type:string82UserJoined:83name:userjoined84payload:85type:object86properties:87username:88type:string89numUsers:90type:integer91UserLeft:92name:userleft93payload:94type:object95properties:96username:97type:string98numUsers:99type:integer100LogIn:101name:login102payload:103type:object104properties:105numUsers:106type:integer107ServerMetric:108name:servermetric109payload:110type:object111properties:112name:113type:string114value:115type:number116117channelBindings:118AuthenticatedWsBindings:119ws:120query:121type:object122properties:123token:124type:string125required:[token]The modified server source code is pushed athttps://github.com/dedoussis/asyncapi-socket.io-example, along with the above AsyncAPI spec, which can be viewed using theAsyncAPI playground.Note that there is no point in documenting thereserved eventssince all Socket.IO APIs support these by default.AsynctionIn parallel to this exercise I have been developingAsynction, a Socket.IO python framework that is driven by the AsyncAPI specification. Asynction is built on top of Flask-Socket.IO and inspired by Connexion. It guarantees that your API will work in accordance with its documentation. In essence, Asynction is to AsyncAPI and Flask-SocketIO, what Connexion is to OpenAPI and Flask.Inthis example, I forked the minimal chat application that we documented above and re-implemented the server in python, using Asynction. Be mindful of thex-handlerandx-handlersextensions that have been introduced to relate AsyncAPI entities (such as message or channel objects) to python callables (event handlers).You may find extensive documentation of Asynction at:https://asynction.dedouss.isThe framework is still at a beta stage, so please get in touch before using it in a production setup.Any piece of feedback would be much appreciated.The endFor any questions, comments, or corrections, feel free to reach out to me atdimitrios@dedouss.is.A special shout out toderberq,quetzalliwrites, and the wider AsyncAPI community for being particularly helpful and responsive.🙇Photo byMatt HowardonUnsplash
"""
--------------------------------------------------------------------------------


Post 72
ID: https://www.asyncapi.com/blog/release-notes-2.2.0?utm_source=rss
Title: AsyncAPI Spec 2.2.0 Release Notes
Link: https://www.asyncapi.com/blog/release-notes-2.2.0?utm_source=rss
Summary: 2.2 release of AsyncAPI specification is here. The long-awaited feature for assigning channels to servers is finally here.
Content:
"""
I'm happy to share that AsyncAPI specification 2.2.0 is here. Check out all the goodies that it brings.This is a minor release, and it doesn't bring any breaking changes. You can switch to it by modifying the following value in your AsyncAPI fileasyncapi: '2.1.0'intoasyncapi: '2.2.0'Assigning channels to serversThis feature allows the definition of AsyncAPI documents for applications with more selective use of channels and servers. An example is message protocol adapters that consume messages from one server (say, Kafka) and publish those messages to another server (say, Anypoint MQ).Now you can add a newserversproperty toChannel Item Object. It must be a list of server names provided as a string.1description:ThisapplicationpublishesWebUICommandmessagestoanAMQPqueueonRabbitMQbrokersintheStagingandProductionenvironments.2servers:3-rabbitmqBrokerInProd4-rabbitmqBrokerInStaging5subscribe:6message:7$ref:"#/components/messages/WebUICommand"8bindings:9amqp:10is:queueNames of servers must match the names of the servers defined in theServers Object. This new property is optional, so moving from 2.1.0 to 2.2.0 is as easy as changing the specification version in your current AsyncAPI file. Ifserversis absent or empty, the given channel must be available on all servers defined in the Servers Object, like the previous version.For more details, check outthis pull request.We heard some community members asking for this feature. It wasGerald Loefflerthat decided to champion the proposal and lead it until it got released. Thank you🙏.New protocol bindingsThe specification is now extended to support the following custom protocols through the bindings feature:Anypoint MQ, thanks toGerald Loeffler. For more details check outthis pull requestandbinding definition.Become a contributorPushing things through into the specification is not an easy process. It requires a lot of time and patience, but it is worth it. Have a look at ourcontribution guideand start contributing.ConclusionsAre you wondering how we managed to release 2.2.0 just three months after 2.1.0? I recommend you familiarize yourself with theAsyncAPI release process. The next release is scheduled for January 2022. Later releases are in April, June and September, according to the agreedrelease cadence.Does the above meme give you mixed feelings? Are you afraid of possible changes, or actually happy to see it coming? Don't overthink it! Join ourSlackand talk to us, or check out the3.0.0 milestone.Photo byJeremy ThomasonUnsplash
"""
--------------------------------------------------------------------------------


Post 73
ID: https://www.asyncapi.com/blog/socketio-part1?utm_source=rss
Title: The journey of documenting a Socket.IO API (Pt 1)
Link: https://www.asyncapi.com/blog/socketio-part1?utm_source=rss
Summary: This post originally appeared on https://dedouss.is



My recent adventures with Socket.IO took me off on a tangent, exploring the world of AsyncAPI as a means of documenting Socket.IO APIs. This is t
Content:
"""
This post originally appeared onhttps://dedouss.isMy recent adventures withSocket.IOtook me off on a tangent, exploring the world ofAsyncAPIas a means of documenting Socket.IO APIs. This is the first part of a series of blog posts covering the modeling of the Socket.IO protocol using AsyncAPI objects, followed by a step-by-step tutorial on how to create a specification YAML file given an existing Socket.IO API.Setting the sceneEarlier this year my team undertook the task of re-implementing the backend of a realtime chat application-mentioningre-implementingandbackendin the very first sentence is probably a PTSD trigger for many of you, but thankfully this post has nothing to do with rewriting-from-scratch horror stories. The app was originally built using a 3rd party push-notifications platform which allowed us to deliver a functional MVP in a relatively speedy manner. However, as new requirements started creeping in from the business, it was clear to the team that this 3rd party dependency was not really worth it anymore. We thus had to take the (arguably not so easy) decision to implement our own realtime API to gain complete control of each server connection. The design meeting would soon follow, to answer questions like“What framework should we use?”or“Would serverless make sense?”. The stack of the team, namely Python,FlaskandKubernetes, pointed us in the direction ofFlask-SocketIO, making Socket.IO the protocol of choice. Although pragmatic, this stack driven design approach felt very unorthodox. The tooling dictated the choice of the client<->server communication protocol rather than the other way around. It was a decision primarily based on the stack and the expertise of the backend team. What if the Socket.IO client library for Swift is not maintained anymore? What if Socket.IO is a very verbose protocol, not friendly for clients with limited network connectivity? Thankfully, this is not the case and Socket.IO happens to be a well supported and carefully designed protocol. Nonetheless, the decision was made and the development of a Socket.IO API was about to commence.In the spirit of not repeating the sins of the past (i.e. not focusing on the client<->server interface), I started looking into how one can document a Socket.IO API. By document, I mean putting together some sort of spec or contract that can be agreed upon and shared with the consumers of the API. To my surprise, I couldn’t find a lot of resources on the topic. Coming from the REST world (whereOpenAPIis nowadays the de facto standard) and from theGraphQLworld (where everything is strictly typed), I found myself rather disappointed. It felt like the industry had been treating the documentation of event-driven APIs, such as Socket.IO or WebSocket ones, as a niche area not worth standardising. This felt odd, given how popular event-driven architectures had become over the past decade.After getting over the initial shock of this realisation, I finally managed to put together some properly worded google searches and came acrossAsyncAPI. Apparently, there is a growing community out there that serves this exact purpose of documenting event-driven APIs! Since 2017, the AsyncAPI folks have been developing a protocol agnostic specification for asynchronous APIs (inspired by OpenAPI), along with tooling such as spec parsers and code generators. Diving deeper into my google search, I looked for articles and tutorials on how one may express a Socket.IO API using the AsyncAPI specification. The only single resource I managed to find on the public cyberspace wasthis(not very comprehensive) StackOverflow answer. It was at this point when I realised that I was on my own, facing the problem of modelling the Socket.IO protocol using the AsyncAPI semantics. I decided to take on the challenge and if successful, write a blog post documenting my journey. So here we are.What is Socket.IO?Before jumping to the AsyncAPI part of the problem, let’s first try to establish some common understanding of what Socket.IO is.Many would argue that Socket.IO is a library rather than a protocol. In fact,its wikipedia entrydefines Socket.IO as a JavaScript library for realtime web applications. However, I regard this as an outdated definition. I see Socket.IO as a protocol of its own, with a JavaScript library being the reference implementation. It is a protocol enabling duplex, event-driven communication, treating the underlying WebSocket and fallback HTTP long-polling mechanisms as an infrastructure layer that the user should never be bothered with. The protocol is implemented in various languages (Java,Python,C++andRustto name a few) and has an official specification sourced athttps://github.com/socketio/socket.io-protocol.The caveat is that a user of Socket.IO (client or server) should never interact with the protocol directly, but instead use the Socket class API of the respective implementation library. The Socket class implements the following symmetrical interface:socket.on(eventName, callback):Registers a new handler (callback) for a given event.Implements a subscribing operation.The return value of the callback is sent to the sender party as an acknowledgement.socket.emit(eventName[, …args][, ack]):Emits an event to the receiver party.Implements a publishing operation.Theackcallback is invoked only if the receiver returns an acknowledgment.A more advanced concept of Socket.IO isNamespace, which enables multiplexing capabilities. A Namespace has its own event handlers (and potentially its own dedicated connection). Socket.IO uses the main Namespace (/) by default, but it is possible to set up multiple custom Namespaces.At this point one may wonder:This is all great, but why do we even need to document a Socket.IO API?TheeventNamegranularity allows Socket.IO to dispatch messages (args) based on event names. This means that a Socket.IO server could be supporting any amount of custom event names per namespace. Also note that the event payload (args) along with the ACK (callbackreturn value) can be of any type as long as it is serializable. Now imagine the very likely scenario of the Socket.IO client being developed from a completely separate team (or even company) to the one developing the server. How would the client know what namespaces and event names the server supports? And even if it was aware of the supported events, how would it know what data structures the server expects for each of those? Does the client need to acknowledge the messages it receives? If yes, what would be the structure of the acknowledgement payload? I wouldn’t want to live in a world where the answers to all of these questions would only be agreed verbally through some meeting. A piece of documentation should stand as the source of truth.Note that the scope of this documentation is limited to the interface between the client and the server, and does NOT cover the functionality of the server itself. Hence, we are not interested in server specific Socket.IO concepts such asroomsorbroadcasting events.What's nextStay tuned for the next (and most exciting) part of this series which adds AsyncAPI into the equation. In the meantime, you can check outAsynction, a python Socket.IO micro-framework driven by the AsyncAPI specification.Special thanks toderberqandquetzalliwritesfor reviewing this post!🙏Photo byMatt HowardonUnsplash
"""
--------------------------------------------------------------------------------


Post 74
ID: https://www.asyncapi.com/blog/hackathon-faq?utm_source=rss
Title: AsyncAPI Hackathon FAQ
Link: https://www.asyncapi.com/blog/hackathon-faq?utm_source=rss
Summary: Answers to all the questions you ever wanted to ask about the AsyncAPI Hackathon 2021
Content:
"""
Last year was the first time we hosted the AsyncAPI Conference. This year, we're going to host our first AsyncAPI Hackathon. This article tries to address the many questions coming from our community.😀When is the Hackathon?1st - 31st of October, 2021.We wanted you to have an entire month to complete your idea. This way, you don't have to stress and overwork yourself over the weekend. Instead, enjoy a relaxed month and remember it's about having fun!🤩What is the main theme for the Hackathon?The goal of the Hackathon is to provide MVP solutions that can help AsyncAPI Community in ways like:Ease education and getting started with the project.Bring new AsyncAPI-related solutions that can solve the existing challenges the community is facing with event-driven architectures.Extend existing tools, reuse them for some scenarios, and add the extra implementation on top.Do I need to register for the event?No, you do not need to register for the event.🙂Anybody can join the Hackathon, whenever they want! No pressure, in case you realize you can't deliver what you had originally planned.Is it a team competition or only for individuals?Both.You can work solo or form a team if you want! Just keep in mind that if you win with a team, the prize is divided amongst the entire team.I want to participate, but I don't have a good ideaNo worries, look at the ideas thatcommunity members are sharing in our public community discussion thread; you can pick one of them and/or get some inspiration.Can there be multiple submissions with the same idea?Yes.We do not set any limits here. The same idea can be done by multiple teams. Just keep in mind that if there are two excellent submissions for the same idea, I doubt judges will vote for both to let other ideas shine, although this is not an official rule.What is the scope of the submission? What does finishing my solution on time really mean?Your solution must be fully open-sourced and stored in a repository under your GitHub profile. Please do not use Bitbucket or GitLab as it will increase complexity for our community members that will review submissions.Your repository must havean open sourcelicense. If it helps, at AsyncAPI Initiative we always use Apache 2.0😉.It cannot integrate with a commercial solution that has no free tier.You must submit it before the deadline. Evaluation of the solution will not take into account any commits pushed to the repository after the deadline.How do I submit my task?Create a new discussion itemhere. Make sure there is:Overview of what the solution is about.Screenshots/Video/Diagrams/Code snippets (anyOf😉) that helps judges to quickly understand the solution and encourage them for further review.Link to the repository where the full solution can be found.If you win, you get to present your idea at our upcoming 2021AsyncAPI Conference in November.How will solutions be scored?A selected group that will represent the community will review all solutions. They will be obligated to only provide YES comments for ideas they liked the most and explain why. Each judge has 3 votes.Submissions and scores are public, and we reserve the right for judges to not make public NO comments, for the respect of all involved parties.The solution with the highest score wins!😀How do I get help? Who can help with further understanding of AsyncAPI and the entire tooling landscape?Join one ofContributor Firstmeetings. These will be streamed throughout the entire month of October, 2021. Add this calendar withGoogle Calendar formatoriCal format.  TheContributor Firstmeetings will take place every Wednesday, twice a day, at 8AM UTC and 4PM UTC.Join ourSlack. We are a very friendly and responsive community.Create an issue inone of the repositoriesand explain what help you need.What prizes are there?$5000 for the winner, $3000 for the runner-up, and $1000 for 3rd place.There will also be additional swag-packs for other participants.How do I get the winning prize money or swag?After the AsyncAPI Conference, you must submit an expense to Open Collectiveherewith an invoice that indicates the amount of money you have won.For swags, we will ask you directly to share your postal address with us that we will share with the agency responsible for swag-pack production.Who owns the intellectual property (IP)?AsyncAPI Initiative doesn't claim the IP of submitted solutions. Nevertheless, we welcome projects donations. Contact us if you want to continue working on your submission further after the Hackathon, and you want to do it under the GitHub organization owned by the AsyncAPI Initiative.Photo byEmily MorteronUnsplash
"""
--------------------------------------------------------------------------------


Post 75
ID: https://www.asyncapi.com/blog/openapi-vs-asyncapi-burning-questions?utm_source=rss
Title: AsyncAPI vs OpenAPI: Answers to Your Burning Questions About Two Leading API Specs
Link: https://www.asyncapi.com/blog/openapi-vs-asyncapi-burning-questions?utm_source=rss
Summary: AsyncAPI and OpenAPI are different ways of defining application programming interfaces (APIs), also commonly known as API specs. Both API specs serve a crucial role in defining and governing distribut
Content:
"""
AsyncAPI and OpenAPI are different ways of defining application programming interfaces (APIs), also commonly known as API specs. Both API specs serve a crucial role in defining and governing distributed computing systems, but AsyncAPI and OpenAPI are used for different styles of integration, as seen here:This postAsyncAPI vs OpenAPI: Answers to Your Burning Questions About the Two Most Popular API Specsappeared first onSolace.This post answers the following common questions about AsyncAPI vs OpenAPI and APIs in general…What are Application Programming Interfaces (APIs)?Application programming interfaces, or simply “APIs”, are a key part of modern programming that make it easier to exchange information between applications. APIs tell you what information an application expects to receive, and what information an application sends, without needing to know what the internal details of an application.As long as the API doesn’t change, different teams can invoke the application’s functionality without worrying about the messy details underneath. Because of this, separate teams can work independently on implementations.When did APIs start?APIs have been around for a while. For instance, the painful Simple Object Access Protocol (SOAP) used APIs in the early 2000s, but they really started getting interesting when representational state transfer (REST) came along. REST, which used the ubiquitous HTTP protocol, was lightweight and fun to work with.Did REST solve all the problems of SOAP by being lightweight, fun, and easy? Not quite, because it was a little too lightweight in some cases.What is Swagger and how does it relate to REST APIs?There was no great way to tell people in your company or a partner what needed to be in REST requests, and what they could expect as a reply. Whether the request needed a PUT or a POST was a constant source of confusion, and without a standard way of describing REST APIs, you had to resort to emailing.Something needed to happen. Swagger and WADL to the rescue! The goal of these competing standards was to standardize a way of documenting what a REST API looked like that was both readable by humans (somewhat, anyway) and could programmatically validate incoming requests and generate code.What happened to Swagger? And what is OpenAPI?The Swagger specification was renamed OpenAPI in 2016 when the Linux Foundation acquired it from the fine folks at SmartBear. Somewhat confusingly, Swagger lives on as a toolset for creating and manipulating OpenAPI specs.Implementing OpenTelemetry typically means instrumenting code so that it can emit monitoring information. This information is then aggregated in a backend system, either on-premises or through monitoring as a service provider.Are REST API and OpenAPI the same thing?They are related but different. OpenAPI describes and documents how a REST API operates in a standard way so that it can be shared widely.Why do Microservices Architecture and IoT benefit from  Asynchronous Communications?Microservices architecture is the new, cool kid on the street. Its purpose is to split up huge globs of code into tiny, manageable pieces, so different teams can work on them simultaneously.Typically, if a company wants to create something new, it glues different combinations of microservices together using REST calls. This method for microservices architecture worked… to an extent. People eventually realized that REST wasn’t always the best glue, and recognized the need for a new kind of glue that facilitated asynchronous communication.Establishing asynchronous communication between microservices makes them more reliable, faster, easier to scale, and more agile to adopt.Here’s a great video explaining why.The internet of things also changed things up. Mycoffee cupis connected to the Internet now. Which is fantastic. But internet connected gadgets like cars and stoves and refrigerators don’t always have solid internet connections. Again, asynchronous communication seemed like a better way to connect.With asynchronous communication, if a device is inaccessible, the information can be stored until it comes back online. Asynchronous communication can also help handle the surge of data than can come from connected devices. For example, think about all the coffee mugs firing up at 7am in the morning…Why do Microservices Architecture and IoT benefit from  Asynchronous Communications?You may be wondering why OpenAPI struggles with asynchronous APIs. Well, prior to version 3.1*, OpenAPI assumed two things:There is a single client connecting to a single server or application.The client requests something from the other server or application.*(OpenAPI 3.1 introduces some async capablities through the ability to define webhooks)As you can see here, that only covers about 25% of the ways that APIs can be implemented.Asynchronous communications do not satisfy those assumptions in numerous ways, but two stand out:Information is frequently shared with many consumers at the same time.In the case of one-way notifications, there may not be a request at all. With event-driven architecture, applications proactively send notifications about things that have occurred without being asked for that information.How does AsyncAPI describe asynchronous APIs?Without diving too deep, AsyncAPI adapts many of the core structures of OpenAPI to the asynchronous world. Rather than assuming that information flows in a request-reply style between a single client and server pair, messages are assigned to “channels” that many applications can send messages to, or receive messages from. If you want to learn more, check out theprimer on the AsyncAPI website.With the combination of OpenAPI and AsyncAPI, many more API possibilities are covered, as you can see in this diagram:Can an API gateway be asynchronous?There’s no reason it can’t be, which is one of the reasons many companies are focusing more on evented API products, along the lines of more traditional API products. Companies like Slack are already letting outsiders use evented APIs.If REST is all about HTTP, what protocols does AsyncAPI use?One of the cool things about AsyncAPI is that you can use a variety of different protocols that are defined by “bindings”. Right now, there are AsyncAPI bindings for over a dozen protocols including Apache Kafka, AMQP, IBM MQ, MQTT, SNS, WebSockets, and JMS.How can I create an Asynchronous API with AsyncAPI?If you want to see examples of how AsyncAPI can help you create an asynchronous API, there’s a great series withWebSockets examples, and you can check out thiscode generation example from Solace. If you’re looking for how to create an AsyncAPI API from scratch, the easiest way is with theAsyncAPI playground.What's next for API specs?AsyncAPI and OpenAPI are now both part of the Linux Foundation, which means:Both are well supported and have a stable futureBoth will be open standards with community governanceBoth should continue to be integrated with open-source tooling and commercial products
"""
--------------------------------------------------------------------------------


Post 76
ID: https://www.asyncapi.com/blog/events2021?utm_source=rss
Title: AsyncAPI Hackathon and Conference - Get Yourself Ready
Link: https://www.asyncapi.com/blog/events2021?utm_source=rss
Summary: It is official! October is an AsyncAPI Hacking Fest! and November 16-18 a 2nd online AsyncAPI Conference
Content:
"""
AsyncAPI Community organizes two important events in the second half of 2021:Hackathon in OctoberOnline conference on November 16-18We do not have the website ready yet.We do not have the call for proposals opened yet.Don't worry though, all logistics are in progress.What we do know so farWe do know these events will take place for sure!Hackathon will be month-long, and there will be a prize for winners. Its goal is to provideMVPsolutions that can help AsyncAPI Community in different ways:Ease education and getting started with the projectBring new AsyncAPI-related solutions to challenges the community has with event-driven architectures.Extend existing tools, reuse them in some scenarios, add the extra implementation on topConference will be 3 days long. The first day we will have a contributors summit where:Current maintainers can showcase projects that they maintain and explain how to contributeGoogle Summer of Code participants will be invited to showcase their projectsWe will explain in detail how to become a contributorDay 2 and 3 of the conference setup highly depends on the number of proposals, source (vendors, tooling providers, or end-users), and topics.What you can do alreadyJoin detaileddiscussionabout the event!Start talking to your employer.We need some cash from sponsorsto give it away to the community and spend some on event marketing.Start working on a proposal for a conference talk. The call for proposals is not yet officially opened, but you can already draft the initial proposal.Start brainstorming on your hackathon project as it's only one month left for the event:You want to be part of it? Feel free todiscuss your idea with othersif you are not sure it makes sense,You don't have time? That is fine, at leastdrop your ideas, maybe others will pick them upThat's all for now folks. Stay tuned!Photo bySamuel PereiraonUnsplash
"""
--------------------------------------------------------------------------------


Post 77
ID: https://www.asyncapi.com/blog/json-schema-beyond-validation?utm_source=rss
Title: Using JSON Schema Beyond Validation
Link: https://www.asyncapi.com/blog/json-schema-beyond-validation?utm_source=rss
Summary: What is JSON Schema, why is it important and why is it so hard to use beyond validation? 

For those unfamiliar with Asyncapi we use a superset of JSON Schema as the default format for defining operat
Content:
"""
What is JSON Schema, why is it important and why is it so hard to use beyond validation?For those unfamiliar with Asyncapiwe use a superset of JSON Schemaas the default format for defining operation payloads, headers, channel parameter schemas, etc.Even though formats such as Avro, OpenAPI 3.x and Swagger 2.x, RAML schemas, etc, are allowed in its place, as soon as it hits the parser (which most tooling utilizes), said formats are converted toJSON Schema draft 7to ensure acommon structure for tooling.However, in tooling, many times you do not want to validate data, but to represent the data in a structured manner so it is easier to interact with, such as classes that represent a message payload. How can you achieve this with validation rules?Quick intro to JSON SchemaLet's try and take a look at an example. Given the following, I have defined a schema representing the validation rules that the data should comply with.Displays the overall process of validating data using JSON Schema.The JSON Schema defines that the JSON data should be an object, which requires a property calledsomeRequiredPropertyto always be present and an optional property calledsomeOptionalProperty.someRequiredPropertyshould validate against an integer andsomeOptionalPropertyagainst an arbitrary string. The schema also dictates that no additional properties ("additionalProperties": false) may be allowed. There is also some metadata defined, called$idand$schema, but they are not important for this example.If we then take a look at the example data instances (below the JSON Schema in the figure), the first one contains the required property, and the second one has both the required and the optional property.The data and the JSON Schema can then together, validate whether the data is an instance of the schema, i.e., validate if the data comply with the validation rules and give a simple true or false statement if they are compatible.JSON Schema is an extremely powerful tool that allows you to create complex validation rules for data and is the standard specification used in not only AsyncAPI but also OpenAPI, however it has its challenges in tooling when used beyond validation.Challenges using JSON Schema for data definitionsMany of the JSON Schema keywords are forJSON instance validation, which means specifying validation rules that data should comply with. However, what if you wanted to know the definition of the data rather than what it should validate against?This is currently not something the JSON Schema specification provides to you, even though it is such an important part of tooling. First, let me show you how to interpret data definition from the above example for then to move into a more complex JSON Schema.Interpreting data definition from a JSON Schema is not always complex. For our previous example, I can almost interpret it as is. If I wanted a class in TypeScript that represented the data, it could look something like this (gonna use TS syntax as examples throughout). Notice how the$idkeyword is used to define the naming of the class.1classSomeIdForSchema{2publicsomeRequiredProperty: number;3publicsomeOptionalProperty?:string;4}In theory, I use the very same validation rules and interpret them, such that the output gives us the definition of what form the data may take. Sounds easy enough right?😅The problem is that JSON Schema –which might seem simple on the surface— is complex underneath when you start to interpret the recursive keywords such asnot,if,then,else,allOf,oneOf, etc. This causes the possibilities to be endless in terms of how the JSON Schema document can be structured (at least endless in principle).Ideally, all keyword possibilities MUST be supported with no restrictions. So let's take a look at a more complex example, that introduces thenotkeyword. We aren't interested in why one would define something like this, but merely the possibility of doing so.1{2"$schema":"http://json-schema.org/draft-07/schema#",3"type":"object",4"$id":"SomeIdForSchema",5"additionalProperties":false,6"properties": {7"someOptionalProperty": {8"type": ["string","number"]9}10},11"not": {12"properties": {13"someOptionalProperty": {14"type":"number"15}16}17}18}Take a moment and think about what data would you say is valid against this schema?In the very simplest form the JSON Schema could be converted to the following:1{2"$schema":"http://json-schema.org/draft-07/schema#",3"type":"object",4"$id":"SomeIdForSchema",5"additionalProperties":false,6"properties": {7"someOptionalProperty": {8"type":"string"9}10}11}Where the propertysomeOptionalPropertymay only be of typestring. But, let's try and break the complex schema down step by step, to show how the validation would work against the data:1{2"someOptionalProperty":"string"3}Notice how thenotkeyword reverses the validation result of step 5, which is why the inner schema is validated before the keyword itself.1{2"$schema":"http://json-schema.org/draft-07/schema#",3"type":"object",//Step 14"$id":"SomeIdForSchema",5"additionalProperties":false,//Step 26"properties": {7"someOptionalProperty": {//Step 38"type": ["string","number"]//Step 49}10},11"not": {//Step 612"properties": {13"someOptionalProperty": {14"type":"number"//Step 515}16}17}18}Step: accept, as the input is of type object.Step: accept, as no additional properties have been defined.Step: accept, as the property exists.Step: accept, as the property is of type string.Step: reject, as the property is of type string and not number.Step: accept (negate step 5), as the validation of the inner schema is negated.With thenotkeyword it means that it is not only a matter of interpreting what form the data may take but also which it may not. If we had to represent a class for this Schema it would be the following:1classSomeIdForSchema{2publicsomeOptionalProperty?:string;3}The interpretation of JSON SchemaSo, how can we create an algorithm that will enable us to consistently and accurately represent the underlying data model for the JSON data? How can this be standardized across all versions of JSON Schema (as we might not stay on Draft 7 forever)?Some of the alternatives to JSON Schema is specification such asTypeSchemaorJTD, that instead of focusing on validation, you focus on the definition of data models. Using these as the standard definition for payloads would indeed solve the problem in terms of data definitions in tooling. However, doing so neglect many important features of JSON Schema that simply cannot be done by defining the models, and we are left with the very same problem of transformingJSON Schema -> TypeSchemaorJSON Schema -> JTD, which to some extent is the process we are trying to figure out.In terms of the algorithm, it is highly work in progress😃ForModelinawe have our own process, but... It is something we are trying to solve collectively (as AsyncAPI is not the only one with this problem,OAI, IBM, etc) in the JSON Schema organization.Therefore I started adiscussionto trigger some initial thoughts on the subject and aJSON Schema SIGhas been formed to tackle this problem.This blog post is as much a call for help as it is to enlighten you about the problem of using JSON Schema beyond validation. If you want to help tackle this problem, test the process, review changes, or make some kick-ass documentation, just reach out, cause we want your help!Photo byHalGatewood.comonUnsplash
"""
--------------------------------------------------------------------------------


Post 78
ID: https://www.asyncapi.com/blog/mistake-odyssey?utm_source=rss
Title: Mistake Odyssey
Link: https://www.asyncapi.com/blog/mistake-odyssey?utm_source=rss
Summary: Experience with Git, GitHub, VS Code and Markdown for non-developers within AsyncAPI.
Content:
"""
The human being for many centuries delegated the responsibility of preserving a great part of their culture, of the most precious information, in the capacity of keeping in their memory the data, the names, the places, the details...In the Ancient Greece, Homer was the first to leave written traces of what until then were only remembered words, poems heard and recited from generation to generation. All this with the invaluable help of the muses. What a relief! He must have thought. What enormous risk and stress must have been in the atmosphere of those times. What would happen if amnesia came, the sudden loss of information. To forget is human. To err is human.The age of errorUndoubtedly, in our time, a recurring nightmare that we have all had is the one in which, after having done a work on our computer, just when we have to present it, a failure in the system makes everything written in the last minutes disappear... sometimes hours. Re-writing a previously written text is a hard exercise of memory, between frustration and despair. It will never be the same. Muses hardly come to the rescue. We are not Homer.Such suffering could be avoided in an ideal, utopian world where we would all keep backup copies of our documents every second. But the reality is that neither the obsession with saving versions in the cloud or on external disks is infallible. The danger of losing a moment of inspiration is part of all of us. Some say that we live in the age of error. Some of them made by us, others by the machines.For a writer or content creator, this nightmare can be especially hurtful, since the ability to write good texts and communicate information does not imply being an expert in computers or in the operation of the software that serves as a platform on which to shape texts.Getting out the comfort zoneWhen we are trained, we learn tools for our profession that we tend to hold on to tightly. Our first jobs are usually done with those initial tools and little by little we discover new ones that open up a world of infinite possibilities. Of course, it is not always easy to let go of the everyday to tackle new challenges with different methods. Homer first learned to recite by heart... at some point he would learn to write... and to read verses.Sometimes opportunities appear when you least expect them. Thus AsyncAPI appeared in my life and the opportunity to contribute to this project arose. Initially it was an exciting and challenging idea in a totally unknown sector for me, coming from the world of communication. I began to familiarize myself with the concepts and objectives covered by the project and little by little I started to get into it until I came across new tools and working methods that were new to me. Outside my comfort zone, an incomprehensible world was opening up before me. Are there maps for the desert? Who brought me here? Why learn something new if I have already internalized the mechanisms of my previous work?Learning from mistakesAsyncAPI is an open, free and collaborative project so the community needs to work with tools that allow working from transparency and horizontality creating an agile system. We are talking about Git, GitHub and VS Code, three free and open source software tools.When it comes to writing, the project relies on plain text, specifically the use of Markdown. It is considered a language that has the purpose of allowing the creation of content in a simple way of writing, and that at all times maintains a readable design. VS Code is the text editor in which we will work with Markdown. And then Git and GitHub conform the system that allows to store the information and easily retrieve it in case of loss, failure or error, as well as to consult the changes and revert them at any time.Evidently my immersion in these programs was for weeks an odyssey through the vast ocean of ignorance, or what is the same, an odyssey through the purest science of trial and error in which, apparently, there were only errors. Empirical learning is hard.Fortunately AsyncAPI has a community that works as a great team, in it I found people who help me to dispel my doubts and solve my mistakes. I take this opportunity to thank you from these lines, especially@anbreakerfor your patience😅.The end of a nightmareMultidisciplinarity is increasingly on the rise. It has been amply demonstrated that the convergence of different disciplines in the same project achieves a more successful and impactful result. This peculiarity makes us get closer and closer to disciplines that work with different tools than the ones we are used to.Beyond the mistrust or distrust derived from leaving our comfort zones, all this can be approached as an opportunity for learning. Ultimately, we discover new tools that make our work easier and more productive. A treasure hunt. An unexpected return to Ithaca. The odyssey comes to an end.The stress generated by the loss of information when writing is over for me. There is no concept of "unrecoverable text" in my new work environment thanks to the copies made by Git. There is a map where there are traces of everything that was done before. The nightmare has come to an end. We Homer wannabes can finally rest peacefully... waiting for the muses to arrive in our dreams.Photo byCarolinie CavallionUnsplash
"""
--------------------------------------------------------------------------------


Post 79
ID: https://www.asyncapi.com/blog/june-2021-at-asyncapi?utm_source=rss
Title: June 2021 at AsyncAPI
Link: https://www.asyncapi.com/blog/june-2021-at-asyncapi?utm_source=rss
Summary: 2.1.0 spec released, GSoC started, CLI released, other tools under heavy development. June was a hell of a ride.
Content:
"""
ReadMay 2021 at AsyncAPIfor the update from May.Specification 2.1.0 releaseThe eagle has landed. The new version of the AsyncAPI specification is here. For more details, readAsyncAPI Spec 2.1.0 Release Notes.For more details on security improvements introduced into the spec byDale Lane, readthis interactive article.For more details on new properties in examples, check out the demo of the latest version of Microcks whereLaurent Broudouxshows them in action in the new release:A significant side effect of the release is that we automated the process of publishing the specification. NowAsyncAPI Websitealways reflects the latest version of specification document fromthe spec repository. Thank youAayush Kumar Sahufor the hard work.The next release is scheduled for September. It is not decided if it is going to be a major or minor. It depends on the changes in the spec. Patch releases will be automatically released as 2.1.1 etc.Google Summer of Code (GSoC) kicked offBy courtesy ofPostmanthat agreed to list AsyncAPI-related ideas on their list ofGSoCideas, the AsyncAPI Initiative entered the event a big time.In June, we started at GSoC with five different project!DiffAayush Kumar Sahustarted working onthe AsyncAPI Diff library. It will show differences between two different AsyncAPI files as a list of breaking and non-breaking changes.Later it will be used in AsyncAPI CLI and Studio. It will be a standalone library, browser compatible, so the community can also integrate it in other use cases.OptimizerKhuda Dad Nomanistarted working onthe AsyncAPI Optimizer library. It is meant to optimize your AsyncAPI documents, such as finding duplications that can be changed into references or removing unused components. Very useful, especially for use cases where the AsyncAPI document is generated from code.Later it will be used in AsyncAPI CLI and Studio. It will be a standalone library, browser compatible, so the community can also integrate it in other use cases.App Relations DiscoveryArjun Gargstarted working onthe AsyncAPI App Relations Discovery library. It can discover relations between different applications in the system. As input, you provide a set of AsyncAPI documents provided for multiple applications.Except of default map of relations you will be able to also get a diagram of relations. Some ready examples based onthis flight system use case:Figure 1: Flow diagram using Mermaid syntax.Figure 2: Class diagram using PlantUML syntax.Simulator aka Fluffy RobotNektarios Fifesstarted working onthe AsyncAPI Simulator. It is a library that can simulate real traffic against your system basing on provided AsyncAPI documents and initial information of the traffic that should be generated. As a result, you will get a set of statistics.ChatBotAcestarted research on implementing aChatBotthat could help new AsyncAPI users to create first AsyncAPI documents. Throughout a conversation with a bot, you would get a generated AsyncAPI document in return.New CLI releasedThe initial version of theAsyncAPI CLIis finally here🚀.Jorge Aguiar Martínfinished his hard work on initial setup of the CLI with first initial feature for AsyncAPI documents validation:The next features are on their way. Feel free to join and work on it together with us.Modelina supports GoOur model generation library is under heavy development. I want to explicitly mention one change among all the recent changes inModelina.Sergio Moyaenabled support for model generation for Go💪It is a 4th language that is supported by the library.1const { GoGenerator} = require("@asyncapi/modelina")23const generator = new GoGenerator();45const doc = {6$id:"Address",7type:"object",8properties: {9street_name:    { type:"string"},10city:           { type:"string", description:"City description"},11house_number:   { type:"number"},12marriage:       { type:"boolean", description:"Status if marriage live in given house"},13pet_names:      { type:"array", items: { type:"string"} },14state:          { type:"string", enum: ["Texas","Alabama","California","other"] },15},16required: ["street_name","city","state","house_number","state"],17};1819async function generate() {20const models = await generator.generate(doc);21models.forEach(function (model) {22console.log(model.result);23});24}2526generate();2728//outputs2930/*31// Address represents a Address model.32type Address struct {33StreetName string34City string35HouseNumber float6436Marriage bool37PetNames []string38State *State39}40// State represents an enum of string.41type State string42*/You can also try out this code onRunKit.React component vs HTML template and where are weReact componentis still under development towards 1.0.0 release. Keep in mind that we are already using release candidates in theHTML template, and you can give it a try too:npminstall--save@asyncapi/react-component@v1.0.0-next.11In June, a couple of release candidates were released. Most important to notice is a new standalone bundle that makes it super easy to reuse React component inAngularandVueprojects. In addition, we now provide not onlycjsbut alsoesmandumdmodules. As a result, it is much easier to use React component withNext.jsprojects. In addition, the component supports the whole specification, exceptdiscriminator.Few more items left for the official 1.0.0 release:Custom theming that isright behind the cornerComponents extensibilityNew playground aka editor that will be available as a standalone package and used by use in a new AsyncAPI Studio (new AsyncAPI Playground)If you are interested in more details, follow therelease milestoneand the work done byMaciej Urbanczyk.JobsIf you missed it, we have aJobsboard on our website where different companies can share opportunities involving working with AsyncAPI. There are 4 open positions at the moment.We also generate anRSS feed, so you can subscribe for notifications on new jobs only.Good learning materialsJune was super rich in good learning content. Below you can find a list of all the articles and videos, but I'd like to explicitly point you to thiskids book about Kafka:Designing your APIs with AsyncAPI (Part 1)Simulating CloudEvents with AsyncAPI and MicrocksAsyncAPI and Its Horizontal Working SystemThe journey of documenting a Socket.IO API (Pt 1)Photo byRahul PanditonUnsplash
"""
--------------------------------------------------------------------------------


Post 80
ID: https://www.asyncapi.com/blog/release-notes-2.1.0?utm_source=rss
Title: AsyncAPI Spec 2.1.0 Release Notes
Link: https://www.asyncapi.com/blog/release-notes-2.1.0?utm_source=rss
Summary: The eagle has landed! Check out all the changes the AsyncAPI specification introduces in the new v2.1.0 release
Content:
"""
The last AsyncAPI release (2.0.0) took place on the 11th of September, 2019. In 2020 the focus went into growing community and adoption and stabilization of basic tooling for specification. This year was a year of "formalizm"😃aka getting into the foundation, setting up governance model and contribution guide to enable work on next spec release. We are good to go forward. The 2.1.0 release is out in the wild🎉Message examples object extended with additional fieldsThanks to work done byLaurent Broudoux, you can now clearly describe message examples. New propertiesnameandsummaryare optional. These properties help not only to properly describe the example in documentation but make it easier to work with mocking and testing tools (likemicrocks), so you can better identify what example to use for mocking and what it does.Example of new properties added to existingWebSocket example for Gemini API:1components:2messages:3marketData:4summary:Messagewithmarkeddatainformation.5description:|6The initial response message will show the existing state of the order book. Subsequent messages will show all executed trades, as well as all other changes to the order book from orders placed or canceled.7payload:8$ref:'#/components/schemas/market'9examples:10-name:updateMessage11summary:Exampleofanupdatemessagethatcontainsachangeinpriceinformation.12payload:13type:update14eventId:3690223336215timestamp:161976967316timestampms:161976967352717socket_sequence:66118events:19-type:change20side:bid21price:'54350.40'22remaining:'0.002'23delta:'0.002'24reason:place25-name:heartbeatMessage26summary:Exampleofadditionalheartbeatmessagewhenyouenablethem.27payload:28type:heartbeat29socket_sequence:1656Rendering of new example properties in React component and HTML template:For more details, check outthis pull request.New protocol bindingsThe specification is now extended to support the following custom protocols through the bindings feature:Mercure, thanks toKévin Dunglas. At the moment, no specific bindings are necessary for this protocol. For more details, check outthis pull requestandbinding definition.IBM MQ, thanks toDale LaneandRichard Coppen. For more details check outthis pull requestandbinding definition.Custom schema formats mandatory vs recommendedSupport for Avro and OpenAPI schemas changed from mandatory to recommended through contribution fromFran Mendez. For more details, check outthis pull requestNew security schemesThanks toDale Lane, you can now describe secured Kafka clusters with SASL security schemes (scramSha256,scramSha512,gssapi). For more details, check outthis pull request.Old new defaultContentType property in root objectWe used and supporteddefaultContentTypeproperty to specify the default content type when encoding/decoding a message's payload.Lucas Blockspotted that we do not have it defined in the specification. For more details, check outthis pull request.Tooling supportThe following official AsyncAPI tools are already updated to support 2.1.0 version of the specification:JSON Schema that supports validation of AsyncAPI documents is updated inthisrepository. Also@asyncapi/specspackage has been updated on NPM to version 2.8.0, and it contains the 2.1.0 JSON Schema.JavaScript Parseruses latest@asyncapi/specspackage and can be used to parse and validate 2.1.0 documents. Upgrade to 1.7.0 version.AsyncAPI Generatoruses the latest@asyncapi/parserpackage, so while generating output, it can validate 2.1.0 documents. Upgrade to 1.8.0 versionGenerator filtersfunctionsgetPayloadExamplesandgetHeadersExamplessupport new message example properties. Upgrade to 2.0.0 version.React componentsupports rendering of new message example properties. Upgrade to v1.0.0-next.10 version.Markdown templatesupports rendering of new message example properties. Upgrade to 0.14.0 version.HTML templateuses the latest@asyncapi/react-componentpackage. Upgrade to 0.23.0 version.JavaScript Converterenables conversion from any AsyncAPI version into the 2.1.0 version of the spec. Upgrade to 0.5.0 version.Modelinanow also accepts AsyncAPI documents valid against the 2.1.0 version of the spec. Upgrade to 0.16.0 version.Last but not least is the AsyncAPI Playground. Check new playground that uses latest HTML template and Markdown template withthis example.Big thanks toMaciej UrbanczykandJonas Lagonifor updating most relevant tooling.This is not all! Not only official AsyncAPI tools are updated. Thanks toLaurent BroudouxalsoMicrocksnow supports version 2.1.0 and its new example's properties. Upgrade to 1.3.0 version.Thank youI want to send a special thank you toAayush Kumar Sahu, who helped us to automate the part of the release responsible for updating the specification Markdown document on the AsyncAPI website, right after triggering the release, even the release candidate. Thank you🙇.Photo byDoug SwinsononUnsplash
"""
--------------------------------------------------------------------------------


Post 81
ID: https://www.asyncapi.com/blog/may-2021-at-asyncapi?utm_source=rss
Title: May 2021 at AsyncAPI
Link: https://www.asyncapi.com/blog/may-2021-at-asyncapi?utm_source=rss
Summary: We have JSON Schemas for bindings and some great community tools, one that was donated to AsyncAPI Initiative
Content:
"""
ReadApril 2021 at AsyncAPIfor the update from April.JSON Schemas for the bindingsAsyncAPI is protocol agnostic. It doesn't mean that you cannot specify some protocol-specific information in the AsyncAPI document. It is possible through abindingsfeature. In different parts of the AsyncAPI document, you can provide specific details for Kafka, MQTT, and other protocols. Definitions of bindings are maintained separately from the main AsyncAPI specification in thebindings repository.The current challenge with bindings is that they are hard to validate because they are written in Markdown, human-readable form only. Support in tooling is also pretty limited because of this. We had to start maintaining the JSON Schema, as we do with the main AsyncAPI specification.Thanks to a monumental effort fromKhuda Dad NomaniI'm proud to say that all 15 bindings now have their JSON Schemas. So for exampleKafka bindinghas itsJSON Schemas. The next step is to figure how to link these JSON Schemas with the main AsyncAPI specification JSON Schema and support it in parsers.For more details, have a look atthis issueand help us out to drive it further.Bindings are getting more and more adoption and interest. Many interesting discussions are happening that are shaping the bindings feature. I highly recommend joining them, like, for example, the debate started byIan Cooperto getconsistency between protocol configurations using bindings.InfoQ Architecture and Design 2021I don't think I need to write more than you can spot in this tweet😃. 2021 is very generous for AsyncAPI.Assigning channels to serversI want to suggest you pay attention to the proposal fromGerald Loefflerthat introduces a way toassign a channel to a specific server. This proposal would enable you to have a single AsyncAPI document with multiple different servers supporting different protocols. You could specify that your application is subscribed to channel A on the Kafka server and that it publishes messages to Channel B on the MQTT server.It is a feature that many asked for in the past. Please jump into the discussion. Even if you have no comments, then at least leave some emoji, so we know it was viewed and what people have an opinion.VSCode PluginIván García Sainz-Ajadonated to AsyncAPI Initiative the plugin he developed for the VSCode to enable you to preview AsyncAPI documents using our HTML template directly in the IDE. We need to do some cleanup and rebranding now, and then we will be ready with further development.Any help will be highly appreciated, so please check outthe repository.New AsyncAPI-related toolsWe have new tools onour listof tools created by the AsyncAPI Community:EventBridge AtlasfromDavid BoyneIt parses AWS EventBridge schemas into documentation solutions, shows rules matched to your events, adds metadata to each event property, support slate, AsyncAPI, and docuowl output, and more...AsynctionfromDimitrios DedoussisThe purpose of Asynction is to empower a specification first approach when developing SocketIO APIs in PythonTests coverage tracking in toolingTo increase the quality of our tools now and maintain it in the future, we started exploring tools for tracking test coverage. We integratedCoverallswith theModelinaproject.Jonas Lagonithat actively maintains the library gave Coveralls a score of 8 out of 10. Now we need to roll it out to other projects. If you were looking for some good first issue to start contributing to AsyncAPI, thenthis issueis a good one.Modelina is a data models generator that supports AsyncAPI and JSON Schema. Its goal is to make it easier to write code generators. Jonas released many improvements in May and still does, so it is best to try it out now and provide feedback.Slack reorganizationWe are growing fast, and it was the right time to do some reorg in our Slack workspace to get some structure, clean up, and properly structure discussions. In the end, yes, we are still using Slack because we got accepted as an exceptional organization and receivedStandardsubscription for free❤️.All the official Slack channels are listed below:I think that actually, the most important thing is that we defined our first version of theSlack etiquette.Photo byRahul PanditonUnsplash
"""
--------------------------------------------------------------------------------


Post 82
ID: https://www.asyncapi.com/blog/designing_your_apis_with_asyncapi_part_1?utm_source=rss
Title: Designing your APIs with AsyncAPI (Part 1)
Link: https://www.asyncapi.com/blog/designing_your_apis_with_asyncapi_part_1?utm_source=rss
Summary: How can you utilize code generation to speed up the development process and only focus on what is important - the business logic? In this miniseries, I will explore the ways AsyncAPI and code generati
Content:
"""
How can you utilize code generation to speed up the development process and only focus on what is important - the business logic? In this miniseries, I will explore the ways AsyncAPI and code generation can work hand in hand beyond generating documentation.Structure of the miniseries:Part 1: Designing your APIs with AsyncAPIPart 2: Implementing your applications using code generationPart 3: Black-box testing the applications using code generationPart 4: Introducing new changes when using code generationPart 5: The path to 1 billion players - Scaling the applications and finding bottlenecks with toolingDon't see this blog post series as anything other than an example workflow. This is purely how I do it with my applications and how I use AsyncAPI and its tooling to my advantage. Use this as an inspiration to finding an approach that works for you.BackstoryBack in 2019 when I started contributing to the tooling of AsyncAPI, I was still in university studying for a master's in software engineering and had at that point been a student developer at a company calledEURISCO, for about 3 years. Besides that, I have always had side projects that I worked on in my spare time, and it was one of these side projects that sparked my need for AsyncAPI.My side project at that time was aRustgame server plugin that collected in-game events, such as when a player farms resources, kills another player, loots a container, etc, and send them to a backend. Later these could be extracted by an API to display the player's progression and detailed account of what the player did on the game server.Initially, I used OpenAPI to describe the REST API, and the community tooling allowed me to generate clients and servers in different languages, which accelerated the implementation process.I soon encountered a use case that required me to push data to the game server, and solving this with REST was possible but cumbersome. So I started exploring different alternatives in terms of event-driven architecture. However, none could be described using OpenAPI removing tooling, so I had to find alternatives.That was when I vaguely remembered a meeting in the company where AsyncAPI was mentioned. Around that time, we began to switch from a custom socket protocol toNATSand spend some time figuring out how to mainstream the process for both documenting and generating code for the APIs. This was where we had found AsyncAPI and started adopting the specification.So I started to look into AsyncAPI for my project, which sparked my first ever contribution to an open-source project, but that is a story for another time, maybe.So this blog post is a dedication to that experience, showcasing how I use AsyncAPI to document and generate code to speed up the development process and maybe spark your interest in helping us build the best tooling possible.To that endExplaining something is always better with actual examples, therefore I will be creating a little system to show you how code generation can support the development process.The general setup of the project, with the two applications game server and processor. The round dot between "some broker" and the applications represent how others may grab/interact with the application, ergo its API.I will be creating a system of two applications, agame serverand aprocessorusing a micro-service architecture with no public-facing API. How a player interacts with thegame servercould be through a phone, a computer, Xbox, or PlayStation. I only care about the interaction between thegame serverand theprocessorin this blog post.Thegame serverwill produce the following events: when players join the server, pick up items in-game, uses the chat, hit one another, and eventually disconnect. It will be implemented to simulate players at random intervals joins the server, perform the different actions, and eventually disconnect to provide a sense of realism.The backendprocessorwill be consuming these events to process them. In this series, I will not do anything particular with the data. TheProcessorwill simply save the received events directly to a database.I will not get into the specifics of the stack for this system yet since it does not affect the writing of the API documents for the two applications.Designing the APIs with AsyncAPIWhen starting designing the application APIs I always use thedesign first principle, even when we are talking about internal systems.The game serverI always start with the basics and define all the different channels for which thegame servershould produce events over.1asyncapi:2.0.02info:3title:"Game server"4version:"0.0.1"5channels:6game/server/{serverId}/events/player/{playerId}/item/{itemId}/pickup:7description:Channelusedwhenaplayerpicksupanitemin-game8game/server/{serverId}/events/player/{playerId}/connect:9description:Channelusedwhenaplayerjoins(connectto)thegameserver10game/server/{serverId}/events/player/{playerId}/disconnect:11description:Channelusedwhenaplayerleaves(disconnectsfrom)thegameserver12game/server/{serverId}/events/player/{playerId}/chat:13description:Channelusedwhenaplayerwritessomethinginchat14game/server/{serverId}/events/player/{playerId}/hit:15description:Channelusedwhenaplayerhitanotherplayerin-gameAsyncAPI channels have a different meaning based on the underlying setup. For brokers such asApache Kafka, this is referred to astopics.However, regardless of the underlying setup, channels must be defined as aRFC 6570 URI template.The way I like to structure my channels is to utilize parameters to separate the action from information about the event, so it describes, on what server the event was performed{serverId}, by what player{playerId}and in case ofpickup, what item{itemId}gets picked up. For the last part of the channel, I describe what event it was,pickup,connect,disconnect, etc.Next I define the actual definition of the channels, and here I will focus on explaining the channelgame/server/{server_id}/events/player/{player_id}/item/{item_id}/pickup. The full AsyncAPI document can be foundhere.1...2game/server/{serverId}/events/player/{playerId}/item/{itemId}/pickup:3description:Channel used when a player picks up an item in-game4parameters:5serverId:6description:The id of the server the action was performed on7schema:8type:string9playerId:10description:The id of the player who performed the action11schema:12type:string13itemId:14description:The id of item picked up15schema:16type:string17subscribe:18message:19payload:20type:object21properties:22pickupTimestamp:23type:string24format:date-time25description:The timestamp the item was picked up26$id: PlayerItemPickupPayload27additionalProperties:false28...First, I have the definition ofparametersused in the channel.serverIdtells us where the action originates from, theplayerIdtells us who performed the action, and theitemIdtells us which item was picked up and should all validate against a value with typestring.Displays the game server API as it is described with AsyncAPI with version 2.0.0. The round dot between "some broker" and the game server represent how others may grab/consume the produced event from the game server.Next, we have thesubscribeoperation, which might not make much sense at first glance. I do want thegame serverto publish this event, right?And you would be correct, but this is how you currently define operations in AsyncAPI. You define the operation others may interact with. This means that thegame serverpublishes on this channel and others maysubscribeto it [1][3]. If you want a more detailed explanation, I suggest reading Nic Townsend's post aboutDemystifying the Semantics of Publish and Subscribe.Thepayloadof the channel (is described using a super-set of JSON Schema draft 7) should validate against anobjectwhich contains the propertypickupTimestamp, which should validate against astring. WhenadditionalPropertiesisfalse, no extra properties may be added to the object (by default this istruein JSON Schema draft 7). The$idkeyword is used as an identifier for that specific schema, in this case, I name the object schemaPlayerItemPickupPayload.The backend processorNext, I design theprocessorAPI, which contains all the same channels as thegame server, but with a different operation keyword.Displays the processor API as it is described with AsyncAPI with version 2.0.0. The round dot between "some broker" and the processor represent how others may grab/provide events that the processor subscribes to.This is again because I need to define how others may interact with ourprocessor. This means that instead of using thesubscribeoperation I usepublishto tell others that they can publish to this channel since the backendprocessoris subscribing to it. The full AsyncAPI document for theprocessorcan be foundhere.1...2game/server/{serverId}/events/player/{playerId}/item/{itemId}/pickup:3...4publish:5...6...Introducing reusabilityAt the moment, each of the AsyncAPI documents contains its definition of the channels. But what if I were to add a new validation rule such as a new property to theplayerItemPickupPayloadschema? In this case, I would have to change this for both applications, which is way too much work😄Therefore, we can introduce$refto separate the parameters and messages into smaller sections for reusability. I will be placing all separate components into a"components" directoryin the same directory the AsyncAPI documents reside.Just a quick note, at the moment, it is not possible to reuse channels and operations directly between the two applications. Therefore we can only apply this to the parameters and message individually while keeping some duplicate information [2].First, I separate the different parameters. For simplicity, I add all of them into the same file./components/Parameters.yaml.1serverId:2description:Theidoftheserver3schema:4type:string5playerId:6description:Theidoftheplayerwhoperformedtheaction7schema:8type:string9itemId:10description:Theidoftheitem11schema:12type:stringAnd then change all the channel parameters to reference the external parameter definition.1...2game/server/{serverId}/events/player/{playerId}/item/{itemId}/pickup:3description:Channelusedwhenaplayerpicksupanitemin-game4parameters:5serverId:6$ref:"./components/Parameters.yaml#/serverId"7playerId:8$ref:"./components/Parameters.yaml#/playerId"9itemId:10$ref:"./components/Parameters.yaml#/itemId"11...12...For the messages, I add a new file per message instead of keeping everything in the same file as parameters. I use this approach since I find it easier to maintain and extend.We add the message file./components/messages/PlayerItemPickup.yaml1payload:2type:object3properties:4pickupTimestamp:5type:string6format:date-time7description:Thetimestamptheitemwaspickedup8$id:PlayerItemPickupPayload9additionalProperties:falseand alter the channel definition for thegame serverto:1...2game/server/{serverId}/events/player/{playerId}/item/{itemId}/pickup:3description:Channelusedwhenaplayerpicksupanitemin-game4parameters:5serverId:6$ref:"./components/Parameters.yaml#/serverId"7playerId:8$ref:"./components/Parameters.yaml#/playerId"9itemId:10$ref:"./components/Parameters.yaml#/itemId"11subscribe:12message:13$ref:'./components/messages/PlayerItemPickup.yaml'14...These changes are applied to theprocessoras well. You can find all the AsyncAPI fileshere.What's nextNow, that the APIs are designed for two applications, we can move on to the fun part, implementing the applications using code generation.Related issuesIf you are interested in jumping into our discussions and being part of the community that drives the specification and tools, I have referenced some of the outstanding issues and discussions related to the different aspects I have referenced in the post.Add a View property to the info section to change the perspective of subscribe and publish operationsReusing channel definitions across files is hardConfusions with the Publish and Subscribe meaning/perspectiveCover photo byDavid JakabfromPexels
"""
--------------------------------------------------------------------------------


Post 83
ID: https://www.asyncapi.com/blog/async_standards_compare?utm_source=rss
Title: AsyncAPI, CloudEvents, OpenTelemetry: Which Event-Driven Specs Should Your DevOps Include?
Link: https://www.asyncapi.com/blog/async_standards_compare?utm_source=rss
Summary: A decade ago, event-driven architecture was the wild west. Documentation? It’s in a spreadsheet somewhere. Where did the event go? Here’s a list of ten logs to search through. How do we make sure even
Content:
"""
A decade ago, event-driven architecture was the wild west. Documentation? It’s in a spreadsheet somewhere. Where did the event go? Here’s a list of ten logs to search through. How do we make sure events from System A can be understood by System B? Slap some headers on the message and hope that they make it across the event broker.This postAsyncAPI, CloudEvents, OpenTelemetry: Which Event-Driven Specs Should Your DevOps Include?appeared first onSolace.Thankfully, the increased adoption of event-driven and distributed architectural patterns has meant increased attention to related open-source specifications. With solidifying specifications, standardized instrumentation and reusable tooling has emerged as well. Becoming event-driven today involves less guess work and more assurance of compatibility.But which specifications matter? And how should they be used?Within the event-driven ecosystem, there are three major emerging specifications: CloudEvents, OpenTelemetry and AsyncAPI. Each of them map to phases of the DevOps lifecycle, and address a distinct challenge with event-driven development and/or implementation. Used together, they can make event-driven DevOps easier to implement.Here’s a summary of where each of the specifications fits, I will examine each more in depth later:In addition to different portions of the DevOps lifecycle, the three specifications focus on different challenges and objects within the event-driven landscape:There is some overlap between the three, particularly as the specifications mature and expand. There are areas where two specifications cover the same ground in different ways, so it’s up to architects to determine how best to allocate functionality.Async APIParticularly in API-first methodologies, the DevOps “Plan” phase revolves around defining the application programming interface (API). The API describes what messages an application can accept and emit. The APIs can then be used to build the application, advertise its capabilities to others and document its functionality.However, defining an interface requires having a standard way of describing it that can be 1) used by many different programming languages, 2) leveraged by multiple tools and 3) read (at least sort of) by humans. In the synchronous world, OpenAPI does this work. For event-driven applications, AsyncAPI tries to do the same thing. It offers a parallel to the OpenAPI specification, but with modifications to allow for asynchronous, event-driven behavior. You can see the parallel for yourself in the structure of the specifications:In addition to the Plan phase, AsyncAPI also has emerging capabilities for other phases (shown in grey above):Code:Acode-generator for Spring Cloud Streamtakes an AsyncAPI definition and creates skeleton code, reducing the need to laboriously create boilerplate code. More code generators are planned. And vice-versa, there arecode-first toolsat that will generate an AsyncAPI spec out of numerous popular languages.Test:Thepartnership between AsyncAPI and Postmanhighlights the increased ability to test async flows once they are well defined.Deploy:Technology-specificbindingsdefined within the spec can be used to establish connections and subscriptions to event brokers upon deployment.Operate:Once messages are flowing at runtime, an AsyncAPI document can be used to ensure schema compliance with tools likeNode.js AsyncAPI ValidatorCloudEventsAs more technologies become event-driven, ensuring that they all communicate effectively becomes challenging.For example: An equipment failure occurs at a manufacturing plant, generating an event. The attached IoT device publishes a message containing the alert event to an MQTT server. At the end of the journey, the event lands in a Kafka topic, is pushed to a websocket, and is sent to a function as a service using an HTTP webhook.Contextual information about the event is crucial for all the consumers, but every consumer could expect it in a different place, with a different naming convention and a different format. Some producers might even choose not to include a key piece of metadata.To resolve these challenges, enterprises have traditionally created their own custom envelope: standards about what meta information is included in messages and in what format. But many applications don’t comply, either because they are outside the organization, it’s a legacy app that’s too pricey to retrofit, or because they use a protocol that hasn’t been included in the standard.The workaround is typically tedious and error-prone – manual mapping of metadata. This additional step can mean using data transformation software to enrich messages.  And in cases where information is missing, you either have messy data generation or make do without it.CloudEvents aims to eliminate the metadata challenge by specifying mandatory metadata information (like event source and type of event) into what could be called a standard envelope. The fields are then mapped to individual messaging protocols like Kafka, MQTT and HTTP, so there’s no question about where the fields exist on each message. Most importantly, there’s wide support for different programming languages.There is an overlap between CloudEvents and AsyncAPI, as noted by AsyncAPI’s founder. The metadata fields used by CloudEvents could be defined within an AsyncAPI schema. However, there is an advantage to using CloudEvents in addition to AsyncAPI. CloudEvent libraries are available for multiple programming languages for multiple protocols, which streamlines interoperability. For instance, a Java developer can utilize a CloudEvents SDK to publish CloudEvents compliant messages to Kafka, without having to worry about the underlying metadata implementation.And as an evolving standard being used by major SaaS and cloud providers, CloudEvents is gaining both momentum and functionality. In addition to the Operate phase, now that the core specification has been released, the group’s focus has turned to several extensions that address other stages and address other event-driven challenges:Plan:Discovery capability allows new and existing applications to query a catalog of services for available events using a standardized API.Deploy:Subscription manager capability allows applications to subscribe to events using a standardized API.OpenTelemetryIn contrast to AsyncAPI and CloudEvents, which address producing and consuming events themselves, OpenTelemetry focuses on end-to-end monitoring of those events. OpenTelemetry standardizes the creation and management of trace information, which can reveal the path of a single event through multiple applications, or show the aggregate metrics that combine multiple events.Implementing OpenTelemetry typically means instrumenting code so that it can emit monitoring information. This information is then aggregated in a backend system, either on-premises or through monitoring as a service provider.Once completed, OpenTelemetry helps to answer the classic event-driven question “Where’s my event?” By including business-related fields in the trace, it’s possible to search by, say, the order number of the original event, and have its entire path through multiple applications revealed.ConclusionIt’s a great time for event-driven architecture. Challenges that used to be overcome in different ways in every implementation are now being addressed by standard, open-source solutions. While OpenTelemetry, AsyncAPI and CloudEvents do have overlapping capabilities, they are distinct enough to all warrant a place in your DevOps processes.If you have more questions or want to share your experience with these standards, you can let us know in theAsyncAPI Slackor theSolace Community Forum.
"""
--------------------------------------------------------------------------------


Post 84
ID: https://www.asyncapi.com/blog/websocket-part3?utm_source=rss
Title: From API-First to Code Generation - A WebSocket Use Case
Link: https://www.asyncapi.com/blog/websocket-part3?utm_source=rss
Summary: Learn how to go from API design to code generation. Create a WebSocket API for ChatBot. All supported by AsyncAPI
Content:
"""
This is the last article of WebSocket series. I recommend you readWebSocket, Shrek, and AsyncAPI - An Opinionated IntroandCreating AsyncAPI for WebSocket API - Step by Stepfirst.In my previous articles from the WebSocket series, I introduced you to WebSocket topic and explained how you would describe your WebSocket API using AsyncAPI specification.What was the point of doing it anyway? Why learning the specification?Just to document your API? Nah, that would be a huge waste of time. Like seriously, would you learn a new specification only to describe the API for documentation purposes? Please don't. You could do so much more with it.Look at the list ofall the toolsbuilt for AsyncAPI. There are many ahead of us, but the current list already explains what can be done with AsyncAPI. You can validate your messages in real-time in your application withasyncapi-validatoror mock and test your application withMicrocks. You can also generate code by picking one ofthe official templates. In this article, I will focus on the aspect of code generation.API-First vs Code-FirstDesigning API first and then coding later is not an easy shift. For a coder, it is easier just to code and focus on code aspects. And this is just fine. That is how humans work. We do what we learned and focus on making things good and maintainable. Different tasks require different skills, and it is ok that not everybody has them. Designing API requires a different look on the subject, being more flexible and abstract. You need a wider perspective, forget about implementation details, and think about the user first.Do you need the specification to design API?No, but specification makes the design process and feedback loop easier to handle and faster. If backed by good tools, of course.What is wrong with generating AsyncAPI from code?Even though I'm an author of many memes like those in this article, I'm actually far from judging. It all depends on your project, architecture, and even the work environment.In the end, I think there is a wrong assumption that if you generate spec from code, it means you did not think about API design and your users.Even AsyncAPItooling liststigmatize tools that allow you to generate spec from the code as code-first tools. Who said you couldn't do both things in parallel.I just realized this topic could continue and evolve into a dedicated article, so let me do a full stop here.My goal is to educate you on:Designing a WebSocket API with multichannel, with one message each. In other words, I want to show you something opposite to my previous articles where you could see a WebSocket API that has one channel but with multiple different messages.Performing code generation that enables you to focus on business logic only.I'll try to come back intoAPI-First vs Code-Firsttopic in the summary of the article.ShrekAppI know that inthis article, I wrote that I would not try to model a Shrek application. Since the moment I wrote I will not do it, I immediately started thinking about doing it😃So here I am, showing you a possible use case for AsyncAPI with WebSocket protocol basing on Shrek. I shamefully admit I do it mainly to make sure my head moves on and thinks about something other than Shrek😃Write AsyncAPI documentYou can see entire AsyncAPI documenthereThere are several questions you need to ask yourself when designing an API:What is the name of the API?What is the purpose of the API?What is the version of the API?How user can connect with the API and over what protocol?What messages can your user receive from and send to your API?On what channels are these messages available?What is the structure of these messages? What is the schema?These are basic questions that can be reflected in the AsyncAPI document.In case you didn't notice, these questions are user-oriented. Your AsyncAPI document must describe what users can do with your application and not what it does. It makes a difference.InfoI'm designing aShrekApp, release under 1.0.0 version. Its purpose is to enable chat with a chatbot trained to behave like Shrek. I want to useWit.aias a platform for training the bot that gives me a REST API to talk to the bot.1info:2title: Shrek App3version:'1.0.0'4description: |5Purpose ofthisappisto have some fun with AsyncAPIandWebSocketanddefine aninterfacefor...Shrek.67![](https://media.giphy.com/media/10Ug6rDDuG3YoU/giphy-downsized.gif)89YoucanusethisAPItochatwithShrekbotortogetupdatesaboutartificaltravelstodifferentlocations.ServersThe communication with the application goes over the WebSocket protocol. For now, it is not publicly hosted. You can run it locally and therefore connect throughlocalhostonly.1servers:2swamp:3url:localhost4protocol:wsChannelsThere are two separate entry points for the user to interact with the API:chatwhere bi-directional communication is possible to enable real-time conversation with the bottravel/statuswhere user can subscribe for a stream of updates on different travels, like for example:1destination:Far far away2distance:Beyond the seven mountains and seven forests3arrival:Pretty soonExcept for basic information like the purpose of messages, pub/sub operations, and messages schema, it is good to specifyoperationIdthat is unique across the entire AsyncAPI document and helps to generate human-readable functions' names.In the below example, you can see a usage ofcomponentssection and schema definitions. I don't want to explain those sections in detail here as I did it already in theCreating AsyncAPI for WebSocket API - Step by Steparticle.1#2# Details about all the channels that user can listen to or send to messages3#4channels:5/chat:6subscribe:7summary:Client can receive chat messages.8operationId:subChatMessage9message:10$ref:'#/components/messages/chatMessage'11publish:12summary:Client can send chat messages.13operationId:pubChatMessage14message:15$ref:'#/components/messages/chatMessage'16/travel/status:17subscribe:18summary:Client can receive travel info status.19operationId:subTravelInfo20message:21$ref:'#/components/messages/travelInfo'2223#24# All reusable parts for readability and staying DRY25#26components:27messages:28chatMessage:29summary:Message that you send or receive from chat30payload:31type:string32travelInfo:33summary:Message that contains information about travel status.34examples:35- payload:36destination:Far far away37distance:Beyond the seven mountains and seven forests38arrival:Pretty soon39payload:40type:object41properties:42destination:43description:Name of travel destination.44type:string45distance:46description:How much distance left to the target.47type:string48arrival:49description:Time left to get there.50type:stringFinal documentYou can see the entire AsyncAPI document for ShrekApp always up to datehereThe AsyncAPI document I just created is not very complicated as this way it will be easier to understand the generated code. Most important is for you to notice that all information about your application is expressed in the AsyncAPI document, and once you do it, options for the next steps are just endless.Generate CodeIt is time now to generate some code that enables you to focus just on the business logic.AsyncAPI GeneratorThe AsyncAPI Initiative maintains theAsyncAPI Generator, a tool that enables you to generate anything you want out of an AsyncAPI document.Generatorprovides several features that make it much easier to provide so-calledtemplates. The template is a standalone project that defines what files should be rendered by the Generator as a final output.We have many templates on ourlist. Try out the project by following👇instructions:Select a Generator template:HTMLMarkdownNode.jsNode.js WebSocketsJava Spring Cloud StreamJava Spring BootPython PahonpmDocker1npm install -g @asyncapi/cli2asyncapigeneratefromTemplate https://bit.ly/asyncapi @asyncapi/html-template -o exampleGenerate Server and ClientThis article focuses on WebSocket therefore, I use ourNode.js WebSocket templatethat is capable of generating server for WebSocket API and also a client that is aware of available channels.Create a new directory where you will work on the project:mkdir shrekapp &&cdshrekappTrigger generation using the template:ag https://raw.githubusercontent.com/derberg/shrekapp-asyncapi-designed/main/asyncapi.yaml @asyncapi/nodejs-ws-template -o myapp -p server=swampAccess generated folder and list all files from the directory. Notice that Node.js application is generated:cdmyapp && lsInstall application dependenciesnpm iStart the applicationnpm startThat is it. The basics are done. The application is ready, and all the basic logic is there. You can already interact with the application onlocalhoston port80. Now you need a client able to communicate with WebSocket protocol. For now, we will not explore the generated client.Getwebsocat(curl-like tool for WebSocket) by followingthese instructionsConnect to one of the channels and notice that the server sent you a message to respond to established connection.1websocat ws://localhost/travel/status23Message from the server: Implement here your business logic that sends messages to a client after it connects.Logs in the running server should also indicate a new connection with the server:1Listening on port 802/travel/status client connected.Code WalkthroughBefore writing some code, let's first go through the generated code:For the generated server, we need to look intosrc/api/routes.jsandsrc/api/servicesFor generated client, everything is in theindex.htmlServer CodeRouterBasing on the information provided in the AsyncAPI document about available channels, in thesrc/api/routes.jsthe following routes are generated:1const { subChatMessage, pubChatMessage } = require('./services/chat');2const { subTravelInfo } = require('./services/travel-status');34router.ws('/chat', async (ws, req) => {5const path = pathParser(req.path);6console.log(`${yellow(path)} client connected.`);7await subChatMessage(ws);8ws.on('message', async (msg) => {9console.log(`${yellow(path)} message was received:`);10console.log(util.inspect(msg, { depth: null, colors: true }));11await pubChatMessage(ws, { message: msg, path, query: req.query });12});13});14router.ws('/travel/status', async (ws, req) => {15const path = pathParser(req.path);16console.log(`${yellow(path)} client connected.`);17await subTravelInfo(ws);18});In the case of this particular template, routes are handled byExpress frameworkandexpress-wsmiddleware.First let's have a look at/travel/statusroute:1router.ws('/travel/status', async (ws, req) => {2const path = pathParser(req.path);3console.log(`${yellow(path)} client connected.`);4await subTravelInfo(ws);5});Once the client establishes connection with the server, generated code invokes a function calledsubTravelInfo. Now look again at the AsyncAPI document:1/travel/status:2subscribe:3summary:Client can receive travel info status.4operationId:subTravelInfo5message:6$ref:'#/components/messages/travelInfo'The name of the function maps to theoperationId. The/travel/statuschannel supports onlysubscribeoperation which means that client can only connect to the channel to listen for the messages, no messages are accepted. This is why the generated router doesn't react to any message sent to the channel. As oposite to the/chatchannel:1router.ws('/chat', async (ws, req) => {2const path = pathParser(req.path);3console.log(`${yellow(path)} client connected.`);4await subChatMessage(ws);5ws.on('message', async (msg) => {6console.log(`${yellow(path)} message was received:`);7console.log(util.inspect(msg, { depth: null, colors: true }));8await pubChatMessage(ws, { message: msg, path, query: req.query });9});10});ThesubChatMessagefunction is invoked when client connects with the server. There is also a message listener generated that invokespubChatMessagefunction whenever a message is sent from the client. Now look again at the AsyncAPI document:1/chat:2subscribe:3summary:Client can receive chat messages.4operationId:subChatMessage5message:6$ref:'#/components/messages/chatMessage'7publish:8summary:Client can send chat messages.9operationId:pubChatMessage10message:11$ref:'#/components/messages/chatMessage'The client can not only listen to the messages incoming from/chatchannel but, in this case, can also send messages. This way, there can be bi-directional communication established between the client and the chatbot.ServicesFunctions like, for example,pubChatMessageare generated in theservicesdirectory. All functions for single channel go into individual file. Have a look atsrc/api/services/travel-status.jsfile:1constservice =module.exports = {};23/**4* Client can receive travel info status.5* @param {object} ws WebSocket connection.6*/7service.subTravelInfo =async(ws) => {8ws.send('Message from the server: Implement here your business logic that sends messages to a client after it connects.');9};As you can see, you are ready to provide your business logic by replacing the generated one:ws.send('Messagefromtheserver: Implement here your business logicthatsends messagestoa clientafteritconnects.');Client CodeThe Node.js WebSocket template that I use for this article also generatesindex.htmlfile to showcase that client generation is also possible using AsyncAPI document. As I mentioned in the beginning, with AsyncAPI and the AsyncAPI Generator, you can generate whatever you want.Theindex.htmlcontains a simple API that you can call from the browser's console to talk to the WebSocket API. Open the file in the browser and play with the API:Add Business LogicThe Business logic goes only to generated services.Add Travel Status UpdatesI don't have here any real travel status updates. I add some dummy data that are sent to the client every 1s, 100 times.Adddummy-jsonthat makes it easier to provide mock data. I add it only to make sure the code is not overcomplicatednpm i --save dummy-jsonImported the package in thesrc/api/services/travel-status.jsfile:constdummyjson= require('dummy-json');ModifysubTravelInfofrom the same file to send mock data to the client withws.send()function:1service.subTravelInfo = async (ws) => {2(functionmyLoop (i) {3setTimeout(() => {4ws.send(generateResponse());5if (--i) myLoop(i);6},1000);7}(100));89function generateResponse() {10const template = `{11"destination":"{{city}}",12"arrival":"{{int 2 6}}h",13"distance":"{{int 18 65}}km"14}`;15return dummyjson.parse(template);16}17};This is it. Now restart the server and check with previously installedwebsocatif after connecting totravel/statuschannel you are now regularly receiving a stream of messages:1websocat ws://localhost/travel/status23{"destination":"Woodville","arrival":"4h","distance":"60km"}4{"destination":"Denver","arrival":"3h","distance":"60km"}5{"destination":"Fargo","arrival":"3h","distance":"42km"}6{"destination":"Exeter","arrival":"2h","distance":"62km"}7{"destination":"Bradford","arrival":"2h","distance":"55km"}8{"destination":"Toronto","arrival":"6h","distance":"28km"}9{"destination":"Durham","arrival":"5h","distance":"59km"}10{"destination":"Canterbury","arrival":"4h","distance":"50km"}Add ChatBot CommunicationI chose Wit.ai as a platform that:Makes is super easy to train the botGives me access to API that enables integration with custom services, like the one that we just generatedI encourage you togive it a tryas it is pretty easy to use if it is your first time with ChatBots. It was my first time.To make it easier to talk to Wit.ai API I usenode-fetchpackage:npm i --save node-fetchImported the package in thesrc/api/services/chat.jsfile:constfetch= require('node-fetch');ModifysubChatMessagefrom the same file to send to the client message that connection is working:1service.subChatMessage= async (ws) => {2ws.send('Connection with Shrek established');3};ModifypubChatMessagethat is invoked when message from the client gets to the/chatchannel:1service.pubChatMessage= async (ws, { message, path, query }) => {2constmessageToShrek= message ? encodeURIComponent(message) :'';3constdefaultAnswer='Shrek is out sorry. He\'s busy rescuing the princess.';4letshrekAnswer= defaultAnswer;5let botAnswer;67try {8botAnswer= await fetch(`https://api.wit.ai/message?q=${messageToShrek}`, {9headers: { 'Authorization': `Bearer ${process.env.CHATBOT_TOKEN}` }10});11} catch (e) {12throw new Error(`Having issues communicating with the bot: ${e}`);13}1415if (botAnswer) {16constwrongQuestionAnswer='Is it you Donkey!? Ask a better question!';17constanswerObject= await botAnswer.json();18let firstTraitValue;1920for (const[, v]of Object.entries(answerObject.traits)) {21firstTraitValue= v[0].value;22break;23}2425shrekAnswer= firstTraitValue ? firstTraitValue : wrongQuestionAnswer;26}27console.log(`Answered with: ${shrekAnswer}`)28ws.send(shrekAnswer);29};The most important part of this code is when the communication with the Wit.ai platform happens to send a message and get a response:1botAnswer = await fetch(`https://api.wit.ai/message?q=${messageToShrek}`, {2headers: {'Authorization':`Bearer ${process.env.CHATBOT_TOKEN}` }3});This is it. Now restart the server and check with previously installedwebsocatif after connecting tochatchannel you can send messages to chatbot and receive answers. You need to start the server withCHATBOT_TOKENenvironment variable with the token:CHATBOT_TOKEN=your-token npm start. I cannot give you my token, sorry, you have to get yours fromWit.aiand train your chatbot:1websocat ws://localhost/chat23Connection with Shrek established45Me: Hi Shrek6Shrek: hey,doyou know ogrs have layers?7Me: Interesting8Shrek: are you mocking me?9Me: Why would I? I like you10Shrek: Is it you Donkey!? Ask a better question!11Me: No, not a donkey12Shrek: goodYou can also see logs on the server-side:1Listening on port 802/chat client connected.3/chat message was received:4'Hi Shrek\n'5Answered with: hey,doyou know ogrs have layers?6/chat message was received:7'Interesting\n'8Answered with: are you mocking me?9/chat message was received:10'Why would I? I like you\n'11Answered with: Is it you Donkey!? Ask a better question!12/chat message was received:13'No, not a donkey\n'14Answered with: goodSummaryIf you do not want to go through all the steps of getting the generated code, you can directly usethis project. It contains everything mentioned in this article.As you could see, the only coding part was just business implementation details, and the rest was generated. When I worked on this article, I focused first on the API. My main goal was to write the AsyncAPI document first, and the rest was easy.Are you convinced now that API-first is better than code-first?I'm an API-first person. I can go on and give you many arguments that support my view.I won't do it.Instead, I will honestly tell you what the problems are related to API-first and code generation. You judge what is the path you want to take.AsyncAPI 2.0 LimitationsAs I mention in this article and the previous ones on WebSocket, you write AsyncAPI document for your application from a client perspective. When you start designing your API, you ask yourself questions from the user's perspective.Don't get me wrong; I'm not saying that taking user perspective is wrong. It makes sense but also confusing for many. I recommend joiningthis threadfor more details.Confusion betweensubscribeandpublishis not the only problem. Once you understand that your application that publishes events must describe it as subscribe operation, the rest is trivial.The real problem is with code generation. You describe the application from a user perspective, so client code generation is easy. What about generating code for your server? Have a look again at the/travel/statuschannel from ShrekApp:1/travel/status:2subscribe:3summary:Client can receive travel info status.4operationId:subTravelInfo5message:6$ref:'#/components/messages/travelInfo'I had to try hard to make sure thesummaryandoperationIdare as neutral as possible. My first version looked like this:1/travel/status:2subscribe:3summary:You can listen to travel info status.4operationId:onTravelInfo#client code perspective, generated client reacts"onTravelInfo"incomming message5message:6$ref:'#/components/messages/travelInfo'Then insrc/api/services/travel-status.jsfile, I would haveonTravelInfoinstead ofsubTravelInfowith the following jsdoc:1/**2*Youcan listen to travelinfostatus.3* @param {object}wsWebSocket connection.4*/5service.onTravelInfo = async (ws) => {6...This is a function responsible for sending messages to the Client once it connects with a given channel. Function name likeonTravelInfois misleading, not to mention the generated code description.I chose neutral descriptions. They are acceptable, I think, but not when it comes to user-facing documentation. Every technical writer will tell you that the best docs are the ones that are directed to a reader. You don't write "what user can do with the API" but "what you can do with the API".Therefore, all descriptions and even things likeoperationIdshould have two versions to satisfy both docs and code depending on the perspective. Otherwise, you need to make a sacrifice. You either make the developer that maintains the code happy or the technical writer that maintains docs happy.Join the discussion aroundoperationId.Keeping AsyncAPI in Sync With CodeIn this article, I generated a server that was easy to extend, to showcase AsyncAPI capabilities. Using such projects is a way for building prototypes and quickly design architectures. You can even scaffold a server that later you can tune and use on production.You did your work, you did API-first.What happens later? I mean later during further development of the application.Let's say you add a new channel to the server or modify the name of the old channel.Where do you do it? AsyncAPI document or the code? You need to do it manually in both. You need to add a channel to the AsyncAPI document and add implementation for the channel in the code. You enter the land where your AsyncAPI document describes something different from your code at some point in time. You cannot regenerate the project with the template you used in the beginning, as your custom logic will be lost.The AsyncAPI Generator provides support for Git. If you have a Git repository and unstaged files, the Generator warns you that your changes may be lost. Git support is definitely helpful. You can try code regeneration, but you need to review changes and manually ignore overrides after that.It can be a cumbersome process, but you maintain sync between the AsyncAPI document and the code. There is no place for automation, though.There must be a way to solve these challenges. Maybe some kind of markers.  One could use them in code to indicate that the generator must ignore a given part of the code. Another helpful solution could be a way to specify what template files should be ignored during generation. For example, regenerate only models built from messages' schemas. We need to figure it out.Don't give up, though. Technical challenges are not a good excuse for avoiding the API-first approach.In my opinion, specification limitations and gaps in tooling support should not block you from choosing an API-first direction. The benefits are too big to resign that easily. Just join us and let us find solutions together. We want to help solve all those issues, but we just need some help from you too.That would be it. Thanks for staying with me until the end. Don't forget to read my previous articles on AsyncAPI spec and WebSocket protocol. Share your feedback and connect with the AsyncAPI community in ourSlack workspace.
"""
--------------------------------------------------------------------------------


Post 85
ID: https://www.asyncapi.com/blog/april-2021-at-asyncapi?utm_source=rss
Title: April 2021 at AsyncAPI
Link: https://www.asyncapi.com/blog/april-2021-at-asyncapi?utm_source=rss
Summary: AsyncAPI 2.1 release is scheduled. Is there anything else that could be more important.
Content:
"""
ReadMarch 2021 at AsyncAPIfor the update from March.AsyncAPI specification release cadenceI'm super happy to share that we removed the last roadblock for the next AsyncAPI release. Basing on some discussions during our public meetings and onthisissue, the release schedule for the spec looks like this:June 2021September 2021January 2022April 2022June 2022September 2022January 2023April 2023June 2023I hope you noticed a pattern. We do not want to do releases during the summer holidays and stay away from December😃.In June 2021, we will release 2.1.0 version of the specification. It is going to be the first release underopen governance model, under Linux Foundation and newcontribution guide. So many new things, a lot to organize around. It means we probably won't accept too many changes as logistics will consume a lot of time. We welcome any help. Join ourSlackfor more details.AsyncAPI use case at eBayIf you were looking for an AsyncAPI use case that shows some big tech using AsyncAPI in production, it is here. I highly recommend you read the articleAsyncAPI 2.0: Enabling the Event-Driven WorldfromShekhar Banerjeefrom eBay.React component and HTML template mergeAsyncAPI document can be rendered into documentation using two different tools maintained by the AsyncAPI Initiative:You can useReact component, also bundled as Web Component, to render the AsyncAPI document on the client-side.You can useHTML templatethat is a docs generator compatible with the AsyncAPI Generator for a server-side generation.These are two completely separate tools. People are contributing to both. There are some features supported in the first one but not in the other one, and vice-versa.It is such a waste of time for contributors. We never liked it.Maciej Urbanczyktook the effort to change it.Solution: Use React component as the core and HTML template to provide static output by rendering React during generation (you may know such approach from tools like Gatsby or Next.js).Sounds simple, but there was a lot of work to do:React component to use official AsyncAPI Parser (yes, we were a bit behind there)Provide features from HTML template to React component (who likes functionality regression, right?)Rework design of React component to match the HTML templateThe result:You need to try the new React component that is getting closer to the 1.0 release and jointhe discussion.npm install @asyncapi/react-component@nextHTML template already uses this React release candidate under0.21.1version.Don't stay behind. Maciek is now entirely focused on the component. Now is the best time to push for your features😃.Your favorite missing features like rendering of extensions and bindings are already there!Intend-driven API for AsyncAPI ParsersOver the last couple of weeksJonas LagoniandSergio Moyaworked on an idea to make the AsyncAPI JavaScript Parser, and in future other parsers, resilient to breaking changes in the AsyncAPI specification.Why?The current parser is bound to the structure of the AsyncAPI specification. The goal is to move away from such an approach into the API driven by the developer's intent.Learn more about the outcome of this tremendous effort from Sergio's article:Designing a unified Intent-driven API for all AsyncAPI's parsersWebSocketSince we were getting more and more questions about using WebSocket with AsyncAPI, it was about time to provide some learning materials. We had no dedicated documentation nor examples, so I decided to spend few weeks on that subject, and as a result, we got:Blog post onWebSocket, Shrek, and AsyncAPI - An Opinionated IntroBlog post onCreating AsyncAPI for WebSocket API - Step by StepAnd soon I'll release the last blog post onFrom API-First to Code Generation - A WebSocket Use CaseIn addition, you can have a look atofficial WebSocket example.There is also alive streamI did about this topic. I will also present atEDASummiton 19th of May and most probably atAPIOps Helsinkisomeday around mid-June. Stay tuned.JobsIs your company looking for an AsyncAPI expert? Now you can share your job description on the AsyncAPI website to share it directly with the AsyncAPI community. In April, we had 300 individual users looking at Jobs view even though we do not actively promote it. Once the list of jobs grows, we will promote it more to increase the traffic and job offers visibility.Head onhereand check out instructions on getting your job posting published.This option to add custom job offers, including jobs filtering, was contributed byAcebuild🙏.RSSWe finally have anrss feedfor our AsyncAPI blog. All thanks toMike Ralphson.If you do not like feed readers, just like me, then use some service likeBlogtrottrto get email notifications. I use it for a GitHub blog on the free plan, and I'm super happy.AsyncAPI workshop aka trainingMore and more people learn about AsyncAPI. We need to make sure there are good learning materials for anyone. More important, we need a solution that is easy to scale.Our new initiative is to work on training materials that can be used for in-class workshops with trainers, but on the other hand, they need to be available on a platform that offers self-learning training. All discussions happenhere, and you can also join the #training channel in ourSlack.We need people that want to become trainers, trainees or help to work preparing training materials. All hands aboard💪.Who knows, maybe once it grows to a proper size, we will start thinking about some official certification program?AsyncAPI and KafkaThis year there were many sessions about AsyncAPI atKafka Summit. You need to have a look. If you want to work around the registration process, watch the below recording fromDale Laneexplaining how to use AsyncAPI with Kafka:Dale has more content about AsyncAPI. For example, have a look at his work on the AsyncAPINode-REDplugin:Interest growthI'm losing track here. It is growing so fast that we should expose some real-time metric that shows some aggregated data.For example, on Twitter, we went up by 200 followers in April, up to 1900. Now, when I write this article, it is already over 2000.On Slack, we are already over 1200, and on LinkedIn, over 1100.🚀🚀🚀Photo byWaldemar BrandtonUnsplash
"""
--------------------------------------------------------------------------------


Post 86
ID: https://www.asyncapi.com/blog/intent-driven-api?utm_source=rss
Title: Designing a unified Intent-driven API for all AsyncAPI's parsers
Link: https://www.asyncapi.com/blog/intent-driven-api?utm_source=rss
Summary: Afraid because of breaking changes? Learn how do we plan to reduce breaking changes in our tooling APIs by introducing a new design approach called Intent-driven.
Content:
"""
TheFree and Open-Source Software(FOSS) model, since its inception, has brought a flurry of libraries and applications available to everyone.Thanks to the growth of the open-source community, we can now enjoy free software and, in most cases, generate profit from it.I believe there is no tech company that doesn't use open source in one way or another.FOSS has changed the way most developers operate: from coding all features from scratch to become consumers of libraries that implement most of the basic operation of an application. Sometimes even the core logic of the application is baked with free software.So much so that I, as a developer, can't imagine having to implement a complex application from scratch.If we go a step further, we won't talk only about libraries but also about APIs as services. For example, the fast adoption of theJamstackarchitecture, where the backend consists of different API services (primarily third-party), is pushing SaaS companies to make their private APIs public.In short, applications worldwide depend on free libraries maintained by the community, which constantly deliver updates at a frenetic rate: new functionalities, fixes, or in many other cases, drastic changes that allow us to continue growing and maintaining those libraries or APIs.The latter is, precisely, a problem for many developers. The feared👻breaking changes👻.Disclaimer: This post provides examples from the point of view of a software library API maintainer. However, the same principles apply to any other API, such as command-line tools, REST, Kernel modules, or peripheral drivers.What is a breaking change?A change in one part of a software system that potentially causes other components to fail; occurs most often in shared libraries of code used by multiple applications.Source:https://en.wiktionary.org/wiki/breaking_changeBreaking changes are non-backward compatible changes in the public interface of an application, either a library, an API service, or even a command-line utility.Users of such software are forced to alter their code if they want to use the latest version; otherwise, their code will be unusable.I propose a metaphor to better understand what abreaking changeis. By the way, based on something that happened to me a few days ago.
Imagine that your preferred supermarket, the one you have been going to for several years, decides to restructure its interior completely. Where you could find the fruit, now you only find water and other drinks. At this point, I have three options:You adapt yourself to the new layout and changes made to the surface. It will take a few days or maybe weeks to know where each product is, but in return, you can continue shopping at your favorite supermarket.Seek another supermarket that does not make drastic changes. In case they want to make changes, changes to be less and communicated in advance.Decide that you will devote all your efforts to grow your vegetables, raise your cattle, ride a water purification plant, and everything it takes to not rely on any supermarket or store.I went for the first option. Today I still get lost when I go shopping, but at least pasta is still on the same shelf as it was!In the software world, the first option would mean to update your code, so you avoid breaking changes.Therefore, the second option would be to look for another library or an API designed to avoid, as far as possible, these breaking changes. Building an API that meets this requirement is the primary purpose of this post.Finally, the third option would be to make zero use of FOSS.How can we mitigate the impact on users when releasing a newmajorversion of our library or service API?Designing APIs that are resilient to breaking changesAPIs solve user needs.However, I believe we do not listen to the final users that much. Instead, we tend to expose functionalities based on our own experience, biased by our position or the knowledge we own of the platform behind. Sometimes guided by preliminary research (Product-oriented) or lead with a not-so-clear goal in mind. At least I used to do it in that way.Not an easy journey, but I can promise you it is worth it.
AsMark Dalgleishonce tweeted:Be ready for what the user needsFocusing on what the user needs pulls away most of the overprint of any API: What is the userintentionwhen asking for a particular action to happen?An Intent represents a user intention of performing an action that solves a clear use case.Continuing with the metaphor presented in the previous paragraph, notice that my only intention was tobuy groceries for dinner. In particular, I needed some avocados, tomatoes and a baguette.The supermarket should provide a mechanism that lets me buy those items. How to get those, it's just the implementation detail and can be up to each supermarket to decide how to do it.For example, my supermarket had shelves where customers can pick up fruits from, offers bags, a balance to know the weight of those, and a checkout place. However, after the last changes, fruits are weighted at checkout, and baguettes are no longer on the shelf. So you need to ask the baker.As you can see, the interface didn't change: I still can buy the groceries. However, the implementation completely changed.Building APIs based on the implementation detail will nothing less than lead your users to suffer the (not-so-good) design choices made in the past. Furthermore, each change you make will penalize the user experience and force them to upgrade their code.Let's pick up another example, this time a more practical one.Here is a modified version of theStreetlights tutorialdocument made for demo purposes:1asyncapi:'2.0.0'2info:3title:StreetlightsmodAPI4version:'1.0.0-alpha'5servers:6mosquitto:7url:mqtt://test.mosquitto.org8protocol:mqtt9channels:10light/measured/changed:11subscribe:12summary:Receiveanupdateeverytimealightingconditionchanged.13operationId:onLightMeasureChanged14message:15$ref:"#/components/messages/lightMessage"16components:17messages:18lightMessage:19payload:20type:object21properties:22id:23type:integer24minimum:025description:Idofthestreetlight.26lumens:27type:integer28minimum:029description:Lightintensitymeasuredinlumens.By the time of this post, there is only one implementation of the parser, which is written in JavaScript.Parser-jsparses AsyncAPI spec documents and provides functions to work with them and access the different objects and their values.In the hypothetical case a user wants to parse this document andget all the messages a consumer of the application can consume, this is needed:doc.channels().filter(c=> c.hasSubscribe()).map(c=> c.subscribe().messages()).flat();We can observe that theParser-jsAPI (v1.x) is completely coupled with the structure of the AsyncAPI spec (by the date of this post,v2.0.0) document. The API is just a layer on top of the JSON Schema parsed document with some helpers and extras, meaning you should know the document's structure to access any information.Let's emulate a possible breaking change.Imaginemessagesare now independent of channels andOperationsget moved from where they used to be (under the channel) to the root of the document. For instance:1asyncapi:'99.99.99'2# ...3operations:4onLightMeasureChanged:5operationType:subscribe6summary:Receiveanupdateeverytimealightingconditionchanged.7message:8$ref:"#/messages/lightMessage"9channel:10$ref:"#/channels/light/measured"11channels:12light/measured:13description:Channelforupdatesonlightningconditions.14messages:15lightMessage:16# ...Now the users of theParser-jsthat wanted toget all the messages a consumer of the application can consumewill need to change their code so their app keeps working after thebreaking changegot introduced. For instance:doc.operations().filter(o=> o.isSubscribe()).map(o=> o.message()).flat();Intent-driven design to the rescueWhat if I tell you that you could avoid most of the breaking changes on your APIs by following an Intent-driven design approach?Let's give a twist to the API by adding some user intents. In this particular case, a method that represents the intent:clientSubscribableMessages(): Message[]Some naming clarification:client: user wants to get messages from the point of view of a client/consumer of the application.subscribable: user wants to get the messages they can consume.It looks simple, right? We have just written down our first intent!🎉From now on, users won't need to know in detail how the spec document is structured. The parser will reflect any change on the underlying document inside each function instead. Therefore,doc.clientPublishableMessages();willalwaysbe available as a method: it makes complete sense from a business model point of view for the AsyncAPI project.New versions of the library will be out, but those will mostly be minor or patch versions, adding new features, or fixing bugs. Meaning the users will follow a fearless and simple upgrade process.This approach also sets the foundations for creating backward compatibility APIs, among other features. For example, you can support several versions by executing one or another logic inside your intent functions.Designing a unified Intent-driven API for all AsyncAPI's parsersThe idea behind the Intent-driven design approach is to first focus on getting what the user intents are by getting feedback from final users as much as possible. Sometimes users are nothing else than other libraries, so go and check how they use your API.Our goal was to design an API that could be implemented in any language, meaning others could create their parser but always following this API. For example, theParser-go.Here is a summary of the steps we followed:1. Identify how users use the libraryWe first focused on identifying the intents behind ourgenerator templates. By doing some code analysis, we came out witha listofpotentialintents that became the foundation of our API.Furthermore, we tried to think about potential users of the parsers. For example,Slackdevelopers could use the parser for adding documentation to their UI, validating messages, among others.That gave us another list ofpotentialintents, most of them already covered by the list we got from the templates.2. Transform potential intents to actual intentsIt is an important step, if not the most. It is one of the hardest as well.For this step, we tried to abstract our minds and forget most of what we knew about the structure of an AsyncAPI document. We instead focused on the models and theirlogical(from a human point of view) relationship:Messages flow through ChannelsMessages can exist without channels.Messages can be (or not) related to OperationsEtcWe then wrote down a draft of our first list of intents.3. Build a mock APIAfter getting a list of intents to implement, we built a simple mock API in JavaScript with that list.Methods were returning hardcoded data but were enough for getting an idea of how difficult it would be to create such API from the point of view of a maintainer.At this point, we faced up some API design decisions, such as:Shall we add getters for all properties?Are we going to use singular or plural methods?Are methods going to have any argument at all?Etc4. Validate the intents and their UXWith the new API mock built-in JavaScript, we chose some of the most usedgenerator templatesand replaced all the calls made to the oldParser-jsAPI with the new ones.This step made us realize that some of the intents we mocked up worked like a charm: We were pretty happy seeing how the code got simplified.However, we found some inconsistencies, such as missing intents and helpers required for simplicity purposes.5. Wrap up documentationThis step included writing down all our documentation around the new API in a new repository, where developers of AsyncAPI parsers will refer and follow the specification of the API.Even though each parser will now maintain an individual release cycle, changes to this API will force the individual parsers to update.It followsSemver(as we do for all projects), so each parser will therefore maintain its compatibility matrix, making visible what version of the API specification they support.You can find the new repository holding the new Parsers API specificationhere, which at the moment of writing this post, it's stillv1.0.0-alpha, as we are waiting for more feedback from the community.What's next?Even though we do now have an alpha version of the new parser API, work is pending around implementation.
We are actively asking for feedback. Please submit yours via GitHub Discussionshere.Our next steps are going to be:To release a new version (alpha) of theParser-jsthat implements the new API specification.To use that newParser-jsversion in some of thegenerator templates. That will help us to:Validate that theParser-jsbehaves as expected.Set an example of what kind of changes users will need to do on their codes to adopt the new API (We expect code will require no significant changes).To ask for feedback from the community, especially to maintainers and users of theParser-js. Reviewing the new API now becomes easier as there will be the specification, a new version of theParser-jsand also examples to follow.Review feedback, apply suggestions, and do release a release-candidate or final version.Related issues and linksPlease find the outstanding issues related to the design process we went through here:Main issue for the API design processCollecting potential intentsEmulating few breaking changesFiguring out how to do API versioningThe new Parser(s) API specification can be foundhere. Discussions take placehere.ConclusionIntent-driven design helps to better understand your users by focusing on their intentions rather than technical details.It is not an easy path in the short term; however, the benefits can be visible early, making the process a grateful experience.I firmly believe making a great user experience should always be a top priority, especially for publicly available projects. If we don't care about users then, who is going to use our software?I want to take this opportunity to express my gratitude toJonas Lagoni, who has been my partner along this journey.
Hours of figuring out small details, long backs and forths, and discussions around user experience were easy-going, thanks to this one.I hope you enjoyed reading this post as much as I did writing it😃Cover photo byKarolina GrabowskaonKaboompics
"""
--------------------------------------------------------------------------------


Post 87
ID: https://www.asyncapi.com/blog/publish-subscribe-semantics?utm_source=rss
Title: Demystifying the Semantics of Publish and Subscribe
Link: https://www.asyncapi.com/blog/publish-subscribe-semantics?utm_source=rss
Summary: Learn how to interpret publish and subscribe operations when reading an AsyncAPI specification, and why they might not mean what you expect.
Content:
"""
This post originally appeared onIBM Integration CommunityAs adoption of AsyncAPI increases, a frequent topic of conversation in the community is how to describepublishandsubscribesemantics - both now and in future versions of the specification.In this blog post I aim to introduce the discussion and set you on the right path to document your event driven APIs.Or in other words, what code would you expect to be generated for the publish operation in the following AsyncAPI document?1asyncapi:2.0.02info:3title:MyApplication4version:1.05servers:6bootstrap:7url:mybroker.com:35148protocol:kafka9channels:10myChannel:11publish:12message:13payload:14type:stringIf you would be surprised to hear that this would result in a Kafka Consumer, then you should keep reading!In the beginningAsyncAPI started as an adaptation of OpenAPI - which describes synchronousrequest/responsebased APIs. In an OpenAPI world, you describe the application from the perspective of the client. Or in other words, the OpenAPI document describes how a client should interact with your application. The client and server communicate directly with each other.You document that a GET endpoint exists to access data, a POST endpoint exists to create data, etc. In all cases, a client speaks to the application (server) that is serving these endpoints.If you were implementing an application to honour the contract described in an OpenAPI document, you know to build route handlers that provide the documented endpoints for clients to access.Callbacks and webhooks are asynchronous operations, but in OpenAPI they are still described from the perspective of the client – the client has to initiate/register with the server before the server will push data to the client.What about AsyncAPI?In an event driven architecture there is no client/server paradigm. Applications do not directly communicate with one another - instead, each application sends and receives events via communication channels provided by s messaging infrastructure such as a broker. The broker ensures that events sent to a channel are delivered to interested applications. It can be consideredfire and forget- an application sends an event, but does not have any interest in whether other applications receive or make use of the event.AsyncAPI approaches this by describing an application as having two potential roles:If it sends messages to a channel, it's a “Publisher".If it is interested in receiving messages from a channel, it is a “Subscriber".An application can have either one or both roles.What does the following AsyncAPI document describe?1asyncapi:2.0.02info:3title:MyApplication4version:1.05servers:6bootstrap:7url:mybroker.com:35148protocol:kafka9channels:10myChannel:11publish:12message:13payload:14type:stringIsMy Applicationa Publisher or a Subscriber?Answer... it's a Subscriber!Like with OpenAPI, an AsyncAPI documents an application from theclientperspective. For a client to interact withMy Application, it must publish an event to the myChannel channel on the Kafka broker hosted at mybroker.com:3514The exception to the rule is websockets - there is a client/server paradigm rather than a messaging infrastructure - so other applications will connect directly to the server. However, the semantics remain the same - you describe the server as an application from theclientperspective.See Lukasz's previous article for more details.Where's the confusion?An AsyncAPI document can have multiple purposes. It can act as documentation for other developers to understand how to interact with the API. It can also act as documentation for developers to implement the API.In OpenAPI, there is no ambiguity - if you implement the API your server must listen for incoming requests on the documented endpoints, and any clients know to make requests to the documented endpoints. A GET endpoint means the same thing to both client and server.In AsyncAPI, the confusion has arisen because applications can both publish and subscribe - soverbs become interchangeable depending on the perspective of the person reading the document.When describing your architecture - a collection of applications communicating via channels - it can feel more familiar to describe what each application is doing (it publishes eventxto channelaand subscribes to events from channelb).Conversely, if you are intending on socialising your asynchronous API for use by other developers - it is a more familiar paradigm to describe how external developers can interact with the API. Ultimately, that was the decision for v2.0.0 of the AsyncAPI specification.What does this mean for using the spec?TheAsyncAPI generator projectis designed to facilitate generation of various assets from an AsyncAPI document - including sample or mock applications. The application generators are primarily written to interpret the API as detailed in this blog post - so apublishwill generate a Kafka consumer. However, some of the templates have added support for interpreting the document so that apublishgenerates a Kafka producer.Java Spring Cloud Stream templateuses the parameterview=provider- (providerinterprets the AsyncAPI document as describing the behaviours the applicationprovides)Java Spring templateuse the parameterinverseOperations=trueSummaryAsyncAPI documents describe applications. When reading an AsyncAPI document:publishmeanspublish an event to the channel and this application will receive itsubscribemeanssubscribe to this channel to receive events published by this applicationThere is aGitHub issueraised for discussing these semantics moving forward into the next version of the AsyncAPI specification - please do get involved with the discussion!
"""
--------------------------------------------------------------------------------


Post 88
ID: https://www.asyncapi.com/blog/websocket-part2?utm_source=rss
Title: Creating AsyncAPI for WebSocket API - Step by Step
Link: https://www.asyncapi.com/blog/websocket-part2?utm_source=rss
Summary: Learn how to create a complex AsyncAPI document using WebSocket API as an example.
Content:
"""
This step-by-step guide is a continuation of a series of articles about WebSockets. I recommend readingWebSocket, Shrek, and AsyncAPI - An Opinionated Introfirst.If you do not want to read this article, then watch the recording of the live stream about the same:All roads lead to Rome, but all those roads are different. First, you need to identify where you are and what is the purpose of your journey. What is your goal? What do you want to use AsyncAPI for?You may invest in using the specification for many different reasons, like for example:documentationtestingmockingcode generationmessage validationDepending on your goal, you might need to take different roads to get there. If your only goal is documentation, you might take a different approach to writing an AsyncAPI file than you would take while thinking about code generation.Choosing the right road to RomeLet's say AsyncAPI does not fully cover your use case. You are missing some extra property. You are disappointed that you cannot explicitly provide information that your production servers both support different channels. Server A supports channel AA and AB, while Server B supports channel BA and BB. It is not currently possible with the specification as the assumption is that your application communicates with servers that support the same channels.There are two roads to Rome:Roaddocs-only: You need AsyncAPI for docs generation only and have no intention of sharing the source document with anyone. It means you do not need to bother much about inventing some specification extension. You can just add missing information to the description of a given object.Roadautomation: You need AsyncAPI for docs and code generation, which means that all details in your AsyncAPI document must be machine-readable. You can't just put unsupported information in the description.Kraken API use caseI'm going to guide you through the process of creating an AsyncAPI document. I'll use the example of Kraken API mentioned in myprevious article.The challenge I had here was that I'm trying to document an API basing on public docs with no access to a subject matter expert. I also have zero understanding of the cryptocurrency industry and still do not fully understand the vocabulary.Message to Kraken API developers and technical writersIn case you want to continue the work I started on the AsyncAPI document for Kraken API, feel free to do that. I'm happy to help, just let me know. Reach me out in ourAsyncAPI Slack workspace.More interesting here are the technical challenges though, caused by the fact that Kraken's API:has two production servers for non-secure and secure message exchangesome messages are supported only by the public and some only by a private serverhas just one entry point for communication. You do not get specific messages from one of many endpoints. You get specific messages after first sending a subscription message. Meaning you have a request message and you get a reply message, so something that is not yet possible to describe with AsyncAPI in a machine-readable wayWriting a single AsyncAPI documentBecause of all these different challenges, I took thedocs-onlyroad described in sectionChoosing the right road to Rome. No worries though, I give tips for theautomationroad too.Basic information about the APIFirst, provide some basic information that every good AsyncAPI file should have:What AsyncAPI version do you use?What is the name of your API?What version of the API you describe?Do not underestimate the description. Optional != not needed. AsyncAPI supports markdown in descriptions. Provide long generic documentation for your API. Benefit from markdown features to structure it, so it is easier to readIn case you think using just one property to add overarching documentation for your API is very limiting, I agree with you😃Join discussionhere. I believe spec should have better support for docs, and we should first explore it with specification extensions. To be honest, I always thought documentation deserves its specification, but I don't want to bother you with my wicked visions now.1asyncapi:2.0.02info:3title:KrakenWebsocketsAPI4version:'1.8'5description:|6WebSockets API offers real-time market data updates. WebSockets is a bidirectional protocol offering fastest real-time data, helping you build real-time applications. The public message types presented below do not require authentication. Private-data messages can be subscribed on a separate authenticated endpoint.78### General Considerations910-TLSwithSNI(ServerNameIndication)isrequiredinordertoestablishaKrakenWebSocketsAPIconnection.SeeCloudflare's[WhatisSNI?](https://www.cloudflare.com/learning/ssl/what-is-sni/)guideformoredetails.11-AllmessagessentandreceivedviaWebSocketsareencodedinJSONformat.12-Alldecimalfields(includingtimestamps)arequotedtopreserveprecision.13-TimestampsshouldnotbeconsidereduniqueandnotbeconsideredasaliasesfortransactionIDs.Also,thegranularityoftimestampsisnotrepresentativeoftransactionrates.14-Atleastoneprivatemessageshouldbesubscribedtokeeptheauthenticatedclientconnectionopen.15-PleaseuseRESTAPIendpoint[AssetPairs](https://www.kraken.com/features/api#get-tradable-pairs)tofetchthelistofpairswhichcanbesubscribedviaWebSocketsAPI.Forexample,field'wsname'givesthesupportedpairsnamewhichcanbeusedtosubscribe.16-Cloudflareimposesaconnection/re-connectionratelimit(perIPaddress)ofapproximately150attemptsperrolling10minutes.Ifthisisexceeded,theIPisbannedfor10minutes.17-Recommendedreconnectionbehaviouristo(1)attemptreconnectioninstantlyuptoahandfuloftimesifthewebsocketisdroppedrandomlyduringnormaloperationbut(2)aftermaintenanceorextendeddowntime,attempttoreconnectnomorequicklythanonceevery5seconds.Thereisnoadvantagetoreconnectingmorerapidlyaftermaintenanceduringcancel_onlymode.Provide server informationDescribe how to connect to the API:What is the URL of the server?Is there any authorization in place?What is the protocol requirement, is SSL connection required?The Kraken API is an excellent example of how different WebSocket implementations can be and that there is never one way to design your architecture. It all depends on your requirements, the use cases that drive your product.Describing multiple serversBelow you can notice two different servers. These are not, as you might think, production and development servers. Here you have a clear division between publicly available data and private-only data. In other words, users use two different servers, not channels/paths/endpoints, to talk to the API.1servers:2public:3url:ws.kraken.com4protocol:wss5description:|6Public server available without authorization.7Once the socket is open you can subscribe to a public channel by sending a subscribe request message.8private:9url:ws-auth.kraken.com10protocol:wss11description:|12Private server that requires authorization.13Once the socket is open you can subscribe to private-data channels by sending an authenticated subscribe request message.You can verify if above is true by connecting tows.kraken.comand trying to subscribe to one of the event streams that require a token:{"event":"subscribe","subscription": {"name":"ownTrades","token":"WW91ciBhdXRoZW50aWNhdGlvbiB0b2tlbiBnb2VzIGhlcmUu"} }In response you get an error:{"errorMessage":"Private data and trading are unavailable on this endpoint. Try ws-auth.kraken.com","event":"subscriptionStatus","status":"error","subscription":{"name":"ownTrades","token":"WW91ciBhdXRoZW50aWNhdGlvbiB0b2tlbiBnb2VzIGhlcmUu"}}In the documentation, they also indicate beta servers likebeta-ws.kraken.com. It is hard to understand their purpose, so I did not put them in the AsyncAPI document. For me, beta means something new, some upgrades, and I would consider writing a separate AsyncAPI document.Is it reasonable to describe API that has two different production servers in one AsyncAPI? As usual, it depends. Fordocs-onlyroad described in sectionChoosing the right road to Rome, you can "workaround" some AsyncAPI features if they do not support your use case. Check out, for example, what I had to do in sectionServer securitywhere I was not sure how to describe the specific security of the private server. Short answer: just extend the description.Forautomationroad described inChoosing the right road to Romesection, you need a machine-readable structure. In case you have messages that can be consumed only by theprivateserver, you need a way to specify that the given message can be published only to theprivateserver. It is exactly the case with Kraken API.Imagine you want to read the AsyncAPI document in real-time in your server and validate all incoming messages. Take serverws.kraken.com. The only way to emit errors likePrivate data and trading are unavailable on this endpoint. Try ws-auth.kraken.comis by writing the code that handles validation manually. You can't generate that as the AsyncAPI file does not specify what messages can go tows.kraken.comand what messages can't.Why?At the moment, in AsyncAPI, you don't have a way to "wire" a server with a message, operation, or a channel. There are no default properties that allow you to provide information that message with the nameownTradescan only be sent tows-auth.kraken.comserver.Solution?Create two AsyncAPI documents. Treat those two servers as separate services that share messages and schemas. Use$reffeature tocross-reference schemas.Server securityYou can use AsyncAPI also to describe the security of your API. You can describe in a machine-readable way the security mechanism that protects the server. Severalsecurity schemesare supported. In Kraken's case, I could not figure out what kind of security scheme they use from their docs.  They seem to have a non-standard set up for getting the authorization token, which is why the only option was to put a human-readable-only description there.1servers:2public:3url:ws.kraken.com4protocol:wss5description:|6Public server available without authorization.7Once the socket is open, you can subscribe to a public channel by sending a subscribe request message.8private:9url:ws-auth.kraken.com10protocol:wss11description:|12Private server that requires authorization.13Once the socket is open, you can subscribe to private-data channels by sending an authenticated subscribe request message.1415TheAPIclientmustrequestanauthentication"token"viathefollowingRESTAPIendpoint"GetWebSocketsToken"toconnecttoWebSocketsPrivateendpoints.Formoredetails,readhttps://support.kraken.com/hc/en-us/articles/360034437672-How-to-retrieve-a-WebSocket-authentication-token-Example-code-in-Python-31617Theresultingtokenmustbeprovidedinthe"token"field of any new private WebSocket feed subscription:18```19{20"event":"subscribe",21"subscription":22{23"name":"ownTrades",24"token":"WW91ciBhdXRoZW50aWNhdGlvbiB0b2tlbiBnb2VzIGhlcmUu"25}26}27```Endpoints aka ChannelsI saw WebSocket APIs that provide different streams of messages on separate endpoints. It is often the case when you build the WebSocket API for the frontend only and design it for different UI views. In the case of Kraken API we have no endpoints. You connect to the root of the server.No matter what setup you have, just remember you should usechannelsto describe it. In the case of connecting to the root, it is as simple as:1channels:2/:Multiple different messages on the same channelYou can have one or many different messages coming to your channel. Like in the case of Kraken API, you can even have multiple messages, incoming and outgoing. You can describe it usingoneOfonmessageobject as you can see below:1channels:2/:3publish:4operationId:sendMessage5message:6oneOf:7-$ref:'#/components/messages/ping'8-$ref:'#/components/messages/subscribe'9-$ref:'#/components/messages/unsubscribe'10subscribe:11operationId:processMessage12message:13oneOf:14-$ref:'#/components/messages/pong'15-$ref:'#/components/messages/heartbeat'16-$ref:'#/components/messages/systemStatus'17-$ref:'#/components/messages/subscriptionStatus'Hold on! Where did thesepublishandsubscribekeywords came from.When we talk about WebSocket, we usually do not use words like subscribe and publish, as we do not think about producers and consumers. Just check outthe protocol RfC. We are used tosendingandreceivingmessages.Let me present to you an unofficial AsyncAPI vocabulary translator for WebSocket users😃WebSocket termAsyncAPI termMeaning from API server perspectiveMeaning from API user perspectiveSendPublishThe API server receives the given message.The API user can send a given message to the API server.ReceiveSubscribeThe API server sends a given message.The API user can receive a given message from the API server.Messages definitionIn event-driven architectures (EDA) it's all about the event, right? The message passed in the system. You need to specify many details about the message, like its payload structure, headers, purpose, and many others.Above all, always remember to have good examples. Please don't count on the autogenerated ones, as in most cases, they're useless.1messages:2systemStatus:3description:Status sent on connection or system status changes.4payload:5$ref:'#/components/schemas/systemStatus'6examples:7- payload:8connectionID:86286153908486100009event:systemStatus10status:online11version:1.0.0Describe responses - specification extensionsDescribe responses? What responses?It is EDA. Who cares about responses, right? Fire and forget rules!The thing is that request and reply pattern is also used in EDA. This is also the case with Kraken API where communication goes through a single channel with multiple different messages. One message triggers another message in response.The simplest example is the messagepingthat triggers apongreply. The current AsyncAPI limitation is that you cannot specify that once the user sends (publish) messageping, thepongmessage is received in a reply. Look at thisthreadto participate in an ongoing discussion about request/reply pattern support in AsyncAPI.Fordocs-onlyroad from sectionChoosing the right road to Rome, I would be lazy and just put such info in the description of both messages. Even though this is an error-prone approach, I would just make my life easier. Forautomationroad I would choose to use a specification extension.What is specification extension?You can extend every AsyncAPI object in the AsyncAPI document with extra properties. You only need to prefix them withx-. You can also share extensions or reuse extensions from others thanks toextensions catalog.In the below document, you will notice that for the request/reply pattern, I use AsyncAPI specification extensions calledx-response.1messages:2ping:3summary: Pingservertodetermine whetherconnectionisalive4description: Client can pingservertodetermine whetherconnectionisalive,serverrespondswithpong. Thisisan applicationlevelpingasopposedtodefaultpinginwebsockets standard whichisserverinitiated5payload:6$ref:'#/components/schemas/ping'7x-response:8$ref:'#/components/messages/pong'Even though the reference to another object is provided inside the extension that is not part of AsyncAPI, our parser will resolve it correctly. It means that underx-responseproperty, I will have access to the entire message object.Schemas vs JSON SchemaBecause the message itself is most important in the entire EDA, you need to describe the message payload properly.AsyncAPI allows you to provide payload information in different schema formats. The default format is AsyncAPI Schema that is a superset of JSON Schema. You can use others too, like Avro, for example.From the AsyncAPI document point of view, the most important is that you can reuse schemas. In other words, instead of providing data directly to thepayloadobject, you can$refthem fromcomponents.schemasor even an external document. Just DRY, right?The rest, I would say, has nothing to do with AsyncAPI itself. How you structure schemas depends on you and the schema format that you use. It is why the next sections of my article describe something specific, not for the AsyncAPI itself but rather JSON Schema.Simplest example of schemas from Kraken API is a payload forpingmessage:1schemas:2ping:3type:object4properties:5event:6type:string7const:ping8reqid:9$ref:'#/components/schemas/reqid'10required:11- event12reqid:13type:integer14description:client originated ID reflected in response message.You can see thatpingmessage is an object that has two properties where only one is required. One property is used across other messages, so is part of many different schemas, so better to keep its definition as a separate schema and reference where needed.Schemas complexitySplitting schemas into reusable chunks with$refusage is not something complex. It gets complex when messages are complex, when you get different message payload depending on system behavior.Kraken API has asubscriptionStatusmessage where payload depends on the success of the subscription. In case of successful subscription, you get a message withchannelIDandchannelNameproperties, but in case of failure, the message doesn't contain these properties but in exchange haserrorMessage. In other words, some properties are mutually exclusive.1subscriptionStatus:2type:object3oneOf:4- required:5- errorMessage6not:7required:8- channelID9- channelName10- required:11- channelID12- channelName13not:14required:15- errorMessage16properties:17channelID:18type:integer19description:ChannelID on successful subscription, applicable to public messages only.20channelName:21type:string22description:Channel Name on successful subscription. For payloads'ohlc'and'book', respective interval or depth will be added as suffix.23errorMessage:24type:string25event:26type:string27const:subscriptionStatus28reqid:29$ref:'#/components/schemas/reqid'30pair:31$ref:'#/components/schemas/pair'32status:33$ref:'#/components/schemas/status'34subscription:35type:object36properties:37depth:38$ref:'#/components/schemas/depth'39interval:40$ref:'#/components/schemas/interval'41maxratecount:42$ref:'#/components/schemas/maxratecount'43name:44$ref:'#/components/schemas/name'45token:46$ref:'#/components/schemas/token'47required:48- name49required:50- eventIt is what I call a complex schema, where good JSON Schema knowledge is needed. The problem with complex schemas is that not many tools support these kinds of schemas. By the time I write this article, our AsyncAPI tools for documentation rendering will fail to render the above schema correctly.It is why you sometimes need compromises and adjusts schemas, so they get proper tooling support. Below you can see the same schema but structured in a more straightforward way supported by most tools.1subscriptionStatus:2type:object3oneOf:4- $ref:'#/components/schemas/subscriptionStatusError'5- $ref:'#/components/schemas/subscriptionStatusSuccess'6subscriptionStatusError:7allOf:8- properties:9errorMessage:10type: string11required:12- errorMessage13- $ref:'#/components/schemas/subscriptionStatusCommon'14subscriptionStatusSuccess:15allOf:16- properties:17channelID:18type:integer19description: ChannelIDonsuccessfulsubscription, applicabletopublicmessagesonly.20channelName:21type: string22description: ChannelNameonsuccessfulsubscription.Forpayloads'ohlc'and'book', respectiveintervalordepth will be addedassuffix.23required:24- channelID25- channelName26- $ref:'#/components/schemas/subscriptionStatusCommon'27subscriptionStatusCommon:28type:object29required:30- event31properties:32event:33type: string34const: subscriptionStatus35reqid:36$ref:'#/components/schemas/reqid'37pair:38$ref:'#/components/schemas/pair'39status:40$ref:'#/components/schemas/status'41subscription:42required:43-name44type:object45properties:46depth:47$ref:'#/components/schemas/depth'48interval:49$ref:'#/components/schemas/interval'50maxratecount:51$ref:'#/components/schemas/maxratecount'52name:53$ref:'#/components/schemas/name'54token:55$ref:'#/components/schemas/token'I managed to get a structure that will be nicely rendered in the UI. Even code generation will work well. It is a bit more complex than initial structure, although this is rather subjective personal-taste-like opinion.Let's have a look at the final documentWebsocket protocol is very flexible, and therefore you can implement the server in many different ways. The path that Kraken API took is complex but not impossible to describe with the AsyncAPI document. Look at the document's final structure and keep in mind that it is not a complete document for Kraken API and the road that I chose to get to Rome was to focus on documentation rendering only.Forautomationroad described in sectionChoosing the right road to Rome, the document should be split into two documents: one for private and one for public servers. Common parts, like common messages and schemas, should be stored in separate files and referred from these two AsyncAPI documents using$ref. Another solution would be to use specification extensions to describe relations between messages and servers.You can open this document directly in AsyncAPI Studio by clickingthislink. Compare it also with theoriginal documentation.1asyncapi:2.0.023info:4title:KrakenWebsocketsAPI5version:'1.8.0'6description:|7WebSockets API offers real-time market data updates. WebSockets is a bidirectional protocol offering fastest real-time data, helping you build real-time applications. The public message types presented below do not require authentication. Private-data messages can be subscribed on a separate authenticated endpoint.89### General Considerations1011-TLSwithSNI(ServerNameIndication)isrequiredinordertoestablishaKrakenWebSocketsAPIconnection.SeeCloudflare's[WhatisSNI?](https://www.cloudflare.com/learning/ssl/what-is-sni/)guideformoredetails.12-AllmessagessentandreceivedviaWebSocketsareencodedinJSONformat13-Alldecimalfields(includingtimestamps)arequotedtopreserveprecision.14-TimestampsshouldnotbeconsidereduniqueandnotbeconsideredasaliasesfortransactionIDs.Also,thegranularityoftimestampsisnotrepresentativeoftransactionrates.15-Atleastoneprivatemessageshouldbesubscribedtokeeptheauthenticatedclientconnectionopen.16-PleaseuseRESTAPIendpoint[AssetPairs](https://www.kraken.com/features/api#get-tradable-pairs)tofetchthelistofpairswhichcanbesubscribedviaWebSocketsAPI.Forexample,field'wsname'givesthesupportedpairsnamewhichcanbeusedtosubscribe.17-Cloudflareimposesaconnection/re-connectionratelimit(perIPaddress)ofapproximately150attemptsperrolling10minutes.Ifthisisexceeded,theIPisbannedfor10minutes.18-Recommendedreconnectionbehaviouristo(1)attemptreconnectioninstantlyuptoahandfuloftimesifthewebsocketisdroppedrandomlyduringnormaloperationbut(2)aftermaintenanceorextendeddowntime,attempttoreconnectnomorequicklythanonceevery5seconds.Thereisnoadvantagetoreconnectingmorerapidlyaftermaintenanceduringcancel_onlymode.1920servers:21public:22url:ws.kraken.com23protocol:wss24description:|25Public server available without authorization.26Once the socket is open you can subscribe to a public channel by sending a subscribe request message.27private:28url:ws-auth.kraken.com29protocol:wss30description:|31Private server that requires authorization.32Once the socket is open you can subscribe to private-data channels by sending an authenticated subscribe request message.3334TheAPIclientmustrequestanauthentication"token"viathefollowingRESTAPIendpoint"GetWebSocketsToken"toconnecttoWebSocketsPrivateendpoints.Formoredetailsreadhttps://support.kraken.com/hc/en-us/articles/360034437672-How-to-retrieve-a-WebSocket-authentication-token-Example-code-in-Python-33536Theresultingtokenmustbeprovidedinthe"token"field of any new private WebSocket feed subscription:37```38{39"event":"subscribe",40"subscription":41{42"name":"ownTrades",43"token":"WW91ciBhdXRoZW50aWNhdGlvbiB0b2tlbiBnb2VzIGhlcmUu"44}45}46```4748channels:49/:50publish:51description:SendmessagestotheAPI52operationId:processReceivedMessage53message:54oneOf:55-$ref:'#/components/messages/ping'56-$ref:'#/components/messages/subscribe'57-$ref:'#/components/messages/unsubscribe'5859subscribe:60description:MessagesthatyoureceivefromtheAPI61operationId:sendMessage62message:63oneOf:64-$ref:'#/components/messages/pong'65-$ref:'#/components/messages/heartbeat'66-$ref:'#/components/messages/systemStatus'67-$ref:'#/components/messages/subscriptionStatus'6869components:70messages:71ping:72summary:Pingservertodeterminewhetherconnectionisalive73description:Clientcanpingservertodeterminewhetherconnectionisalive,serverrespondswithpong.Thisisanapplicationlevelpingasopposedtodefaultpinginwebsocketsstandardwhichisserverinitiated74payload:75$ref:'#/components/schemas/ping'76x-response:77$ref:'#/components/messages/pong'78heartbeat:79description:Serverheartbeatsentifnosubscriptiontrafficwithin1second(approximately)80payload:81$ref:'#/components/schemas/heartbeat'82pong:83summary:Pongisaresponsetopingmessage84description:Serverpongresponsetoapingtodeterminewhetherconnectionisalive.Thisisanapplicationlevelpongasopposedtodefaultponginwebsocketsstandardwhichissentbyclientinresponsetoaping85payload:86$ref:'#/components/schemas/pong'87systemStatus:88description:Statussentonconnectionorsystemstatuschanges.89payload:90$ref:'#/components/schemas/systemStatus'91examples:92-payload:93connectionID:862861539084861000094event:systemStatus95status:online96version:1.0.097subscribe:98description:Subscribetoatopiconasingleormultiplecurrencypairs.99payload:100$ref:'#/components/schemas/subscribe'101examples:102-payload:103event:subscribe104pair:105-XBT/USD106-XBT/EUR107subscription:108name:ticker109-payload:110event:subscribe111subscription:112name:ownTrades113token:WW91ciBhdXRoZW50aWNhdGlvbiB0b2tlbiBnb2VzIGhlcmUu114x-response:115$ref:'#/components/messages/subscriptionStatus'116unsubscribe:117description:Unsubscribe,canspecifyachannelIDormultiplecurrencypairs.118payload:119$ref:'#/components/schemas/subscribe'120examples:121-payload:122event:unsubscribe123pair:124-XBT/EUR125-XBT/USD126subscription:127name:ticker128-payload:129event:unsubscribe130subscription:131name:ownTrades132token:WW91ciBhdXRoZW50aWNhdGlvbiB0b2tlbiBnb2VzIGhlcmUu133x-response:134$ref:'#/components/messages/subscriptionStatus'135subscriptionStatus:136description:Subscriptionstatusresponsetosubscribe,unsubscribeorexchangeinitiatedunsubscribe.137payload:138$ref:'#/components/schemas/subscriptionStatus'139examples:140-payload:141channelID:10001142channelName:ohlc-5143event:subscriptionStatus144pair:XBT/EUR145reqid:42146status:unsubscribed147subscription:148interval:5149name:ohlc150-payload:151errorMessage:Subscriptiondepthnotsupported152event:subscriptionStatus153pair:XBT/USD154status:error155subscription:156depth:42157name:book158159schemas:160ping:161type:object162properties:163event:164type:string165const:ping166reqid:167$ref:'#/components/schemas/reqid'168required:169-event170heartbeat:171type:object172properties:173event:174type:string175const:heartbeat176pong:177type:object178properties:179event:180type:string181const:pong182reqid:183$ref:'#/components/schemas/reqid'184systemStatus:185type:object186properties:187event:188type:string189const:systemStatus190connectionID:191type:integer192description:TheIDoftheconnection193status:194$ref:'#/components/schemas/status'195version:196type:string197status:198type:string199enum:200-online201-maintenance202-cancel_only203-limit_only204-post_only205subscribe:206type:object207properties:208event:209type:string210const:subscribe211reqid:212$ref:'#/components/schemas/reqid'213pair:214$ref:'#/components/schemas/pair'215subscription:216type:object217properties:218depth:219$ref:'#/components/schemas/depth'220interval:221$ref:'#/components/schemas/interval'222name:223$ref:'#/components/schemas/name'224ratecounter:225$ref:'#/components/schemas/ratecounter'226snapshot:227$ref:'#/components/schemas/snapshot'228token:229$ref:'#/components/schemas/token'230required:231-name232required:233-event234unsubscribe:235type:object236properties:237event:238type:string239const:unsubscribe240reqid:241$ref:'#/components/schemas/reqid'242pair:243$ref:'#/components/schemas/pair'244subscription:245type:object246properties:247depth:248$ref:'#/components/schemas/depth'249interval:250$ref:'#/components/schemas/interval'251name:252$ref:'#/components/schemas/name'253token:254$ref:'#/components/schemas/token'255required:256-name257required:258-event259subscriptionStatus:260type:object261oneOf:262-$ref:'#/components/schemas/subscriptionStatusError'263-$ref:'#/components/schemas/subscriptionStatusSuccess'264subscriptionStatusError:265allOf:266-properties:267errorMessage:268type:string269required:270-errorMessage271-$ref:'#/components/schemas/subscriptionStatusCommon'272subscriptionStatusSuccess:273allOf:274-properties:275channelID:276type:integer277description:ChannelIDonsuccessfulsubscription,applicabletopublicmessagesonly.278channelName:279type:string280description:ChannelNameonsuccessfulsubscription.Forpayloads'ohlc'and'book',respectiveintervalordepthwillbeaddedassuffix.281required:282-channelID283-channelName284-$ref:'#/components/schemas/subscriptionStatusCommon'285subscriptionStatusCommon:286type:object287required:288-event289properties:290event:291type:string292const:subscriptionStatus293reqid:294$ref:'#/components/schemas/reqid'295pair:296$ref:'#/components/schemas/pair'297status:298$ref:'#/components/schemas/status'299subscription:300required:301-name302type:object303properties:304depth:305$ref:'#/components/schemas/depth'306interval:307$ref:'#/components/schemas/interval'308maxratecount:309$ref:'#/components/schemas/maxratecount'310name:311$ref:'#/components/schemas/name'312token:313$ref:'#/components/schemas/token'314interval:315type:integer316description:Timeintervalassociatedwithohlcsubscriptioninminutes.317default:1318enum:319-1320-5321-15322-30323-60324-240325-1440326-10080327-21600328name:329type:string330description:Thenameofthechannelyousubscribetoo.331enum:332-book333-ohlc334-openOrders335-ownTrades336-spread337-ticker338-trade339token:340type:string341description:base64-encodedauthenticationtokenforprivate-dataendpoints.342depth:343type:integer344default:10345enum:346-10347-25348-100349-500350-1000351description:Depthassociatedwithbooksubscriptioninnumberoflevelseachside.352maxratecount:353type:integer354description:Maxrate-limitbudget.ComparetotheratecounterfieldintheopenOrdersupdatestocheckwhetheryouareapproachingtheratelimit.355ratecounter:356type:boolean357default:false358description:Whethertosendrate-limitcounterinupdates(supportedonlyforopenOrderssubscriptions)359snapshot:360type:boolean361default:true362description:Whethertosendhistoricalfeeddatasnapshotuponsubscription(supportedonlyforownTradessubscriptions)363reqid:364type:integer365description:clientoriginatedIDreflectedinresponsemessage.366pair:367type:array368description:Arrayofcurrencypairs.369items:370type:string371description:Formatofeachpairis"A/B",whereAandBareISO4217-A3forstandardizedassetsandpopularuniquesymbolifnotstandardized.372pattern:'[A-Z\s]+\/[A-Z\s]+'Stay tuned for more articles around WebSocket and AsyncAPI. Share your feedback and connect with the AsyncAPI community in ourSlack workspace.
"""
--------------------------------------------------------------------------------


Post 89
ID: https://www.asyncapi.com/blog/websocket-part1?utm_source=rss
Title: WebSocket, Shrek, and AsyncAPI - An Opinionated Intro
Link: https://www.asyncapi.com/blog/websocket-part1?utm_source=rss
Summary: WebSocket is a protocol, an industry standard for building client applications that users love to use. What does AsyncAPI have to do with it?
Content:
"""
This is a pretty subjective post. I'm sharing my perspective, taking into account years of experience building backend and frontend with user experience in mind.If you do not want to read this article, then watch the recording of the live stream about the same:Everything we hear is an opinion, not a fact. Everything we see is a perspective, not the truth.
―Marcus AureliusThis blog post is the first of a series of blog posts about WebSocket I'm working on.What is WebSocketIt is a pretty old protocol used for duplex communication over TCP connection. It was standardized in 2011. Yes, ten years ago means it is old, super old.So why do I even mention it in 2021?It is very widely adopted and will not go away anytime soon because tooling support is excellent and serves its purpose well. Just remind yourself when HTTP/2 showed up and how many years it took everyone to migrate. It would not happen without the strong support and push from all the big players.Sure, there isHTTP/2 multiplexingand protocols likeMercureorGraphQL Subscription. There is alsoRFC8441for WebSocket and HTTP/2 and some tools already adopted it, likeEnvoyorJetty. Nevertheless, WebSocket is here to stay.Anyway, the future of WebSocket has nothing to do with this post. This post is for the AsyncAPI community looking into the AsyncAPI spec because of WebSockets now, no matter the protocol's future.Websocket use caseDo you like to see in Slack that someone is typing a response?Do you like it when a user interface updates without page refresh?Do you like it when your client app knows there are updates available for display?That is what WebSocket is for. You establish a long-living connection between client and server. Through such a connection, the client can send a stream of messages to the server, and this is possible the other way around at the same time.One could say:I don't need WebSocket to achieve that. I could just set up a data polling with REST API. Just ask the API every few seconds if there are updates.Sadly this is not a joke. Engineers do it. Some engineers just take shortcuts, mostly because deadlines hunt them down.HTTP polling was presented very well in Shrek's famousAre we there yet?scene.Don't go that path. Do not perform unnecessary connections to your servers and create more and more traffic with more and more resource consumption. Wasting resources is bad and makes Shrek angry. WebSocket changes a lot there:Figure 1: HTTP Pull vs WebSocket vs Shrek.Why AsyncAPIWhen building a WebSocket API on a server, you might have some additional needs:Want to document the API for the team that writes a client app, Web UI, Desktop app, or Mobile app.Want to have a way to specify the format of the messages that the server supports to validate them in the runtime.Want to generate a server or/and a client? If not for final production use, then for sure for prototyping and testing.These are just a few common needs. For WebSocket, you only establish a connection over HTTP protocol, and the rest goes over WS, so OpenAPI specification won't help you much here. WebSocket is one of the patterns in event-based systems. In the end, it is all about a stream of messages and asynchronous processing. Yes, it would be best to use AsyncAPI😃WebSocket described with AsyncAPIWhen I google for some public WebSocket API to play with, I find mostly currency trading products:Kraken WebSocket APIGemini WebSocket APICEXIO Websocket APICurrency trading is a topic I know nothing about🤷‍♂but it feels interesting to explore more. Documentation of the 1st and 2nd API looks familiar from look&feel perspective. I think we can make a bet they are already using AsyncAPI, and Kraken most probably is still running on version 1. Let's release the Kraken then.I'm sorry if you expected me to describe Shrek's API interface using AsyncAPI. It would be fun, but only fun, and I'd also like to teach you something.I will write an AsyncAPI document for Kraken API after playing with the API and basing it on thecurrent documentation.Playing with WebSocket APIThe best way to play with a WebSocket API is through a CLI. Who didn't hear aboutcurlin the REST API world? For WebSocket, I would recommendwebsocat. Kraken's API is partially public without authorization which is just great because to play with it, you do not have to set up an account to get an authorization token.Installwebsocat. For other installation options, check outthislist.brewinstallwebsocatEstablish connection with the API:websocatwss://ws.kraken.comPing the API to see if it responds. Just type the below message and hit Enter:{"event":"ping"}Now subscribe to the eventtickerstream that sends messages with currency price. Just type the below message and hit Enter:{"event":"subscribe","pair": ["XBT/USD","XBT/EUR"],"subscription": {"name":"ticker"}}You should now see a constant stream of data sent by the server. You do not have to ask the API every second for an update, as the update is pushed to you.1{"event":"heartbeat"}2[340,{"a":["45520.10000",6,"6.78103490"],"b":["45520.00000",0,"0.00185230"],"c":["45520.10000","0.01643250"],"v":["1397.95434819","5589.12101024"],"p":["44883.49461","44062.07654"],"t":[14350,66782],"l":["43607.60000","42770.80000"],"h":["45811.10000","45811.10000"],"o":["43659.30000","44709.10000"]},"ticker","XBT/EUR"]3[340,{"a":["45520.10000",5,"5.84803490"],"b":["45492.50000",0,"0.09374582"],"c":["45492.50000","0.00625418"],"v":["1398.10526819","5589.26685876"],"p":["44883.56109","44062.11477"],"t":[14359,66790],"l":["43607.60000","42770.80000"],"h":["45811.10000","45811.10000"],"o":["43659.30000","44709.10000"]},"ticker","XBT/EUR"]4{"event":"heartbeat"}5[340,{"a":["45503.80000",1,"1.00000000"],"b":["45496.20000",0,"0.01426600"],"c":["45496.20000","0.00109400"],"v":["1398.10636219","5589.26295766"],"p":["44883.56157","44062.11447"],"t":[14360,66788],"l":["43607.60000","42770.80000"],"h":["45811.10000","45811.10000"],"o":["43659.30000","44709.90000"]},"ticker","XBT/EUR"]6{"event":"heartbeat"}Boy, it is always such fun to do it. Like seriously, I always have fun playing with APIs, any APIs. Just making this API "conversation". I hope nothing is wrong with me😅Now you know how to interact with the Kraken API. Now let's try to describe it using AsyncAPI.Describing API using AsyncAPII'll explain, in detail, how to describe Websocket API with AsyncAPI in another blog post that will be part of the series. Why? I don't want to make this post super lengthy and discourage others from reading it. Let us learn step by step.For now, I will throw here a full AsyncAPI document I created for the Kraken API. You can also open it up in theAsyncAPI Studioand compare with theircurrent documentationFamiliarize with below before you look at the AsyncAPI document:AsyncAPI describes the API interface between the client and the server. In other words, the AsyncAPI document is for the user of the API. It does not describe what the server does but what the user can do with the API.Kraken API is quite complex. It has some beta servers, some private messages, and messages closely related to vocabulary specific for currency trading. I dropped all of those from my research not to overcomplicate things. In other words, the AsyncAPI file that you can see below is not a complete document.Websocket protocol is very flexible, and therefore you can implement the server in many different ways. There is no standard way of doing things, like there is no common way of doing things with AsyncAPI. We can only make some generic assumptions looking at existing implementations:Your server has one entry point, just one endpoint that you communicate with to gain access to the API. It can be apath with some dynamic values, as some data id. It can also be nothing, no path at all, like in the case of below Kraken API. These entry points arechannelsin AsyncAPI document. Commonly, Websocket API has just onechannelthat user can send messages to and receive messages at the same timeAsyncAPI publish and subscribe operations translates tomessages user can send to the APIandmessages user will receive from the API. Depending on API complexity, sometimes you have an API that sendsonly one message. You can also have a situation where you can send to the server multiple different messages, and also receive different messages in response. This is when you need to useoneOfas I did in document for Kraken API.Current AsyncAPI limitation is that you cannot specify that once the user sends (publish) messageping, thepongmessage is a reply. Look at thisthreadto participate in an ongoing discussion about request/reply pattern support in AsyncAPI. In the below document, you will notice that for such a use case, I use AsyncAPI specification extensions (x-response).Message to Kraken API developers and technical writersIn case you want to continue the work I started on the AsyncAPI document for Kraken API, feel free to do that. I'm happy to help, just let me know. Reach me out in ourAsyncAPI Slack workspace.1asyncapi:2.0.023info:4title: Kraken Websockets API5version:'1.8.0'6description: |7WebSockets API offers real-time market data updates. WebSocketsisa bidirectional protocol offering fastest real-time data, helping you build real-time applications. Thepublicmessage types presented belowdonotrequire authentication.Private-data messages can be subscribedona separate authenticated endpoint.89### General Considerations1011- TLSwithSNI (Server Name Indication)isrequiredinordertoestablish a Kraken WebSockets API connection. See Cloudflare's [What is SNI?](https://www.cloudflare.com/learning/ssl/what-is-sni/) guide for more details.12- All messages sentandreceived via WebSockets are encodedinJSON format13- Alldecimalfields (including timestamps) are quotedtopreserveprecision.14- Timestamps shouldnotbe considered uniqueandnotbe consideredasaliasesfortransaction IDs. Also, the granularityoftimestampsisnotrepresentativeoftransaction rates.15- At least oneprivatemessage should be subscribedtokeep the authenticated client connection open.16- Please use REST API endpoint [AssetPairs](https://www.kraken.com/features/api#get-tradable-pairs)tofetch the listofpairs which can be subscribed via WebSockets API.Forexample, field'wsname' gives the supported pairs name which can be used to subscribe.17- Cloudflare imposes a connection/re-connection rate limit (per IP address)ofapproximately150attempts per rolling10minutes.Ifthisisexceeded, the IPisbannedfor10minutes.18- Recommended reconnection behaviouristo(1) attempt reconnection instantly uptoa handfuloftimesifthe websocketisdropped randomly during normal operation but (2) after maintenanceorextended downtime, attempttoreconnect no more quickly than once every5seconds. Thereisno advantagetoreconnecting more rapidly after maintenance during cancel_only mode.1920servers:21public:22url: ws.kraken.com23protocol: wss24description: |25Publicserver available without authorization.26Once the socketisopen you can subscribetoapublicchannelbysending a subscribe request message.27private:28url: ws-auth.kraken.com29protocol: wss30description: |31Privateserver that requires authorization.32Once the socketisopen you can subscribetoprivate-data channelsbysending an authenticated subscribe request message.3334The API client must request an authentication"token"via the following REST API endpoint"GetWebSocketsToken"toconnecttoWebSocketsPrivateendpoints.Formore details read https://support.kraken.com/hc/en-us/articles/360034437672-How-to-retrieve-a-WebSocket-authentication-token-Example-code-in-Python-33536The resulting token must be providedinthe"token"fieldofanynewprivateWebSocket feed subscription:{
"event": "subscribe",
"subscription":
{
"name": "ownTrades",
"token": "WW91ciBhdXRoZW50aWNhdGlvbiB0b2tlbiBnb2VzIGhlcmUu"
}
}12channels:3/:4publish:5description:SendmessagestotheAPI6operationId:processReceivedMessage7message:8oneOf:9-$ref:'#/components/messages/ping'10-$ref:'#/components/messages/subscribe'11-$ref:'#/components/messages/unsubscribe'1213subscribe:14description:MessagesthatyoureceivefromtheAPI15operationId:sendMessage16message:17oneOf:18-$ref:'#/components/messages/pong'19-$ref:'#/components/messages/heartbeat'20-$ref:'#/components/messages/systemStatus'21-$ref:'#/components/messages/subscriptionStatus'2223components:24messages:25ping:26summary:Pingservertodeterminewhetherconnectionisalive27description:Clientcanpingservertodeterminewhetherconnectionisalive,serverrespondswithpong.Thisisanapplicationlevelpingasopposedtodefaultpinginwebsocketsstandardwhichisserverinitiated28payload:29$ref:'#/components/schemas/ping'30x-response:31$ref:'#/components/messages/pong'32heartbeat:33description:Serverheartbeatsentifnosubscriptiontrafficwithin1second(approximately)34payload:35$ref:'#/components/schemas/heartbeat'36pong:37summary:Pongisaresponsetopingmessage38description:Serverpongresponsetoapingtodeterminewhetherconnectionisalive.Thisisanapplicationlevelpongasopposedtodefaultponginwebsocketsstandardwhichissentbyclientinresponsetoaping39payload:40$ref:'#/components/schemas/pong'41systemStatus:42description:Statussentonconnectionorsystemstatuschanges.43payload:44$ref:'#/components/schemas/systemStatus'45examples:46-payload:47connectionID:862861539084861000048event:systemStatus49status:online50version:1.0.051subscribe:52description:Subscribetoatopiconasingleormultiplecurrencypairs.53payload:54$ref:'#/components/schemas/subscribe'55examples:56-payload:57event:subscribe58pair:59-XBT/USD60-XBT/EUR61subscription:62name:ticker63-payload:64event:subscribe65subscription:66name:ownTrades67token:WW91ciBhdXRoZW50aWNhdGlvbiB0b2tlbiBnb2VzIGhlcmUu68x-response:69$ref:'#/components/messages/subscriptionStatus'70unsubscribe:71description:Unsubscribe,canspecifyachannelIDormultiplecurrencypairs.72payload:73$ref:'#/components/schemas/subscribe'74examples:75-payload:76event:unsubscribe77pair:78-XBT/EUR79-XBT/USD80subscription:81name:ticker82-payload:83event:unsubscribe84subscription:85name:ownTrades86token:WW91ciBhdXRoZW50aWNhdGlvbiB0b2tlbiBnb2VzIGhlcmUu87x-response:88$ref:'#/components/messages/subscriptionStatus'89subscriptionStatus:90description:Subscriptionstatusresponsetosubscribe,unsubscribeorexchangeinitiatedunsubscribe.91payload:92$ref:'#/components/schemas/subscriptionStatus'93examples:94-payload:95channelID:1000196channelName:ohlc-597event:subscriptionStatus98pair:XBT/EUR99reqid:42100status:unsubscribed101subscription:102interval:5103name:ohlc104-payload:105errorMessage:Subscriptiondepthnotsupported106event:subscriptionStatus107pair:XBT/USD108status:error109subscription:110depth:42111name:book112113schemas:114ping:115type:object116properties:117event:118type:string119const:ping120reqid:121$ref:'#/components/schemas/reqid'122required:123-event124heartbeat:125type:object126properties:127event:128type:string129const:heartbeat130pong:131type:object132properties:133event:134type:string135const:pong136reqid:137$ref:'#/components/schemas/reqid'138systemStatus:139type:object140properties:141event:142type:string143const:systemStatus144connectionID:145type:integer146description:TheIDoftheconnection147status:148$ref:'#/components/schemas/status'149version:150type:string151status:152type:string153enum:154-online155-maintenance156-cancel_only157-limit_only158-post_only159subscribe:160type:object161properties:162event:163type:string164const:subscribe165reqid:166$ref:'#/components/schemas/reqid'167pair:168$ref:'#/components/schemas/pair'169subscription:170type:object171properties:172depth:173$ref:'#/components/schemas/depth'174interval:175$ref:'#/components/schemas/interval'176name:177$ref:'#/components/schemas/name'178ratecounter:179$ref:'#/components/schemas/ratecounter'180snapshot:181$ref:'#/components/schemas/snapshot'182token:183$ref:'#/components/schemas/token'184required:185-name186required:187-event188unsubscribe:189type:object190properties:191event:192type:string193const:unsubscribe194reqid:195$ref:'#/components/schemas/reqid'196pair:197$ref:'#/components/schemas/pair'198subscription:199type:object200properties:201depth:202$ref:'#/components/schemas/depth'203interval:204$ref:'#/components/schemas/interval'205name:206$ref:'#/components/schemas/name'207token:208$ref:'#/components/schemas/token'209required:210-name211required:212-event213subscriptionStatus:214type:object215oneOf:216-$ref:'#/components/schemas/subscriptionStatusError'217-$ref:'#/components/schemas/subscriptionStatusSuccess'218subscriptionStatusError:219allOf:220-properties:221errorMessage:222type:string223required:224-errorMessage225-$ref:'#/components/schemas/subscriptionStatusCommon'226subscriptionStatusSuccess:227allOf:228-properties:229channelID:230type:integer231description:ChannelIDonsuccessfulsubscription,applicabletopublicmessagesonly.232channelName:233type:string234description:ChannelNameonsuccessfulsubscription.Forpayloads'ohlc'and'book',respectiveintervalordepthwillbeaddedassuffix.235required:236-channelID237-channelName238-$ref:'#/components/schemas/subscriptionStatusCommon'239subscriptionStatusCommon:240type:object241required:242-event243properties:244event:245type:string246const:subscriptionStatus247reqid:248$ref:'#/components/schemas/reqid'249pair:250$ref:'#/components/schemas/pair'251status:252$ref:'#/components/schemas/status'253subscription:254required:255-name256type:object257properties:258depth:259$ref:'#/components/schemas/depth'260interval:261$ref:'#/components/schemas/interval'262maxratecount:263$ref:'#/components/schemas/maxratecount'264name:265$ref:'#/components/schemas/name'266token:267$ref:'#/components/schemas/token'268interval:269type:integer270description:Timeintervalassociatedwithohlcsubscriptioninminutes.271default:1272enum:273-1274-5275-15276-30277-60278-240279-1440280-10080281-21600282name:283type:string284description:Thenameofthechannelyousubscribetoo.285enum:286-book287-ohlc288-openOrders289-ownTrades290-spread291-ticker292-trade293token:294type:string295description:base64-encodedauthenticationtokenforprivate-dataendpoints.296depth:297type:integer298default:10299enum:300-10301-25302-100303-500304-1000305description:Depthassociatedwithbooksubscriptioninnumberoflevelseachside.306maxratecount:307type:integer308description:Maxrate-limitbudget.ComparetotheratecounterfieldintheopenOrdersupdatestocheckwhetheryouareapproachingtheratelimit.309ratecounter:310type:boolean311default:false312description:Whethertosendrate-limitcounterinupdates(supportedonlyforopenOrderssubscriptions)313snapshot:314type:boolean315default:true316description:Whethertosendhistoricalfeeddatasnapshotuponsubscription(supportedonlyforownTradessubscriptions)317reqid:318type:integer319description:clientoriginatedIDreflectedinresponsemessage.320pair:321type:array322description:Arrayofcurrencypairs.323items:324type:string325description:Formatofeachpairis"A/B",whereAandBareISO4217-A3forstandardizedassetsandpopularuniquesymbolifnotstandardized.326pattern:'[A-Z\s]+\/[A-Z\s]+'Personal noteIf you can, if you are in a planning phase, new project, etc., then start designing your architecture with AsyncAPI. Don't do the mistake of coding first and then trying to figure out how to describe it with AsyncAPI😅Stay tuned for the next blog post that guides you step by step through the above document☮️I recommend you also read another article from the series about WebSocket:Creating AsyncAPI for WebSocket API - Step by Step.
"""
--------------------------------------------------------------------------------


Post 90
ID: https://www.asyncapi.com/blog/march-2021-at-asyncapi?utm_source=rss
Title: March 2021 at AsyncAPI
Link: https://www.asyncapi.com/blog/march-2021-at-asyncapi?utm_source=rss
Summary: AsyncAPI Initiative joined the Linux Foundation in March, but except of this, many other interesting things happened: new roadmap, google summer of code
Content:
"""
ReadFebruary 2021 at AsyncAPIfor the update from February.In case you do not have time to read this article, maybe take time to listen to the news. Let me know what you think about such an appraoch.Q1 2021 came to an end. Let me summarise our targets, revenue, and forecasts😃This month:Slackmembers up by around 100 (reached 1.1k)Twitterfollowers up by around 100 (reached 1.7k)LinkedInfollowers up by around 100 (reached 1k)NewOpenCollectivecontributor,Apideck+ additional 100 USD every monthForecast? Last months were as awesome as March, usually +100. Does it mean that we will have +1k members on all channels by the end of the year?😅Figure 1: Comparison of Q1 2020 vs Q1 2021 visits to asyncapi.comLet's scale this party up!AsyncAPI at Linux FoundationWe did it. AsyncAPI initiative joined Linux Foundation (LF). No more excuses for you not to join us. You're all welcome.I don't want to write about this too much as everything was described in different articles about us joining LF:AsyncAPI joins Linux FoundationLinux Foundation Will Host AsyncAPI to Support Growth and Collaboration for Industry's Fastest-Growing API SpecThe Linux Foundation Announces Hosting of AsyncAPIAsyncAPI Looks to Unify API Workflow under Linux FoundationFAQLet me provide more context in FAQ style:Is Linux Foundation taking control over AsyncAPINo. AsyncAPI Initiative runs underopen governance modeland is community-driven. LF assures the project's intellectual property (IP), and related assets do not belong to any company or individual.Fran Mendezdoes not retire. He only handed over rights to the project to the foundation to assure the community that it is completely safe for all to use the spec and its tooling.It also means ourGitHub organizationis not going anywhere. Nothing changes.Do we need to sign some CLA now to contributeWe do not need a contributor license agreement (CLA) on repositories for our tools. We might need to set upEasyCLAfor the repository where we have the specification. We need to clarify it in the long run—nothing to worry about until we set it up. In the end, the only reason to set it up is to secure the community from a situation that some contributor (or their company) claims rights to some part of the specification they contributed to.How much money you needGlad you asked. We joined the foundation with an open governance model that favors active contributors over sponsors. As a result, we do not have a setup where we can assure significant income in exchange for voting rights. In other words, we do not have a financial founding associated with joining the foundation. We still need your financial support. Go to ourOpen Collective profileand drop some coins. Let us know if I can help to preach about AsyncAPI in your company for some extra money.How can we helpExcept for regular contributions, we need help setting up tooling for our open governance model. We need to:Automate a process of collecting information about TSC membersPut information about current TSC members on the AsyncAPI websiteFigure out tooling for the websiteSetup CODEOWNERS and VOTING files in all the repositoriesEveryone with a different set of skills is welcome.Just contact me.What is nextWe are almost ready for the next releases of the specification. We already have a new, GraphQL-inspired contribution guide that explains how to introduce changes in the specification. What is left is a decision on how actually to decide that release will happen and when. Help us by:Familiarize withinstructionon how to introduce changes in the spec, pickthe ideathat you want to champion, and let us start improving the specHave a look at theproposal on release cadenceand share your opinion, as comments or emojisVision and roadmapAsyncAPI creator,Fran Mendez, published AsyncAPI Initiative's vision and roadmap for next years.tl;drAsyncAPI becomes the #1 API specification for defining and developing APIs. Any kind of APIs.Go to theroadmapview to check out what it means and what needs to be done to get there.We need a lot of help to complete this roadmap. Without engagement and support of the community, all of this is just wishful thinking. All hands aboard, we're waitinghere.Google Summer of CodeIn 2020, we decided to actively supportthe Hacktoberfestto give back to the community by making it easier to make a first contribution in open-source and at the same time improve awareness about the AsyncAPI Initiative. We received a very positive feedback, and people referred us toGoogle Summer of Codeas a place where our engagement would be highly appreciated.We applied this year to be part of the GSoC initiative.We got rejected.It is not easy to reject us, though😃Postmanthat we partner with was accepted for GSoC and offered us to submit the list withour ideas(ideas 7-13) as part of Postman application. We received many proposals and were contaced by many very motivated students (but not only students) who would like to join the AsyncAPI initiative and build great tools.Have a look at the list of ideas. We received proposals for all of them. It looks like soon, our tooling ecosystem will get many new useful tools. Stay tuned. Feel free to join us, share your use cases for the ideas and also help build those tools. A Majority of discussions happenhere.Bindings rendering in react componentThanks to work done bySwen HelgefromSolace, the React component supports rendering of information provided in bindings. Check release0.21in theplayground for the React component.Messages validation in NodeJS templateThanks to work done byKhuda Dad Nomani, the NodeJS template that you can generate using the AsyncAPI Generator includes a message validator that enables real-time validation of all incoming and outgoing messages. Check outthisshort instructions to see it in action or watch the below recording.About AsyncAPI in different languagesAre you tired of reading about AsyncAPI only in English? Some articles in French and Spanish were released recently, have a look:SpanishFrenchIf you want to see more content in different languages, let us know.Also, provide feedback toBarbaño Gonzálezthat works on content for Spanish-speaking audience. Some help neededhere.Photo byMarkus SpiskeonUnsplash
"""
--------------------------------------------------------------------------------


Post 91
ID: https://www.asyncapi.com/blog/asyncapi-joins-linux-foundation?utm_source=rss
Title: AsyncAPI joins Linux Foundation
Link: https://www.asyncapi.com/blog/asyncapi-joins-linux-foundation?utm_source=rss
Summary: Today marks a delightful milestone for us at AsyncAPI: I'm proud to share with you that we're now a Linux Foundation project 🎉
Content:
"""
Today marks a delightful milestone for us at AsyncAPI:I'm proud to share with you that we're now a Linux Foundation project🎉When a year ago, our Łukasz and I started having discussions on the best way to improve the open governance, we instantly agreed that AsyncAPI had to join a neutral home. But not just any neutral home. We needed to join a strong and trusted organization that would allow us to keep the project independent and community-driven. That's the Linux Foundation. The home of many other internet open-source industry standards.It's been a year to remember. Amidst a pandemic, we organized the first AsyncAPI Conference. Lots of new folks joined our great community. Our tools started to get mature enough. And to put the cherry on the cake,we partnered with Postmanto guarantee the continuity and growth of AsyncAPI for the next decade. What a ride!2021 looks no different so far. In less than 3 months, we're seeing an increasing amount of folks joining us tochange the EDA and API landscapes forever. We owed you this. We're joining the Linux Foundation to make sure AsyncAPI stays neutral and isdriven by those who dedicate their effort, time, and love to the project.And that's what it is all about, my friends. Without you —yes, you too!–, AsyncAPI is nothing but an illusory fantasy in the heads of some dreamers. This step is indeed the culmination of years of hard work, but to me, this is just the beginning. Now is when the party is actually getting started. Drop some cool beats and grab some drinks. It's going to be a long night!Let's build the future, together🚀
"""
--------------------------------------------------------------------------------


Post 92
ID: https://www.asyncapi.com/blog/building-async-flight-notification-service?utm_source=rss
Title: Building an asynchronous flight notification service using AsyncAPI, MQTT, Amadeus and Twilio
Link: https://www.asyncapi.com/blog/building-async-flight-notification-service?utm_source=rss
Summary: Flight delays, cancelations and gate changes are among the most common headaches that travelers face. Now more so than ever, travelers need this information literally at hand to enjoy a stress-free tr
Content:
"""
Flight delays, cancelations and gate changes are among the most common headaches that travelers face. Now more so than ever, travelers need this information literally at hand to enjoy a stress-free trip.With this in mind, we decided to build a small prototype to implement an asynchronous scheduling notification service. The prototype will be implemented following the microservices architecture paradigm with the following services and requirements in mind:All services should communicate asynchronously via theMQTTprotocol, a lightweight publish-subscribe messaging pattern. Messages should be correctly defined and documented following AsyncAPI specs.AMonitor servicereceives and queues flight information and queries the REST API to detect changes. When it detects a change, it notifies subscribers. Flight schedule information is retrieved from theFlight Status APIfrom Amadeus for Developers.ANotifier servicereceives the notifications and alerts the user via SMS. Alerts are sent using theTwilio SMS API.ASubscriber serviceprovides a simple web interface so users can subscribe to flight status updates.Defining messages with AsyncAPIFirst, we’ll define two messages to model the events managed by subscribers and publishers:AflightQueuemessage to queue a new flight to be monitored for status changes. This event is composed of two main schemas:user– to model information about the user subscribing to the notifications (name and phone number):1type:object2properties:3userName:4type:string5minimum:16phoneNumber:7type:string8description:phonenumberwherenotificationswillbereceived.flight- to model  information about the flight being monitored (carrier code, flight number and departure date).1type:object2properties:3carrierCode:4type:string5description:2to3-characterIATAcarriercode6example:"LH"7flightNumber:8type:integer9minimum:110description:1to4-digitnumberoftheflight11example:"193"12scheduledDepartureDate:13type:string14format:date-time15description:scheduleddeparturedateoftheflight,localtothedepartureairport.16example:"2020-10-20"AflightStatusmessage to notify about changes. When the service detects a change in flight status, it triggers a notification event to alert the user. The payload of theflightStatusmessage consists of the following structure:flightanduserschemas (the same as in theflightQueuemessage) to identify the flight emitting the event and the user receiving the notification.Twosegmentschemas corresponding to the origin and destination. This lets us notify about changes to both departure and arrival.1type:object2properties:3iataCode:4type:string5description:2to3-characterIATAcarriercode6example:"MAD"7scheduledDate:8type:string9format:date-time10description:scheduleddatetimeoftheflight,localtotheairport.11example:"2020-10-20 19:15"12gate:13type:string14description:departuregate15example:"2D"16terminal:17type:string18description:airportterminal19example:"4"Messages are shared among services so it’s important to correctly organize the YAML definition files under a common folder. In our case, we call it common:common/
messages/
flight_queue.yaml
flight_status.yaml
schemas/
flight.yaml
segment.yaml
user.yamlServices communicate through channels using the publish/subscribe pattern. Our architecture uses two different channels:flight/queueto manage and queue the flights to be monitored.flight/updateto manage the notifications about flight updates.Each service contains anasyncapi.yamlfile with the description of the service and server and channel information. Let's take a look to the finalasyncapi.yamlfile of the Subscriber service to see how the messages and channels are organized:1asyncapi:'2.0.0'2info:3title:FlightSubscriberService4version:'1.0.0'5description:|6Allows users to subscribe events from a given flight7license:8name:Apache2.09url:'https://www.apache.org/licenses/LICENSE-2.0'10servers:11development:12url:mqtt://localhost:188313protocol:mqtt14channels:15flight/queue:16description:|17queue flight in order to retrieve status18subscribe:19summary:Receiveinformationabouttheflightthatshouldbemonitoredforchanges20message:21$ref:'#/components/messages/flightQueue'22components:23messages:24flightQueue:25$ref:'../common/messages/flight_queue.yaml'When the user provides their flight information, the Subscriber service emits aflightQueuemessage that will be received by the Monitor service from theflight/queuechannel. The Notifier service also receives the message and adds the payload to the list of flights to monitor.Once the Monitor service detects a change in flight status (e.g. a change in boarding gate), it emits aflightStatusmessage to inform subscribers. The Notifier service, which is subscribed to the changes on theflight/updatechannel, notifies the end-user by SMS.The AsyncAPI specification files for theMonitor ServiceandNotifier Servicecan be found on GitHub.Monitoring flight status informationThe Monitor service checks the status of the user’s flight by calling the On-Demand Flight Status API, which provides real-time flight schedule information like departure/arrival times, gate, or terminal. A simple cURL request to the API shows how the information is represented:To get your own authorization token, followthisguide.curlhttps://test.api.amadeus.com/v2/schedule/flights?carrierCode=KL&flightNumber=1772scheduledDepartureDate=2021-02-18-H 'Authorization: Bearer dzh1cpJiFgAlE7iZS'In the JSON response, the schedule data of this example has one single segment (a leg of an itinerary, in airline jargon) with severalflightPoints:1"flightPoints": [2{3"iataCode":"FRA",4"departure": {5"terminal": {6"code":"1"7},8"gate": {9"mainGate":"B20"10},11"timings": [12{13"qualifier":"STD",14"value":"2020-11-05T18:20+01:00"15}16]17}18},19{20"iataCode":"AMS",21"arrival": {22"terminal": {23"code":"1"24},25"gate": {26"mainGate":"A04"27},28"timings": [29{30"qualifier":"STA",31"value":"2020-11-05T19:35+01:00"32}33]34}35}36]We can see that:The flight is scheduled to depart from Terminal 1, Gate B22 of Frankfurt International Airport (FRA) at 18:20 (UTC+1).It is scheduled to arrive at Terminal 1, Gate A04 of Amsterdam Schiphol Airport (AMS) at 19:35 (UTC+1).The API is synchronous and therefore needs to be polled to monitor the flight status. This isn’t ideal and we need a solid strategy to avoid DDoSing the Amadeus backend, using up our free call quota or piling up a massive bill at the end of the month.To solve this, we put the Monitor service on a separate thread. Every five minutes, the thread checks to see if it’s time to retrieve information from the API and update the status. The Monitor only calls the API if two conditions are met:The current date is equal to the departure date.The current time is within 4 hours of the departure time.Subscribing to flight updatesThe Subscriber service  lets users subscribe to the notifications. We built a simple HTTP server with Flask to let the user enter their name, phone number and flight information.Once the Subscriber service gets a new user subscription, it emits aflightQueuemessage with that information in the payload to the broker, so that it can be received by the Monitor.Sending notifications to usersThe Notifier service receives flight status updates from the Monitor and uses the Twilio SMS API to notify the end. The service has a very simple implementation: when the Notifier receives aflightStatusmessage, it uses the message payload to build an SMS message:1client = twilio.Client(account_sid, auth_token)23msg = build_message(alert_msg['user'],4alert_msg['departure'],5alert_msg['arrival'])67destination_phone = alert_msg['user']['phoneNumber']89message = client.messages.create(body=msg,10from_=twilio_phone,11to=destination_phone)Running the serviceTheprototyperuns on four Docker containers – one per service plus another for theMQTT brokerbased on the Docker image maintained by the Eclipse Mosquitto project.To avoid manually starting each service (plus the dependency of starting the broker first), we will useDocker compose, a tool to run applications composed of multiple containers using a YAML file to define each container as well as their dependencies.We start the service by executing:docker network create my-network
docker-compose up --remove-orphansIn the browser, we go tohttp://localhost:5000and enter information about the flight we want to monitor. The service will send us an alert once the flight information is updated:ConclusionOur prototype successfully implements our requirements but it’s still far from being ready to use in production. To do so, we’d need to implement authorization, an unsubscribe feature and improve the polling service’s performance, among other improvements.However, developing this prototype lets us learn how to specify and document event-driven architecture using AsyncAPI easily.You can find the complete source code of the prototype on the GitHubasync-flight-status repository. Feel free to clone, modify and improve the implementation!Happy coding!
"""
--------------------------------------------------------------------------------


Post 93
ID: https://www.asyncapi.com/blog/understanding-asyncapis?utm_source=rss
Title: Understanding AsyncAPIs with a Practical Example
Link: https://www.asyncapi.com/blog/understanding-asyncapis?utm_source=rss
Summary: Learn how to map a real-world event-driven Microservices architecture into AsyncAPI specification
Content:
"""
Event-driven applications are inherently distributed and loosely-coupled. That potentially leads to having many self-contained components in your architecture, managed by multiple teams.The information exchanged between them must be documented and maintained consistently for everyone’s visibility.AsyncAPI specificationsteps in to solve that gap.This post explains how to map a simple event-driven application architecture into corresponding AsyncAPI specifications by walking you through an example.The event-driven use caseImagine you are designing a solution to the following use case.Two event-driven microservices are communicating through a message broker in a publish/subscribe manner. The first service, the Account service, publishes theUserSignedUpevent when a new user account is created. The second service, the Email service, subscribed to receive those events to send the new user a welcome email.We can come up with a simple solution architecture as follows.The problemNow we have a solution architecture in place. Should we go ahead and start building?No! Not so fast. There are strong reasons behind not doing so.Account and Email services are loosely coupled distributed services, potentially built, operated, and maintained by separated teams. Two services will have their own context boundaries defined. All teams must explicitly define any information exchanged across these boundaries. For example, all teams must maintain broker configurations, topics, and event formats in a central place. Otherwise, maintaining the solution will become a nightmare in the long run.In our solution, the format of theUserSignedUpevent must be consistent across two services. If one team makes a change, it has to be visible across the board.Therefore, a proper process must be in place to describe different components of an event-driven system and their interactions.
AsyncAPI specification comes into play at this point.AsyncAPI specification to the rescueAsyncAPI is an open-source initiative that provides both a specification to describe and document your asynchronous applications in a machine-readable format and tooling (such as code generators) to make life easier for developers tasked with implementing them.-Marc DiPasqualeAsyncAPI is built on the foundation ofOpenAPI specification. A brings in critical activities from the REST API world, from documentation to code generation, from discovery to event management. Most of the processes you apply to your REST APIs nowadays would apply to event-driven/asynchronous APIs.Currently, the specification is atversion 2.0.0.Documenting the solution architectureLet’s try to document our solution as per the AsyncAPI specification. Our end goal is to share it with respective teams to generate the implementations, validators, and most importantly, the documentation.An AsyncAPI document is a file that defines and annotates the different components ofa specific Event-Driven Application. The file format must be JSON or YAML; however, only the subset of YAML that matches the JSON capabilities is allowed.First, we need to identifyApplicationsin the solution.Identify event-driven applications in the solutionThe first step of documenting an event-driven architecture is to identify discrete components that produce or consume events. In AsyncAPI terms, they are commonly referred to asApplications.As per the specification:An application is any kind of computer program or a group of them. It MUST be aproducer, aconsumeror both. An application MAY be a microservice, IoT device (sensor), mainframe process, etc. An application MAY be written in any number of different programming languages as long as they support the selectedprotocol. An application MUST also use a protocol supported by the server in order to connect and exchangemessages.In our solution, both Account service and Email service can be considered as applications as they produce and consumeUserSignedUpevents, respectively. Hence, both services will get their own AsyncAPI specification file.Let’s start with the Account service first.Documenting the Account serviceCreate a file calledaccount-service.yamland add the following content to it.1asyncapi:2.0.02info:3title:AccountService4version:'1.0.0'5description:|6Manages user accounts in the system.7license:8name:Apache2.09url:https://www.apache.org/licenses/LICENSE-2.0The first line of the specification starts with the document type,asyncapi, and theversion(2.0.0). This line doesn’t have to be the first one, but it’s a recommended practice.Theinfoobject contains the minimum required information about the application. It contains thetitle, which is a memorable name for the API, and the version. While it’s not mandatory, it is strongly recommended to change the version whenever you make changes to the API.Adding serversOur solution has been designed around a message broker. Therefore, both Account and Email services MUST specify brokers’ necessary information such as URIs, protocols, and security configurations.We can use theserversobject to define that information for the Account service. In AsyncAPI terms, a server object defines a message broker, a server, or any other kind of computer program capable of sending or receiving data.Add the following content to the same file. Here, we are using the test MQTT broker available at mosquitto.org. Apart from MQTT, AsyncAPI supports other protocols like AMQP and Kafka.1servers:2production:3url:mqtt://test.mosquitto.org4protocol:mqtt5description:TestMQTTbrokerAdding channels, operations, and messagesSo far, the Account service consumers know where they should connect to send or receive data. The next step is to define operations on the broker.An operation maps to eitherpublishorsubscribemethod/function in the application. Each operation exchanges one or moremessages. Effectively, these messages define different events sent to and received from operations.Operations are bound to a particularchannelin the server, along with the messages they exchange. A channel is an addressable component made available by the server for the organization of messages. Producer applications send messages to channels, and consumer applications consume messages from channels. You can think of channels as the interfaces for external parties to communicate with an application.There can be many channel instances in a server, allowing messages with different content to be addressed to different channels. A channel is equivalent to topics, routing keys, event types, or paths based on the server implementation.This relationship is illustrated in the following figure.In our solution, both services publish and consume events on the same channel.Add the following section to define a channel calleduser/signedup.1channels:2user/signedup:3subscribe:4operationId:emitUserSignUpEvent5message:6$ref:'#/components/messages/UserSignedUp'The Account service publishesUserSignedUpevents to the broker. Hence, it is a publish operation. TheoperationIdspecifies the name of the method or function that emits theUserSignedUpevent in the generated code.The above operation uses a reference to specify the format of the message that publishes. We’ll get to the schema definitions shortly.Defining messages and payload schemaIn our solution, both services produce and consume theUserSignedUpevent, which has the following format.1{2"firstName":"John",3"lastName":"Doe",4"email":"aa@bb.cc",5"createdAt":"2021-02-12 09:34:123"6}The publish operation of theuser/signedupchannel had a reference to the event payload’s schema. Now we need to define it properly. The schema definitions are done with AsyncAPI schema, which is 100% compatible with JSON Schema Draft 07. Refer tothisif you need to explore more on the AsynAPI schemas.Message schemas, security schemes, and bindings are housed byComponentsobject. All objects defined within the components object must be referenced from properties outside the components object.After adding the schemas, the final AsyncAPI definition for the Account service file should look like the following.1asyncapi:2.0.02info:3title:AccountService4version:'1.0.0'5description:|6Manages user accounts in the system.7license:8name:Apache2.09url:https://www.apache.org/licenses/LICENSE-2.01011servers:12production:13url:mqtt://test.mosquitto.org14protocol:mqtt15description:TestMQTTbroker1617channels:18user/signedup:19subscribe:20operationId:emitUserSignUpEvent21message:22$ref:'#/components/messages/UserSignedUp'2324components:25messages:26UserSignedUp:27name:userSignedUp28title:Usersignedupevent29summary:Informaboutanewuserregistrationinthesystem30contentType:application/json31payload:32$ref:'#/components/schemas/userSignedUpPayload'3334schemas:35userSignedUpPayload:36type:object37properties:38firstName:39type:string40description:"foo"41lastName:42type:string43description:"bar"44email:45type:string46format:email47description:"baz"48createdAt:49type:string50format:date-timeDocumenting the Email serviceSimilar to the above, we can create the AsyncAPI specification for the Email service as follows.1asyncapi:2.0.02info:3title:EmailService4version:'1.0.0'5description:|6Sends emails upon certain events7license:8name:Apache2.09url:https://www.apache.org/licenses/LICENSE-2.01011servers:12production:13url:mqtt://test.mosquitto.org14protocol:mqtt15description:TestMQTTbroker1617channels:18user/signedup:19publish:20operationId:onUserSignUp21message:22$ref:'#/components/messages/UserSignedUp'2324components:25messages:26UserSignedUp:27name:userSignedUp28title:Usersignedupevent29summary:Informaboutanewuserregistrationinthesystem30contentType:application/json31payload:32$ref:'#/components/schemas/userSignedUpPayload'3334schemas:35userSignedUpPayload:36type:object37properties:38firstName:39type:string40description:"foo"41lastName:42type:string43description:"bar"44email:45type:string46format:email47description:"baz"48createdAt:49type:string50format:date-time51description:"foo"Notice that the servers, channels, and payloads are the same. The only difference is in thepublishoperation, bound to theuser/signedupchannel. It says that messages published to this channel will be received by this service.What’s next?Now we have completed writing AsyncAPI specifications for both Microservices. The next goal is to check-in them into a central location like Git and let both teams collaborate over the design. They can collaboratively edit the spec files to introduce new operations, parameters, versions, etc. Thanks to AsyncAPI, everything can be controlled from a central place, and every change will be visible across the board. I would say this is the pipe dream of an enterprise architect ;)But our journey doesn’t stop here. The AsyncAPI project brings in a rich set of tools for the betterment of event-driven application building. You can find more information on thishere.Code generatorsApplication developers can speed up their work by automatically generating scaffoldings by specifying the specification file. This design-first strategy provides boilerplate code for dealing with brokers and marshaling/unmarshalling messages over the wire.Generators are available for mainstream applications like Java, .NET, JavaScript, etc. You can check outthisrepo for more information.ValidatorsValidators validate a given message by comparing it with the specification. That is useful at the runtime for input validations.Documentation generatorsThese generators generate human-readable documentation from an AsyncAPI document. Output formats are HTML, Markdown, and React (experimental)Mocking and testing toolsTools that take specification documents as input, then publish fake messages to broker destinations for simulation purposes. May also check that publisher messages are compliant with schemas.ConclusionUse AsyncAPI specification to document your event-driven systems to maintain consistency, efficiency, and governance across different teams who own each architectural component.The tooling ecosystem of AsyncAPI helps you speed up application development by automating tedious but necessary tasks such as code generation, documentation generation, validators, etc. Use them whenever you can.Finally, the AsyncAPI community is growing so fast. Your contribution to the community will be valuable in terms of making better event-driven applications.I hope you enjoyed this post.Originally published athttps://medium.com/event-driven-utopiaCover image bysilviaritafromPixabay
"""
--------------------------------------------------------------------------------


Post 94
ID: https://www.asyncapi.com/blog/february-2021-at-asyncapi?utm_source=rss
Title: February 2021 at AsyncAPI
Link: https://www.asyncapi.com/blog/february-2021-at-asyncapi?utm_source=rss
Summary: We are getting close to joining a foundation. We started a few new initiatives. We are busy. In other words, this is a good time to join us and drive things together.
Content:
"""
ReadJanuary 2021 at AsyncAPIfor the update from January.I enjoy monthly status over weekly one. It is not that I'm just happy I have more time for other things. Content size did not change. I think people do have other things to do than following AsyncAPI only😅Life in open-source runs slower, at least when you look at it from the outside. I have an impression, that more people pay attention to the status when it is once a month. I wonder what your view is on that.Open governance model aka charter ready for the reviewIs an "open governance model" the same as a "charter"? No. Charter is a boring legal document that describes many rules that need to be followed when being under a foundation. One of the things the charter tackles is the general rules on how the project will operate and be governed.I think the most important thing to write here is that the AsyncAPI charter is a reality. It finally arrived and is ready for review. In the special blog post, we also explained what governance model we envision for the AsyncAPI Initiative in more human-friendly words. This content was released and communicated on Tuesday, 9th of March, and we will wait for your feedback until the 23rd of March. It looks like we will kick off April under the umbrella of the foundation🤞Please take your time to:ReadFinding a Good Open Governance Model for AsyncAPIto understand our motivationCheck outthispull request with the charterCode generators activitiesWe had some significant traffic in the area of code generation templates in February.PHPEmiliano Zublenajoined the AsyncAPI community big time by starting with donatinga new template for PHP. It is not yet released under@asyncapiscope on npm, but you can already play with it by using the AsyncAPI Generator with a direct GitHub link like:ag https://bit.ly/asyncapi https://github.com/asyncapi/asyncapi-php-template -o output`GoWe merged the initial pull request to theGo template. The initial contributor was not able to continue working on the template, but the foundation was there.Emiliano ZublenaandTakumi Suedawill try to help to drive forward template development. This template is not yet released as we need to get some feedback from the community first. Give it a try with:ag https://bit.ly/asyncapi https://github.com/asyncapi/go-template -o outputLet us know what you think in the GitHub issues section. Thank you,Jacob Postonfor your initial hard work on the template!TypeScript and NATSJonas Lagoniregularly extends and polishesthe TypeScript template for NATS. It reached 0.3 release and is the first template that is already using a new AsyncAPI SDK for data types generation. Please go and check it out.AsyncAPI CLI to rule them allWe always wanted to have a single CLI to do all the things related to AsyncAPI. In other words, one CLI to validate, generate, edit, create, and others. So far, we had a CLI for the AsyncAPI generator, and recently one of our community members,Jorge Aguiar Martín, referred us to his CLI for AsyncAPI validation.We all agreed that instead of working separately on different CLIs, it is better to work together on one CLI that everyone will love. The project kicked off! A repository has been created and we already discuss details on how the CLI interface should look like.Jointhe discussion.Event gatewaySounds big? It is😃An excellent engineer joined AsyncAPI,Sergio Moya. We felt like we need to start something big that should be built independently from any vendor together with the AsyncAPI community. The project got kicked off, and it is the best time to join. Have a look at the dedicated repository and our plans forthe Everest? AsyncAPI Gate? or maybe Eventide?😃Share your use cases. Please help us understand what you need. Sergio prepared an issue template thathelps with that.Domain model generationAs mentioned inthe blog post about January, February was all about data model generation that we wanted to use to speed up templates development for code generation. The library isready, and we started trying it out. You can try it out too, and you do not even need our AsyncAPI Generator. It is a generic library and you only need a JSON Schema Draft 7 or an AsyncAPI document.1import { TypeScriptGenerator } from '@asyncapi/generator-model-sdk';23const DESCRIPTION_PRESET = {4interface: {5property({ property, content }) {6const desc = property.getFromSchema('description');7if (desc) {8return `// ${desc}\n${content}`;9}10return content;11}12}13}1415const options = {16modelType: 'interface',17presets: [DESCRIPTION_PRESET],18}1920const generator = new TypeScriptGenerator(options);2122const schema = {23$id:"Address",24type:"object",25properties: {26street_name:    { type:"string"},27city:           { type:"string", description:"City description"},28house_number:   { type:"number"},29marriage:       { type:"boolean", description:"Status if marriage live in given house"},30pet_names:      { type:"array", items: { type:"string"} },31},32required: ["street_name","city","state","house_number","state"],33};3435const interfaceModels = await generator.generate(schema);3637// generated interfaceModels[0].result should have the following shape:38export interface Address {39streetName: string;40// City description41city: string;42houseNumber: number;43// Status if marriage live in given house44marriage?: boolean;45petNames?: Array<string>;46}Community continues to growIn February we reached 1600 followers on Twitter.A great thing to see is that the community fromLinkedIngrew to 900, and our news shared there also get more visibility.We are very noisy😅Other featuresThanks to the support ofDaniel CHU—who joined us during last Hacktoberfest— now the JavaScript parser also validates the examples of server variables. For more details, check out the1.4release.Once again, thanks toLudovic Dussartfrom Ineat Lab, we have additional features, these time in HTML and Markdown template. Thanks to the newversionparameter, you can overwrite the version of the application specified in the AsyncAPI file underinfo.version. Useful in CI/CD when your service version is not maintained in the AsyncAPI file but pom.xml or package.jsonThanks toMike Ralphson, we have a newfrontMatterparameter in the Markdown template. It lets you specify an external file with a custom front-matter that should be included in the resulting Markdown during generation. Very useful for static site generators' users.1# 1. Get AsyncAPI Generator2npm install -g @asyncapi/generator34# 2. Create a file with frontmatter5cat > ssg.yml <<EOF6title: AsyncAPI Documentation7layout: asyncapi8permalink: /asyncapi-docs9EOF1011# 3, Generate Markdown file that includes the frontmatter12ag https://bit.ly/asyncapi @asyncapi/markdown-template -o output -p frontMatter=ssg.yml1314# 4. Check out the output15cat output/asyncapi.mdMaciej UrbanczykandI(I mean me😃) pushed some features to the AsyncAPI Generator:It supports the latest Node.js 15 and npm 7You can now install generator templates globally. For more details, readthisnew section in the readme.It is now much easier to generate multiple files using the new React render engine. For more details, readthisor have a look at ithereSome parts of templates can be written in TypeScript. For more details, readthis. We still cannot use TS in main template code. For more details readthis.Check out all thereleasesGood learning resourcesRead this important10 FAQs About Event-Driven APIsfromDakshitha RatnayakeGreat summary from Nordic APIs andVyom Srivastavaon8+ AsyncAPI Documentation GeneratorsFran Mendez was a part of Postman's live stream. Learn how to get from zero to AsyncAPI in just about 1h 30min. I hope it can be done faster, and Fran was just having too much small talk with Kevin and Kin😅Photo byDenys NevozhaionUnsplash
"""
--------------------------------------------------------------------------------


Post 95
ID: https://www.asyncapi.com/blog/governance-motivation?utm_source=rss
Title: Finding a Good Open Governance Model for AsyncAPI
Link: https://www.asyncapi.com/blog/governance-motivation?utm_source=rss
Summary: AsyncAPI can be successful if the initiative is community-driven. To be community-driven, we need the community to see it can drive things and make an impact. For that, we need a proper open governance model. What model would be the best?
Content:
"""
tl;dr charter for the AsyncAPI Initiative open governance is ready for review. Leave your comments there inthispull request. We will wait two weeks for your feedback.December 2020 brought to AsyncAPI an important announcement, apartnership with Postman. This huge milestone secured the AsyncAPI Initiative development efforts as few active community members moved to Postman. This move speeded up our work on transferring AsyncAPI to a foundation and forming an open governance model to assure the community that a single company does not control AsyncAPI Initiative.It took us a lot of time to write down the initial charter for the initiative.Pro Tip:Charteris not a person that creates charts😃Nobody's trying to be a smart ass here. We actually had to google that😃The visionWe started with a basic vision in our heads and studied governance models of many diverse communities, like NodeJS Foundation, OpenJS Foundation, GraphQL Foundation, Cloud Events, OpenAPI Initiative, and CNCF. We also got a charter template from Linux Foundation. That was a lot to handle.In the end, we just wanted to make sure the initiative is community-driven and leaves no one behind. We tried to figure out a governance model that:is as democratic as possiblesupports the asynchronous decision-making processgives power to people that "work", not companies that "pay". In other words, it gives equal power to both individual and corporate contributors.VocabularyIn the AsyncAPI governance model, you can find two essential roles: contributor and committer. A contributor is a person that contributes to the project code, docs, or other artifacts. A committer is a person that contributes regularly and is invited by other committers to manage the repository, to have more privileges, and to approve pull requests.Committer rules in the repository, but for topics that go beyond, there is a Technical Steering Committee (TSC).TSC consists of all committers.Yes, not a dedicated group of people for now. Are you a committer? If yes, then it means you are a voting member of TSC (unless you do not want to). But more on that further in the blog post.Single TSC for spec and toolsSpec and tools will have different licenses, but there will not be two TSCs though. One TSC to handle both the specification and the tools.Why?start small, they say.don't design processes and then work accordingly but better build a process that facilitates the way you work already.we are a large community, but not large enough to handle two different charters, not now.The other good reason for not splitting is that we believe the initiative should work on spec and tools to provide essential open-source tools that consistently support the latest version of the specification. In other words, when we release the newest version of the specification, you can already use it with official tools and do not have to wait for other tooling providers to catch up. We know big companies do not care much about basic tooling as they most probably write their own because it is much easier for them to work without unnecessary noise. Nevertheless, we need to think about the small ones too. Two TSCs sound like having two silos that work separately, and it is not good for the start. Nobody says, though, that the TSC can't organically grow into two separate groups in the future.Value work more than moneyWe want to have a TSC consisting of all the active committers in the project, not people who are there because their company is a sponsor of the project. You are a TSC member because you work on the project, you code, write docs, maintain CI. You work, and therefore, you are a part of the initiative.Why? Don't you like money?We like money, don't get us wrong here😃Money helps the project a lot, we can sponsor many good things with the money we obtain from you.Nevertheless, we believe that it isn't good to run a project alone with lots of bucks in the pocket.What? We need a doctor here!🤷‍♂We just prefer to work with a large group of people, from different cultures, from other parts of the world, with diverse experience and use cases in heads. That is just how you build great products by having many people around you to help and validate the ideas actively.Respecting committers and the right to voteThe rule we want to follow is that the committer automatically gets a right to vote.Why?Voting is always about essential things, essential for the entire initiative. Who else should have a right to vote if not people that are directly affected by the decisions of the ToC? The tricky situation here is that this approach can lead to a problem where one company hires most committers and, therefore, takes over project steering. This is something we actually have at the moment. The majority of folks working actively on the project are from Postman. Nothing terrible happened to the project for now, but this doesn't mean the whole community feels comfortable.We had a tough brainstorming here about finding the right balance between respecting all contributors equally and still making sure that there is no risk that a company has most voters. That is why we have a rule that only 1/4 of voters can be affiliated with the same company. Or 1/3 in case we need to look for more maintainers to bring balance back to the force.Work on all the tools under the AsyncAPI umbrellaWe want AsyncAPI Initiative to be a place where AsyncAPI open source tools are developed, together, so we do not duplicate each other in the community with different variations of the same tool. So far, seven AsyncAPI tools resulted from different companies or individuals' work and moved to the AsyncAPI GitHub organization. We want this to become a standard in the community.The governance model embraces this direction. How?If you own a project, you created it. It means you are its committer.Do you see where We're getting?Yes, it means that once you donate the project to the AsyncAPI Initiative, you do not only stay there as a committer but also become a voting member.No meetings - async all the thingsWe hate to have too many meetings. Meetings suck out your blood. Meetings = schedule and schedule = leash.Zero meetings? No, we will have something on the schedule, but it will not be mandatory. We will not make decisions during the meetings, so you do not have to rush to be there. You just need to watch the recording to learn if there is something relevant for you if there is a topic that needs voting. Decision-making should be asynchronous, and people should have time to make wise decisions.The async decision-making process also assures that the number of voters can scale up easily, and we should be able to handle as many committers in the group as we have. We can automate many things here.Wishful thinkingWe hope that a side effect of such an open governance model will be that companies will have a better motivation to sponsor the initiative financially and assign employees to work on the spec and tooling regularly to become committers and become voting members of the TSC.Hopefully, these companies will take shortcuts here that will open up new job opportunities for individual contributors.That was not our initial goal, though. We just figured that this might happen, and we look forward to it.I hope this rough explanation makes it easier to digest the charter. Please share what you think. UseTwitter,Slack, email. Write publicly or privately. We just care about the feedback and not how you pass it on.You can also comment onthispull request with the charter. You can leave generic comments that we could reuse in official communication after we join the foundation.Cheers🍻Photo byUnited Nations COVID-19 ResponseonUnsplash
"""
--------------------------------------------------------------------------------


Post 96
ID: https://www.asyncapi.com/blog/january-2021-at-asyncapi?utm_source=rss
Title: January 2021 at AsyncAPI
Link: https://www.asyncapi.com/blog/january-2021-at-asyncapi?utm_source=rss
Summary: I always thought January is a month of a slow start of a new year. I could not have been more wrong. No time to rest, no slow down here.
Content:
"""
A new year always comes with New Year's resolution, right? Folks fromBump.shcame up with the best idea you could get this year. Don't you dare to fail this time😃Foundation and open governance modelAs part of recentlyannouncedpartnership with Postman, most core AsyncAPI maintainers joined Postman as employees. This change made it clear that now it is even more important what we planned in the past.AsyncAPI must go into a "neutral ground" aka independent foundation that, among other things, will take over the AsyncAPI intellectual property.Joining a foundation also means setting up an open governance model to ensure a single company's lack of dominance over the specification and its tools.As communicated during our public meetings on2nd of Februaryor19th of January, or our officialTwitter account, Fran and I treat this topic as priority number 1.At the moment, we are trying to figure out a governance model that:is as democratic as possiblesupports asynchronous decision-making processgives power to people that "work", not companies that "pay". In other words, it gives equal power to both, individual and corporate contributorsNow we spend a lot of time reading and reaching out to similar communities that went this path and know what booby traps to avoid to stay healthy. We hope to share something more concrete in the next update, in March.New bronze sponsorWe kicked off this year with a new bronze sponsor. Thanks a lot to Bump.sh and their trust in the AsyncAPI Initiative, and being among the first ones adopting the AsyncAPI specification in their product.Community continues to growMylast postthat summarizes the year 2020 was pretty clear that the community's size grew a lot. Well, it is January, and we see that not much has changed. We keep growing:we went over 1k users on Slack.Join nowwe went over 1.5k followers on Twitter.Follow usto be up to date with the latest news in the projectwe went over 1.4k stars on GitHub. If you like the project,express itwe had several issues solved by the community members from different companies, including few new features. For more details, readFeature releases and community-driven changessectionLast but not least, we beat the record of people joining our public meetings🚀RapidAPI Developer SurveyRapidAPI released the results of theirdeveloper survey. Reading it at the beginning of the year is like drinking a strong coffee in the morning - you get a good kick of positive energy for the rest of the year.Spoiler alert -> number of developers using AsyncAPI in production tripled in 2020.Feature releases and community-driven changesPavel Bodiachevskiicontinues his hard work onasyncapi-java. Wait, it is finally notasyncapi-javaanymore. Thanks to a suggestion fromJames Higginbothamit is all aboutjasyncapinow. Maven, Gradle and IntelliJ plugins are not published as a preview release under official AsyncAPI accounts. Please give them a try and share your feedback.React component:showsrequired flag for required propsthanks toc-piusfromSAPwe have betterDX in Web componentthanks toViacheslav TurovskyiPlayground now showsmuch detailed errorsthanks toJorge Aguiar MartínfromLean Mind - esHTML template:CSS size decreased and introduction of Tailwind 2.0thanks toJulian SchaferCorrelationId renderingthanks toLudovic DussartfromIneatLabTypeScript NATS templateWe have anew templateavailable. You can use this template to generateNATSclient based on the AsyncAPI document for Node.js. Interesting fact: it is already using the newReact render enginefrom the AsyncAPI Generator.Next major feature is data model generationWe again invest big-time in the Generator. This time, it is all about making it super easy to generate a data model for templates, so the template developer doesn't waste much time on templating it and can focus on the template's main logic. In other words, it is all about enabling faster template development. Ourprogresslooks good, and it seems like at the end of February, we should already have something that you can start using.Feel free to share your thoughts inthisissue.Refactoring of our CI/CDGitHub Actions is what powers our CI/CD. It is a great tool that you configure through a file stored in a repository. Things are just getting more complex when you want to use them in an organization with around 40 repositories (and growing). This is not a post about our internal organizational challenges and GitHub Actions limitations, so I will not bother you with details. The most important is to share that we are managing our GitHub workflows like a pro and if you are interested in more details, contact us.So what changed that is meaningful for our community:We have two new channels in Slack workspace:#github-releases where you get information about all the releases from all the repositories#github-new-issues-prs where you get information about all new issues and PRsWhenever we have a major or a minor release in any repository, our bot automatically tweets about itAll pull requests are now tested against Linux, MacOS, and Windows. For you, this means that we fixed a lot of bugs in tests and configurations that were blocking Windows users from smooth contributionsNot used to Conventional Commits specification? now all pull requests have a dedicated check that lints your pull request titles and gives hints what you should fixYou contributed something to the JavaScript Parser, and you wonder what you have to do to see the change in the Generator? No need to wonder. Now, when we release any package, we also bump its version in all the other packages that depend on it. AsyncAPI bot is a super busy bot🤖The future of API specificationsWorking with specifications is not easy because there are many of them. How do you know when to use which one? Just look at the concept of microservices architecture. Did you think that monitoring, scaling, and tracing is a challenge? What about specifications:you need a different spec for your backend that exposes GraphQL API to your frontendyou need another spec to describe how a user can interact with your service using asynchronous communicationyou need a different spec to define how a user can interact with your service with RESTWhat about specs for describing your data model? What about if you use RPC and Protobuf? What if you use Avro? or maybe you only use JSON Schema.Why do you have to define the same things over and over using different specs...Something went wrong down the road, and we need to do something to save the chicken.Watch Fran's presentation on the future of API specification. And don't stop there. We don't want only to admit we know about the problem and expect someone solves it. We want to fix it. Join us!Public meetingsFor notes and links to recordings, look into the below references:Jan 5 2021Jan 19 2021Spoiler alert -> leading topic during the meetings wasthe status of AsyncAPI.Next meeting is scheduled forFeb 16 2021for8AM UTC. Feel free to suggest a topic or such join to say hello.Google Summer of CodeThis month we want to apply forGoogle Summer of Code. We found two volunteers that agreed to mentor participants to work on some good stuff for the AsyncAPI tooling space. January was when we collected all the possible ideas that we would work on together with students. Thelist of ideasis completed. There are many good proposals there, and most of them won't make it to the event, so feel free to let us know if you want to work on them under the AsyncAPI umbrella.Good readAsyncAPI and OpenAPI: an API Modeling ApproachbyAntonio GarroteAPI adoption is on the rise across all industriesHow Microcks Can Speed-Up Your AsyncAPI Adoption - Part 2byLaurent BroudouxSimplify code generation with ReactbyJonas LagoniandMaciej UrbańczykThat was an exhausting month, but looking at what is happening around the project, you feel it was worth it. Let us see what February brings.Photo byNicolas HoizeyonUnsplash
"""
--------------------------------------------------------------------------------


Post 97
ID: https://www.asyncapi.com/blog/react-as-generator-engine?utm_source=rss
Title: Simplify code generation with React
Link: https://www.asyncapi.com/blog/react-as-generator-engine?utm_source=rss
Summary: React permanently changed the way how developers write web-apps. Personally, we love React and knew it would solve many pain points we faced with Nunjucks. Therefore in the last cycle we integrated it
Content:
"""
React permanently changed the way how developers write web-apps. Personally, we love React and knew it would solve many pain points we faced with Nunjucks. Therefore in the lastcyclewe integrated it as a template rendering engine into ourGenerator. This post is a short introduction for developers who write or plan to write templates for AsyncAPI specification using React. It also includes a comparison with the default Nunjucks renderer.Getting startedYour React template requires@asyncapi/generator-react-sdkas a dependency. You need it to access theFilecomponent required as a root component responsible for rendering a file. Furthermore, it provides some common components to make your development easier, likeTextorIndent.Let's consider a basic React template file as the one below calledMyTemplate.js:1import{ File, Text }from"@asyncapi/generator-react-sdk";23exportdefaultfunction({ asyncapi, params, originalAsyncAPI }){4return(5<Filename="asyncapi.md">6<Text>Some text that should render as is</Text>7</File>8);9}The exported default function returns theFilecomponent as a root component that theGeneratoruses to figure out what file it should generate. In the example above, we overwrite the default functionality of saving the file asMyTemplate.js, and we setasyncapi.mdas the filename. Using theTextcomponent, we specify what content should be rendered inside the file. The content of the resulting file is:Some text that should render as is\n. Notice the\ncharacter at the end. It is automatically added after theTextcomponent.For further information about components and their props, see theGenerator React SDK.TheGeneratordoesn't use React renderer by default. You need to specify in the template configuration that your template is based on React. For that, change therendererfield ofgeneratorobject inside the template'spackage.jsonfile:1{2...3"generator": {4"renderer":"react",5...6}7}You can find more information about the Generator configurationhere.How it worksThe process of creating content from React components consists of two steps: transpile and render.The SDK has a custom transpiler which ensures that any directory in template'stemplatefolder are transpiled usingRollup. Rollup helps bundling all dependencies and transpile them into CommonJS modules. This is required because this library will be used through NodeJS (by AsyncAPI Generator) which does not understand these new modules natively and we do not want to limit the developer in which syntax they prefer nor how they want to separate code.Also, SDK has its own reconciler. It traverses through each element in the template structure and transforms it into a pure string. Propchildrenis always converted to a regular string and stored in thechildrenContentprop in each component. Check the below example, to see how it works. In addition, you can also see how to apply the composition to templates using components:1import{ Text, Indent, IndentationTypes, render }from'@asyncapi/generator-react-sdk';23classClassComponentextendsReact.Component{4constructor(props){5super(props);6}78render(){9// In `childrenContent` prop is stored `text wrapped by custom component\n\n`.10// The content of the `children` prop is transformed to string and saved to the `childrenContent` prop.11returnthis.props.childrenContent;12}13}1415functionFunctionComponent(){16return(17<Indentsize={3}type={IndentationTypes.TABS}>18indented text19<ClassComponent>20<TextnewLines={2}>21text wrapped by custom component22</Text>23</ClassComponent>24</Indent>25);26}2728// content will be `\t\t\tindented text text wrapped by custom component\n\n`29constcontent = render(<FunctionComponent/>);There are some restrictions:React hooks feature is not allowed.HTML tags are not supported.React internal components likeFragments,Suspense, and others are skipped.Comparison with NunjucksThe AsyncAPI generator still usesNunjucksas a default render engine. It's a templating language, heavily focused on string literals, filters (similar to bash pipes), and partials called macros.The next sections compare how you can accomplish certain things in Nunjucks and React. For more complex examples, see thetemplate-for-generator-templatesrepository with examples based on React and compare those withnunjucksbranch.Creating reusable partsIt may sound obvious, but when writing any code, even a template, a programmer wants to create reusable parts that separate repeating logic.In Nunjucks, you can reuse parts of the template usingmacros, in React, usingcomponents. Imagine that you are writing a template that produces Markdown content. You need to create a reusable macro/component that renders a list from an array of strings.Using Nunjucks you can write the code below:1{% macro list(data, type ="-") %}2{% for item in data %}3{{type}} {{item}}4{% endfor %}5{% endmacro %}67{% from"partials/list.njk"import list %}8{{ list(["one","two","three"]) }}Using React you can write the code below:1functionList({ list = [],type="-"}){2returnlist.map(item=>`${type}${item}\n`);3}45// use `List` component in another component6exportfunctionSimpleList(){7return(8<Listlist={["one", "two", "three"]} />9);10}Looking at both examples we see that in Nujucks we operate on string literals, it means that when passing data to a macro, you always need to know what type of data the macro takes. In React we operate on JS objects/variables. By this, your IDE should always inform you what value, of what type, you must pass to component. Additionally, you must place Nunjucks's macro inside thepartialsfolder of the template. Using React, you can put your components wherever you want.Using third party packagesUsing helper functions from third-party packages, in Nunjucks you must apply them asfilters. For example, you want to use one function fromUnderscore.stringlibrary likecleanDiacritics, which replaces diacritic characters with closest ASCII equivalents. To do this, you must create a function insidefiltersfolder to convert the function to Nunjucks's filter:1// filters/cleanDiacritics.js2constcleanDiacritics= require('underscore.string/cleanDiacritics');3constfilter= module.exports;4filter.cleanDiacritics= cleanDiacritics;And then you can use this function inside your template/macro:{{Urbańczyk| cleanDiacritics }}# will be UrbanczykThe main problem with this solution is that it creates an unnecessary boilerplate - you must create a function in a separate file. Another problem is that you operate on the name of this helper function which means you must always remember what filters you have included in your template.In opposite, in React you can useUnderscore.stringdirectly in your template:1importcleanDiacriticsfrom'underscore.string/cleanDiacritics';23functionMyComponent(){4returncleanDiacritics('Urbańczyk');// will be Urbanczyk5}It is worth mentioning that when using packages in this way, you always operate on the reference to the function, not on its name, so you know what functions you have in the file's scope.Cons & ProsLike any solution, React has its advantages as well as disadvantages.AdvantagesUsing React, you use JS directly. You don't need to learn custom Nunjuck's syntax, only how React works under the hood.It provides better debugging functionality that is not possible with Nunjucks.It provides better error stack traces.Better tools support development. You write templates in JavaScript, you use a reference to functions/variables, and therefore your IDE can tell you what you can use in a given scope.Provides better support for separating code into more manageable chunks/components. You don't need to createpartialsfolder. You can create React component wherever you want, also next to the template's source code.You can easily test your components. It is difficult with Nunjucks. You can split template file into separate chunks and test them in separate test cases.DisadvantagesCommon pain when writing templates with React is related to indentations and new lines. However, we have several helpers in SDK to make your life easier, likeIndentorTextcomponents.Some people don't like to mix logic inside template files, so probably React won't be friendly for them.HTML tags at the moment are not supported. The developer must write them as a string literal, likehere.ResourcesWe use React render engine already in three official AsyncAPI templates:template-for-generator-templatestemplate showcases features ofthe AsyncAPI Generator, including the React renderer. It shows how to write templates, reusable parts (components), what are the recommended patterns. It has simple and complex examples. You can also check how the same things could be done using Nunjucks inthisbranch.markdown-templateis written using React. It generates documentation into a Markdown file.ts-nats-templateis re-written using React to generate a TypeScript NATS client.If you want to check the source code of React renderer, go to theofficial repository.SummaryThere is a long way ahead of us to stabilize React as a render engine. We know about problems that make it unpleasant to write templates using React, such as indents or new lines, but we will work on that. Additionally, we have a couple of improvements on our list that will allow things likeFile Templatesto be simplified in the Generator. We also plan to supportTypeScript.We are waiting for your feedback.Happy coding!Cover photo is fromDrunken Mastermovie.
"""
--------------------------------------------------------------------------------


Post 98
ID: https://www.asyncapi.com/blog/microcks-asyncapi-part2?utm_source=rss
Title: How Microcks Can Speed-Up Your AsyncAPI Adoption - Part 2
Link: https://www.asyncapi.com/blog/microcks-asyncapi-part2?utm_source=rss
Summary: On our first AsyncAPI blog post we have introduced Microcks 1.0 General Availability (GA) as a unique milestone for mocking and testing event-driven API like any other APIs through the support of Asyn
Content:
"""
On ourfirst AsyncAPI blog postwe have introducedMicrocks 1.0 General Availability (GA)as a unique milestone for mocking and testing event-driven API like any other APIs through the support of AsyncAPI specification.In case you missed it, we have already releasedversion 1.1.0in the meantime. This release includes some nice enhancements related to the topic of the day:Microcks + AsyncAPI use cases using Apache Kafka. This post will show you how Microcks is leveraging the AsyncAPI specification on Kafka in a very pragmatic and powerful approach: way beyond documentation or code generation! We will also go through the different business use-cases implemented by users integrating Microcks in their asynchronous API toolchain.When we are talking about Kafka we mean all Kafka distributions translated intothe choice is yours: from vanilla Apache upstream distribution, to enterprise products and also cloud providers’ managed distributions!By the way, we will be happy to have some QAcontributors and reportson more brokers and AsyncAPI supported protocols😉Before diving into AsyncAPI on Apache Kafka, let first see why simulating producers is a key project success factor.Why simulating producers is a key project success factor?As good developers, we are lazy - in a very good way😉- and hate to restart from scratch our beautiful code implementations due to misunderstanding with Product Owners. However, nowadays Product Owners adopted and love theFail-Fast Principle. We can't rely on functional implementations to start beta testing with consumers, we should fail fast and make them change requirements before we start implementation.Apart from generating frustrations, this above situation is also very inefficient from a cost and time to market point of view for the organization.The contract-first approach is a wonderful way to create strong and efficient agreements between functional / business / product owners and developers! But it represents only a partial answer to the above situationTo avoid unnecessary work from developers and speed-up feedback gathering from consumers, simulation is the second part of the answer. That is why Microck's first use case and the killer feature is mocking!These are some of the reasons why the way to do mocking with Microcks is highly scalable:We rely 100% on Product Owners contractsWe rely 100% on standards and specifications to describe contractsWe automatically generate all APIs mocks from contracts: no code!We publish APIs mocks like real implementations using specifications examplesWe centralize all contracts and are the single point of trustWe are always in sync with your repositories: no drift anymore!We provide sandbox at scale. You can heavily stress tests your business rules. Remember, we are Kubernetes-native!This is why Microcks is the ultimate way to test, iterate and speed-up your APIs validations before asking developers to code the real implementation! And this certainly applies to asynchronous API on Kafka too: thanks toAsyncAPI specification.Now let’s start with first feature: mocking asynchronous API.Mocking asynchronous API on top of Apache KafkaThis is how Microcks value proposition of accelerating Kafka asynchronous API simulation looks like:In a very pragmatic approach, Microcks uses your AsyncAPI specification as the source of truth for your simulation. As soon as it is imported into Microcks, it manages to create a topic for your API version on the connected Kafka broker and starts publishing mock messages. Messages are published at a configured frequency and thus consumers immediately start receiving event messages as if it is published by a real application. Thanks to Microcks’message templatingyou can also easily include dynamic content in the sample messages.Mocking event-driven architecture using Microcks is a game-changer as you do not need to write code nor set up complex infrastructure! Your consumers can receive messages in the minute. Testing some changes is just one commit away. You update the AsyncAPI specification in the Git repository and Microcks will take care of updating everything! It's even capable of providing and managing the Kafka infrastructure thanks to the excellentStrimzi.iooperator if you wish! See ourEverything managed by Microcksdeployment option🚀Our second feature is testing or how to make your delivery lifecycle reliable.How to make your delivery lifecycle reliable?As the number of event producers and subscribers is exploding, managing changes and taking care of versioning compatibility is essential. And what about checking that business rules implying event triggering are correctly implemented? The fact it produces syntactically correct events and all this in a fully automated way based on each change and new commit in your source code repository?Again this is all provided by Microcks thanks to its capability to interoperate with your CI/CD pipeline using our plugins forJenkins,Tektonorany other CI pipeline technology like GitLab. You'll typically use these plugins to trigger a Kafka test in Microcks.In Microcks, testing Kafka endpoints means connecting to a remote Kafka topic on an existing broker in the organization, listening for incoming messages, and checking that received messages are valid against the event-based API schema that is referenced in your source of truth: the AsyncAPI specification. You can find further technical details on the blog postmocking and testing Apache Kafka API using Microcks.Testing of event-driven architecture is no longer a nightmare with Microcks! Microcks can connect to the Kafka brokers in your organization and tell you if the received messages are valid according to your specification. No drifting risks anymore or way to introduce regression in production! You'll drive and control everything from your pipeline.What are the business use-cases of AsyncAPI? Where can you use Microcks as an essential part of your toolchain?Business use-cases of AsyncAPIAs said before, event-driven and asynchronous APIs are becoming mainstream because we truly understand the decoupling level - and thus power and agility - it brings within our products. We see the need for asynchronous APIs and Apache Kafka's presence as the de facto standard for message brokering - everywhere.In every business vertical: to decouple a recording action (registration, purchase, like) to a marketing reaction (CRM update, behavioral analysis, marketing notification, renewal process management, etc...)In Governmental organizations: to synchronize complex and partitioned repositories using master data management and staging pipelines techniquesIn Financial Services: to streamline the sharing of information between core platforms and distribution ecosystems of partners,In Industry: to enable Industry 4.0 to use IoT and become more agile to respond to market unpredictability and improve quality,Soon in every Citizen's life: to power tomorrow Smart Cities with IoT and enable smart real-time insights and decision making.These use cases come from companies using Microcks for simulating and testing their API implementation, and we are thankful to our users and community.SummaryWe are convinced that cutting edge developers understand the purpose, usages, and efficiency of asynchronous mechanisms. To take all its advantages and especially to use an AsyncAPI contract-first approach: developers must work hand in hand with software architects, business/product owners within the enterprise. In our humble opinion, this is clearly a strong point of attention to improve collaboration between enterprise silos and take the quintessence of AsyncAPI specification for a contract-first approach using Microcks as the ultimate tooling for mocking and testing purposes. Please read ourprevious blog post on this topicand share it with your software architects😉We hope these two Microcks features - mocking and testing - and application use-cases are clear and you now better understand our value proposition. Microcks proposes a very pragmatic and powerful usage of AsyncAPI specification: way beyond documentation or code generation! It allows you to speed-up and makes your delivery of Kafka event-driven architectures reliable.The roadmap ahead is also full of exciting new features we are looking forward to:Continuing to make AsyncAPI full potential bloom through implementing multiple schema format supports - like Apache Avro - andadding examples in the spec,Taking advantage of multiple protocol binding capabilities, releasing very soon aMQTT implementationto support our users and prospects on the IoT landscape,Solidifying an initiative we started a long time ago about a shared repository of simulation and test suites for standards or products APIs...We are open and you can help make Microcks an even greater tool! Please spread the word, send us some love throughGitHub stars, follow us onTwitteror join our chat room onZulip.
"""
--------------------------------------------------------------------------------


Post 99
ID: https://www.asyncapi.com/blog/2020-summary?utm_source=rss
Title: Awesome 2020 and What Can Get Better In 2021
Link: https://www.asyncapi.com/blog/2020-summary?utm_source=rss
Summary: Fuck you COVID-19, AsyncAPI Community is stronger than you think. See the growth of AsyncAPI in 2020 in hard numbers. How we compare to 2019?
Content:
"""
🖕COVID-19AsyncAPI Community is stronger than you think.See the growth of AsyncAPI in 2020 in hard numbers. How do we compare to 2019?This post is based on quantitative data using metrics from different platforms where AsyncAPI is present. I collected this data between 15-17.12, so they are already a bit larger by now. I'll try to confront our qualitative knowledge, what we know from discussions with others, and our observations.This post is not 100% just in numbers and analytics. It is also a summary of all the important things that happened to the project this year.Important momentsOur first everAsyncAPI Online Conference. This pandemic edition turned out to be a very successful event that powered us up for the rest of the yearWe took active part inHacktoberfestas maintainers and increased the number of contributions to the projectAsyncAPI was featured in InfoQ'sSoftware Architecture and Design InfoQ Trends Report—April 2020that directly brought 1963 new users to the AsyncAPI websiteAsyncAPI showed up onTechnology Radarthat took 1051 users directly to the AsyncAPI websiteOur two core tools reached their first major releaseJavaScript ParserGeneratorAll those moments lead us to the most important one: thepartnership with Postman.Slacktl;dr AsyncAPI community activity onour Slack workspacedoubled!Figure 1: Slack active members weeklyNumbers getting highI don't think the below tables require any introduction.January 2019January 2020December 2020Messages posted278825388(+22600)76609(+51221)Number of members159432(+273)888(+456)More members means higher activity😅20192020Weekly members activity45 average42 median81 average76 medianMost present companiesI was also super curious to check out where our members are coming from. The only way to do it was by checking the domain of their emails used during registration. Yes, this is not 100% accurate. Not all people use company emails in open source. It is visible in data; half of the users have thegmail.comdomain. Nevertheless, the result of my investigation is pretty accurate with our knowledge. The ones that have more than three representants:mulesoft.compostman.comredhat.comsap.comsmartbear.comsolace.comtibco.comworldpay.comSome of these companies sponsored our work in 2020. The ones that didn't... don't worry, we'll contact you😉In 2021, we want to go into a neutral ground (i.e., joining a foundation). There'll be no more excuses.What's next with SlackSlack hard numbers confirm what we see in Slack every day. Luckily, even though the activity doubled, the number of active users that help out in the workspace also grew🙏With the recently announced Postman partnership, I do not worry about how we'll handle 2021.Next year we need to address two critical topics:our community grows but the knowledge that we all share in Slack is lost. We use a free version of Slack, and therefore, only the last 10k messages are available. In 2021, we need to make a strong decision on what's next. Should we spend some budget on Slack commercial subscriptions, or maybe we should find a better tool?we need to reorganize our channels, be a bit more granular, and target suitable community groups. We'll bother you to get your feedback once we start this reorganization.LinkedInLinkedIngrew a lot this year. We won't be able to compare this year with the previous one because... this is not a place where I want to discuss the experience you get with LinkedIn.Followers and impressionsAt the moment, we have 757 followers.FollowersLikesImpressions61157 from payed marketing125380095People that like our updates are most likely the ones that click on links. 75% (947) of likes converted into visits to ourwebsite. We took this data from Google Analytics, and we know that in 2019 we had only 137 visits from LinkedIn.The most performing update was the one about thepartnership with Postman. It is LinkedIn, and it is all about business.The chart below shows that data match reality. The highest peak in late March is related to our firstAsyncAPI Online Conference. The rise of sponsored traffic is connected to our post-conference activities using the money we got from conference sponsors.Figure 2: Impressions to updates in 2020Sponsored marketingThis year we explored paid adverts on LinkedIn. We had some money left from sponsors of our AsyncAPI conference but zero experience with LinkedIn.Luckily, we have a fantastic community. One of the community members,Dan Weese, helped us here. He did not only put us in contact with marketing expert,Charles Serdoubut also covered his wages. Thank you, Dan🙏This way, we covered only LinkedIn costs paying $1 074,08Figure 3: Followers growth in 2020Marketing was focused on increasing the number of followers. Comparing the results of sponsored marketing with followers' organic growth, one could say LinkedIn marketing was not so good. It was very good though. LinkedIn is just super expensive and charged a lot for every new follower.We should give it a second chance in 2021, but this time with sponsored updates.What's next with LinkedInThe numbers show it is worth investing in the channel. We can reach a lot of people that are not reachable on other channels. So we will for sure continue what we do now, especially that this work doesn't require too much extra effort from us.I feel that probably some traffic coming from LinkedIn to our website is not adequately tracked in Google Analytics. Data from LinkedIn say we should notice 2x947 traffic. It might be related to people blocking tracking tools, and we will have to make sure to use other tracking methods, like putting identifiers in the links.Google AnalyticsWe use Google Analytics onAsyncAPI websitebecause we want to understand what content is most valuable for you, and we want to learn how the interest is growing.Traffic got much higherThe interest is growing by a lot! Our website handles it well with the support ofNetlify, which is free for open-source projects.20192020Unique users visits27 09080 399(+53 309)Number of sessions50 405142 229(+91 824)Unique pageviews143 059348 131(+205 172)Top referring channelsIf we look closer to the statistics to check out how people learn about AsyncAPI, referral channels keep pretty much the same share of the pie, just numbers grow.Figure 4: Top channels in 2019Figure 5: Top channels in 2020In 2019, the most viral was the information about AsyncAPI 2.0 release, while in 2020, the blog post about how weautomated releaseson AsyncAPI packages to speed up work.Top blog postsAsyncAPI blogis not just for Fran and me. It is for the AsyncAPI Community. Anyone can share knowledge, experience, and showcase their work there. Justlet usknow what you want to write about.What is the benefit of writing/republishing on the AsyncAPI blog? Visibility among the AsyncAPI community plus our activities to make your work go viral. Just look at the below table to see our top 3 viral posts.PostUnique pageviewsAuthorFull automation of release to NPM and Docker Hub with GitHub Actions and Conventional Commits(March 2020)9 318Lukasz GornickiAsyncAPI Code Generation: Microservices Using Spring Cloud Stream(June 2020)8 508Marc DiPasqualeAn API Strategist Explores Event-Driven APIs(May 2019)3 451Emmelyn WangWhat's next with the websiteWe need to enable Google Search Console and connect with our Google Analytics account. It will increase our knowledge about how people google before they get into the AsyncAPI website. Knowing how people find us, we can focus on more content related to search queries.We need more posts on our blog. 2020 shows this is something that increases traffic. We already welcomed many guest bloggers, and youcan becomeone of our writers too.TwitterBy the time I gathered data for this blog post, we had 1433 followers on Twitter. 876 followers joined us in 2020. It is a large increase since the account creation back in March 2019.Paid marketingWe used money from our AsyncAPI conference sponsors to advertise the conference on Twitter.We spent $924,14 on this activity and when we compare it to organic impressions over this year, result is just great:Organic (549 tweets)Promoted (3! tweets)Impressions570 466525 329Retweets1 42977Likes2 507567URLs clicks2 7592 283Follows435Nothing is black and white, even Twitter performance. One could say:leave organic growth and invest in paid marketingWe do not treat Twitter as just a marketing channel. It is our window to the community. We use it to share updates, short information and engage directly with our community members. We should continue to work on organic growth. It converted only into 2 160 sessions to the AsyncAPI website, which is not much if we compare it with 2 283 sessions opened with the AsyncAPI Conference website using promoted content. We do not want to close the window, though.It's all about keeping the balance⚖️Top tweetsWe did some research on the most impressive and engaging tweets.TweetImpressions15k14k9kThere is only one tweet that shows up in the top 3 for each category.TweetEngagements428259253(not all those memes were lame after all)It is pretty clear that what you liked the most this year is that we are hiring💪We are still hiring!What's next with TwitterWe should get more insights into how Twitter activity converts into visits to our website. Twitter offers something calledconversion trackingwhich seems like a perfect fit, and this is something we will enable for next year.Paid marketing on Twitter is useful, so we will continue using it for important events.GitHubWe notice growing traffic inour GitHub organizationlike on other channels.Most popular repositoriesOur most popular repositories contain the AsyncAPI specification and the AsyncAPI Generator that the community can use to generate documentation and code.The asyncapi repositorythat had 245 stars in 2019 jumped to 1361. The peak you see on the diagram was caused by us putting the link to the asyncapi repository onHacker News.Figure 6: GitHub stars growth in asyncapi repositoryThe generator repositorygrew from 62 to 198. The path got steeper this year. This popularity is covered with our recent development activities in the project.Figure 7: GitHub stars growth in generator repositoryTraffic growthAll numbers went up😅The growth of contributors was not organic but driven by our activities in theHacktoberfestevent.20192020Contributors76119Commits1.5k3.5kPull requests (opened/closed)399/39799% closed1200/117597% closedIssues (opened/closed)322/28789% closed587/40168% closedWe're closing fewer issues. This number got worse than last year because we freeze progress on the asyncapi repository, and the last few months did not continue any efforts towards specification 2.1 and 3.0 releases. The reason was pretty simple; we were involved in discussions with many players and planning the next step forward to scale up in 2021. It would not be fair with the AsyncAPI community to work on the next specification versions, with the current government process, knowing we preparepartnership with Postman.What's next with GitHubWe are doing well on GitHub, and so far, I don't see any improvements other than the further automation that we have in plans to handle even more traffic next year.npmThe majority of our tools are written in JavaScript/TypeScript, and we host them on Node Package Manager(npm)Top packagesOur most important packages arethe Generatorandthe Parser. Below you can see how downloads of these packages increased.20192020Generator21 536134 224Parser (published May 2019)18 591173 286The change in numbers is so huge that I checked them twice to make sure I'm not wrong.Figure 8: Popularity of all packages on npmIf you know the package from the above list had some different names over the year, you can check it withnpm statproject. For example, late in the year, we moved the React component under@asyncapi, and under the old name, it had 56 520 downloads. Next year won't be so messy.What's next with npmThis year we introduced@asyncapiscope on npm and switched all packages to it. You could see some differences in numbers in previous sections because for the generator and parser I manually counted the sum of downloads of a package under different names.There are still many downloads of the parser and generator using old names. It means we still have many people that do not migrate to new releases. Next year we could write a blog post that summarizes the differences between old tools and their latest versions. It could be linked to the deprecation notice.YouTubeTheAsyncAPI YouTube channelhad a massive increase in the traffic.Watch time goes crazyWe felt it might be significant because of the AsyncAPI conference, but we never expected a 6000% growth of the watch time!20192020Views5278 678Watch time29.9h1 850.1hSubscribers35390Most popular videosUndeniably the most popular this year was our first AsyncAPI online conference.ViewsAuthorAsyncAPI Online Conference4 123AsyncAPI CommunityAsyncAPI SIG meeting 37 (December 8, 2020) - SPECIAL EDITION!542AsyncAPI CommunityEvent-Based API Patterns and Practices354James HigginbothamIn case you missed our conference, watch the recording and stay tuned for the next conference in 2021.What's next with YouTubeI think it is the right moment to work on the channels' landing page. We could use it to promote the most valuable content.Open CollectiveWe earned and spent lots of money this year🤑Huge applause👏to allour sponsors!We enabled theGitHub sponsoringthis year, but still, 99% of funds go through theOpen Collective.SourceAmountBalanceAsyncAPI Online Conference$983 Swags for participants$359,10WWC donation$1 074,08 LinkedIn marketing$924,14 Twitter marketing$66,54 Zoom account$0AsyncAPI Initiative$52 371 Maintanance$3 750JSON Schema$1 493,64In 2021 we continue using Open Collective. Even though we startedpartnership with Postmanto cover many maintenance costs, there are other costs. Even once we join some foundation next year, we still need to collect money to run the project.Ultimate questions - how many people use the spec?We don't know.It is the area where we have no specific metrics. We see the growth in tools' adoption, but not everybody uses open source tools. Many companies prefer to develop those in-house.From observations, we know that number of users that use specification grows:More and more companies seek integration with the specification. From unofficial discussions, we know their customers ask them about AsyncAPI supportThe metrics from this blog post clearly show adoption and interest growthIt is a specification we are talking about here. There is no way to measure how many AsyncAPI files were created worldwide. At least there was no way to do it in 2020. We'll tryone ideaof ours in 2021. It looks like in the 2021 summary, we could provide some hard numbers on the subject🤞Final wordsMost important conclusion: If the AsyncAPI conference brought so much activity, it is evident that in 2021 we must organize another great AsyncAPI event.Thanks for being with us in 2020, and stay with us for 2021 as it will be epic!I planned to include a list of all the AsyncAPI Heroes for 2020, but I was afraid I could miss someone very important and that the list would be very subjective. I hope it is clear, though, that this project is where it is, thanks to many guardian angels out there that help us out.Photo byImmo WegmannonUnsplash
"""
--------------------------------------------------------------------------------


Post 100
ID: https://www.asyncapi.com/blog/asyncapi-partners-with-postman?utm_source=rss
Title: AsyncAPI partners with Postman to boost development of Asynchronous APIs
Link: https://www.asyncapi.com/blog/asyncapi-partners-with-postman?utm_source=rss
Summary: I'm proud and honored to let you know that we're partnering with Postman to boost the development of Asynchronous APIs to a new level.
Content:
"""
I'm proud and honored to let you know that we're partnering withPostmanto boost the development of Asynchronous APIs to a new level🚀Since the very beginning, I knew the duty we had at hand was challenging. And still is! The specification was just the trigger of a snowball effect. What's the spec for if you can't do anything with it? Tooling is as important as the specification. However, tooling is a number of times more complex than the specification. We engineers don't want to abandon our favorite programming language and framework, therefore, it's AsyncAPI's responsibility to integrate with the existing tools in the market.The specification (and tools) should work for the user, not the other way around.Partnering with Postman allows us to boost the development of more and better tools to help engineers create and maintain Asynchronous APIs while using their favorite programming languages and frameworks.Our goal is to make Asynchronous APIs as successful and mature as REST APIs.We are aware this is a long journey but, with Postman's help, we'll be able to grow the team and continue working on the AsyncAPI specification and all the necessary tools to create a delightful developer experience. The AsyncAPI Initiative team is fully committed to open source software (OSS), and the partnership with Postman will help us keep doing our job with freedom and independence.Next stepsWe want to make the AsyncAPI Initiative a neutral and independent place for collaborating on defining the future of Asynchronous APIs. Next step for us is to host the project in a neutral foundation to guarantee the long-term success of the initiative. We're currently in conversations with different actors of the OSS world to make sure the initiative remains independent.Also, we want you to work with us.We are hiringat Postman to work full-time on AsyncAPI. In the first half of 2021, we'll open a bunch of positions, including Software Engineers, Graphic Designers, Technical Writers, and more. Make sure you don't miss them!Before I finish, I would love to thankKin LaneandAbhinav Asthanafor being so supportive. And of course, a huge shout out toŁukasz GornickiandEva Morcillofor their tireless support. None of these would be possible without their help.There's a bright future ahead for Asynchronous APIs. 2021 will be the year of AsyncAPI, the year of you, our beloved open-source community.Cheers!🍻
"""
--------------------------------------------------------------------------------


Post 101
ID: https://www.asyncapi.com/blog/status-update-47-20?utm_source=rss
Title: Happy Birthday AsyncAPI (week 47, 2020)
Link: https://www.asyncapi.com/blog/status-update-47-20?utm_source=rss
Summary: Happy Birthday AsyncAPI

On 18.11.2017 Fran Mendez exclaimed "Eureka” and created AsyncAPI. The story is more complicated than that, but it is not a time for a history lesson, so let us keep it simple
Content:
"""
Happy Birthday AsyncAPIOn 18.11.2017 Fran Mendez exclaimed "Eureka” and created AsyncAPI. The story is more complicated than that, but it is not a time for a history lesson, so let us keep it simple😄Yes, AsyncAPI is 3 years old🍻This is whattheysay about kids at age 3:Around this age, your baby loves to move and will probably start rolling from tummy to back. When you give him tummy time, he might lift his head high or push up on his hands. He might even sit up with some support behind and on each side of his body.That is about it. We do not want to just sit, relax, and enjoy lunch anymore. ** It's time for us to start moving, exploring, and not stopping but making a stand in the industry**. We have great years ahead of us. Trust me. Soon you'll learn that work on AsyncAPI will lift off to another level.Join us during these strange pandemic times in asynchronous remote celebration, whenever and wherever you can.Generator 1.0 And Other GoodiesFollowing the recent1.0 release of the AsyncAPI Parserwe came to the point we could release the first major release ofthe AsyncAPI Generatortoo.Feel free to congratulate us by giving a⭐️ tothe project. This is the moment to join us and think with us about the 2.0 release and all the goodies we can add to it.Try out the project by following👇instructions:Select a Generator template:HTMLMarkdownNode.jsNode.js WebSocketsJava Spring Cloud StreamJava Spring BootPython PahonpmDocker1npm install -g @asyncapi/cli2asyncapigeneratefromTemplate https://bit.ly/asyncapi @asyncapi/html-template -o exampleGenerator GitHub Action 1.0Yes, our officialGitHub Action for Generatoralready uses the latest Generator and is released under v1.1-name:GeneratingHTMLfrommyAsyncAPIdocument2uses:asyncapi/github-action-for-generator@v13with:4template:'@asyncapi/html-template@0.15.4'#In case of template from npm, because of @ it must be in quotes5filepath:docs/api/my-asyncapi.yml6parameters:baseHref=/test-experiment/sidebarOrganization=byTags#space separated list of key/values7output:generated-htmlThe AsyncAPI Playgroundis up to date with the latest generator.Writing Own Generator Template Ain't EasyWriting a template compatible with the AsyncAPI Generator is not an easy task that you can complete in one day. To write a template that generates docs or code, you need to have not only decent knowledge about AsyncAPI specification but also the features of the Generator:How do I extract data from the spec file?What template engine powers Generator and how to use it?How can I add optional features to the template?There is a lot of it. We wanted to make it easy for you. We created aGitHub Templatethat showcases all features available in the Generator. It contains:A template that generates class diagram showing relations between schemasDetailed readme which explains all the features and where are they used in the templateTo try out the template, run👇commands:1# Install the AsyncAPI Generator if you do not have it yet2npminstall-g@asyncapi/generator34# Run generation5aghttps://raw.githubusercontent.com/asyncapi/generator/v1.0.1/test/docs/dummy.ymlhttps://github.com/asyncapi/template-for-generator-templates-ooutput67# Open the result of the generation8openoutput/index.htmlFigure 1: Schema consumed by the template and the resulting diagramReact Component and Web ComponentNew Npm ScopeSince the 0.16.2 release, we changed the npm scope of the component and now use the officialasyncapione. That means you should update your dependencies and from now on use@asyncapi/react-component.Web ComponentSince the 0.17.5 release, we are now automatically publishing also the @asyncapi/web-component to npm. Given that it depends on the React component, it will always follow the same version number. This is all possible thanks to work done by amazingHesyar Uzuner,Claude Gex,Maciej Urbańczyk.Now it should be easier for you to use this component in non-React projects. That is, for example, how you would use it in a plain HTML:1<!DOCTYPEhtml>2<html>34<head>5<metacharset="utf-8">6<title>AsyncAPI Web Component Demo</title>7<scriptsrc="https://unpkg.com/@asyncapi/web-component@0.17.5/lib/asyncapi-web-component.js"defer></script>8<script>9varschema = {10url:"https://raw.githubusercontent.com/asyncapi/asyncapi/master/examples/simple-asyncapi.yml"11};1213window.onload =function(){14document.getElementById("asyncapi").schema = schema;15}16</script>17</head>1819<body>2021<asyncapi-componentid="asyncapi"cssImportPath="https://unpkg.com/@asyncapi/react-component@0.17.5/lib/styles/fiori.css"></asyncapi-component>2223</body>2425</html>There is also a sample project where you can see how this Web component plays together with Angular.We already havesome ideason how to improve DX for the component. Try it on your own and let us know what you think.Examples RenderingSince the 0.16.0 release, the component supports examples provided in the AsyncAPI document on a Message Object level. These examples are treated with priority over others. You can try it out inthe React component playground.Figure 2: View of the AsyncAPI React playground where you can see sample AsyncAPI document with example in Message Object, and how the React component renders it.AsyncAPI Special Interest Group (SIG) open meetingThe last meeting took place on Tuesday, 10th of November, 4PM UTC. Meeting notes and recording are availablehere.The next meeting is scheduled for nextTuesday, 24th of November, 8AM UTC.We work on the agenda for the next meetinghere. At the moment, there is nothing on the agenda, so you can easily sneak your topic in.We host the meeting onZoom. Do not forget about future meetings and always have up to date invitations in your calendar by adding your email tothismailing list.Some Good Read ResourcesWhat Is AsyncAPI and How Does It Differ from OpenAPIHow Microcks Can Speed-Up Your AsyncAPI Adoption - Part 1byLaurent BroudouxIs Hacktoberfest Good For Maintainers?byLukasz GornickiCover photo byWill MyersonUnsplash
"""
--------------------------------------------------------------------------------


Post 102
ID: https://www.asyncapi.com/blog/microcks-asyncapi-part1?utm_source=rss
Title: How Microcks Can Speed-Up Your AsyncAPI Adoption - Part 1
Link: https://www.asyncapi.com/blog/microcks-asyncapi-part1?utm_source=rss
Summary: August 11th 2020 was the official announcement of Microcks 1.0.0 release and our first Microcks General Availability (GA) version to fully manage event-driven API through the support of AsyncAPI speci
Content:
"""
August 11th 2020 was the official announcement ofMicrocks 1.0.0release and our first Microcks General Availability (GA) version to fully manage event-driven API through the support ofAsyncAPIspecification.This first post explains why we decided to start this project and provides more insights.For those who don't knowMicrocksyet: it is the ultimate Open source Kubernetes Native tool for Mocking and Testing all your APIs. With Microcks, you can turn your API contract, collection or SOAP UI projects into live mocks in a few seconds. For further information, please read"Why Microcks ?".We are following theAsyncAPIspecification initiative since day one and I clearly remember how thefirst announcement back in 2017resonated within our team ! We shared the same principles: Open source and community driven... and last but not least, 100% aligned with our vision that open specifications standards likeOpenAPIis the ultimate way to move forward and perpetuate our mantra: unlock developers potential in an unpredictable and strongly innovative environment!Since then, we have been in touch with our mutual communities and strategic users to see if we all embrace the idea of adding AsyncAPI testing and mocking support within Microcks.
Microcks community was very enthusiastic by the idea and problem this integration can solve. We have helped some users on their AsyncAPI use cases to grab valuable feedback on how to manage Microcks event-driven API integration. We learned a lot from different vertical industries, including tricky IoT & Edge computing or fintech implementations.Our communities clearly validate that it makes sense to have the same tool managing all their API whatever the type, open contract definition or design tool used. This is why, today Microcks supports open standards for contract definitions and mainstream open collaborative tools:It took us a year to make, which explains why Microcks 1.0.0 release is already GA and the first tool onthis topic😉This is a major step forward as we are convinced that the transition to cloud-native applications will strongly embrace event-based and reactive architecture. Thus the need to speed-up and govern event-based API like any other services mocking using Microcks will be crucial and a key success factor for any modern and agile software developments.Microcks 1.0.0 provides a solid platform for simulating event-based API using message broker technologies likeApache Kafkaeven before the publishing component has been developed. And once developed, it is then capable to validate that all the publisher sent events will be compliant with the defined specification, automatically from a CI/CD pipeline.To demonstrate our commitment/vision and toimprove AsyncAPI specificationson our favorite topic: testing & mocking, we have launched an upstream feature request in order to provide a formal type for message examples.Please have a look atthis proposal #329and share your opinion. At the moment, it is a part ofAsyncAPI 2.1 milestone.** In the next article, we will focus on Microcks + AsyncAPI use cases. Stay tuned.**And if you can't wait for text explanataions, do not hesitate having a look at theAsyncAPI SIG Meeting #34 recordingfor full illustrations of the capabilities.😉
"""
--------------------------------------------------------------------------------


Post 103
ID: https://www.asyncapi.com/blog/hacktoberfest-summary-2020?utm_source=rss
Title: Is Hacktoberfest Good For Maintainers?
Link: https://www.asyncapi.com/blog/hacktoberfest-summary-2020?utm_source=rss
Summary: tl;dr

In October, we welcomed 26 new contributors with 70 pull requests (PRs) merged. It was an exhausting but also a fascinating experience.

Hacktoberfest Is Ok

Don't be afraid of Hacktoberfest. I
Content:
"""
tl;drIn October, we welcomed 26 new contributors with 70 pull requests (PRs) merged. It was an exhausting but also a fascinating experience.Hacktoberfest Is OkDon't be afraid ofHacktoberfest. It is an excellent event for both contributors and maintainers.There arehatersthat will tell you something different. My advice, followtruncated meanmeasure and always discard extreme opinions, especially if they call for boycotting:Finally, and most importantly, we can remember that this is how DigitalOcean treats the open source maintainer community, and stay away from their products going forwardCancel culture at its best. The fact that someone is good at programming or works at Google or Facebook doesn't make them experts in everything. Remember that celebrities are not good candidates for a role model.There are no perfect events; there are no best solutions. There is always a place for improvement, but it should be followed by open, civilized discussion.Let me conclude by saying that I hope the "harm to the open source made by DigitalOcean" is not as significant as the harm that such hate does to open source by discouraging new open-source contributors. However, this is just speculation. How can I consider any of these things harmful if I did not conduct scientific research? I can only confirm that Hacktoberfest did not harmAsyncAPI Initiative. On the contrary, it was pretty neat.SpamDuring the entire event, we had only two spam PRs. I can imagine that a much more popular and known project might have had more. Nevertheless, adding theinvalidlabel and closing a PR is a super simple operation, three clicks.The definition of spam heavily depends on maintainers. For example,thisis not invalid to me, because I don't think of grammar as "subjective nits".Why We Participated in HacktoberfestOur intentions were pretty clear from the very beginning. As I wrote in theprevious post, we wanted to:PromoteAsyncAPI Initiativeas a place where we work not only on the AsyncAPI specification, but also lots of toolsHelp members of the broader open-source community make their first contributions in a friendly environmentMy impression is that sometimes the open-source is perceived as a kind of elite gathering.This is quite often blocking people from joining because they feel they cannot help but rather waste others' time.I was there in the past, I thought the same. It's just another variation of the damnimpostor syndrome. You can always help, no matter what your experience is.Start small. Don't start with tasks that can be overwhelming. Don't throw yourself into the deep end.We wanted to help others make first baby steps in a secure and inclusive environment, with lots of patience and support.What It Takes To Have 70 PRs MergedIt is not enough to label 70 issues with thehacktoberfestlabel, sorry😃First of all, you need to be passionate about open source and dedicated to what you do. It can't just be a task that somebody assigned to you. It would help if you were prepared to treat Hacktoberfest participants as a priority. I would compare it to the onboarding process of new hires.Of course, not all participants join to stay longer, usually they just follow the  "one pull request, and I'm out of here" approach.It doesn't matter.Please don't make assumptions; assumptions are evil. Be opened, treat every contribution equally, and remember that the onboarding process is a crucial element. If you fail with the onboarding process, you fail big time at the very beginning.What We PreparedWe prepared the following materials for potential participants:Blog postabout our participationOnboarding videosthat explain how to start78 issues from more than 30 repositories and put them all in onelistwith additional information about the difficulty level or the technical area,It took me around eight workdays to do it all. The most time-consuming part was to go through all the issues, pick candidates, create new ones, and group them all in a Google Sheet.What We Did During The Event70 pull requests mean —at least— 70 reviews😅If you know your project well, it is not very time-consuming, and anyway, it is the work you have to do as a maintainer. I do not count this time as an extra Hacktoberfest effort. Of course, it can be overwhelming if this is not a standard amount of PRs that you get every month.We also hostedoffice hoursfor participants. This was fun, and we wanted to start doing live streams about AsyncAPI anyway.Last but not least, once a week, I advertised our project on the official Hacktoberfest Discord server.It looks like we do not need to do more for the next year.Was It Worth ItHell yeah, and I'm already looking forward to Hacktoberfest 2021.It was great to see so many different people interacting with the project and seeing we reached our goal.We got some new features, CI/CD cleanup in all repositories, and solved many trivial SonarCloud-reported issues that we would never found time to solve.What Made It Such a SuccessOur success was a typical return on investment.We asked all contributors to provide feedback on how they learned about us and what was the most helpful resource. 20 out of 26 responded to our request.Figure 1: Ways in which the contributors learned about AsyncAPI participating in HacktoberfestI think it is pretty clear that introducing the official Discord channel was a great idea. I personally do not like Discord because of the lack of support for threads, but better this than nothing.Figure 2: Resources helpful for contributorsSuch a simple thing as a Google Sheet with a list of issues grouped by different factors was, in the end, our best resource for contributors. I encourage you to create such a sheet for your contributors next year.Open Request to Hacktoberfest OrganizersThere is one thing that calls for an improvement for next year. Just one? Yeah, opt-in solution for projects that want to participate in Hacktoberfest was addressed during this event, and I assume it stays on.The number of projects that people can work on is overwhelming, and finding the right issue seems very difficult. Please have a look at the feedback we got from our contributors. It is enough to develop an official application where potential contributors can adequately filter out issues by technology and difficulty. In the end, it doesn't make sense for all maintainers to work on their own Google Sheets and post it on Discord. A better way would be to introduce an app for all.Hall Of FameBelow you can find a list of all contributors that joined AsyncAPI during Hacktoberfest and contributed their time to the project. The list is sorted alphabetically, including the number of PRs created by this contributor.ab510 (2)anbreaker (3)Jesús Miguel Benito Calzada (1)Barbara Szwarc (8)Mitchell Sawatzky (2)Chenemi Zekeri (2)Charlie Tharas (1)Christeen Fernando (1)danielchu (4)depimomo (4)Miguel Angel Falcón Muñoz (1)Gabriel Claudino (1)Talmiz Ahmed (5)HUTCHHUTCHHUTCH (11)Jakub Iwanowski (2)João Francisco Lino Daniel (1)Jürgen B. (3)mbeuil (2)Moritz Wiesinger (1)Katrina Knight (2)Jimmy Kasprzak (3)Phil Antiporda (1)Olivier Lechevalier (6)Sanskar Patro (1)Sam (1)GrimPix (1)Cover photo byIan SchneideronUnsplash
"""
--------------------------------------------------------------------------------


Post 104
ID: https://www.asyncapi.com/blog/status-update-43-20?utm_source=rss
Title: AsyncAPI Initiative Status Update (week 43, 2020)
Link: https://www.asyncapi.com/blog/status-update-43-20?utm_source=rss
Summary: AsyncAPI JavaScript Parser 1.0.0 Is Out

I’m very proud to share that we are finally there, release 1.0.0 is out in the wild.

One month passed since the last release candidate, and no one reported an
Content:
"""
AsyncAPI JavaScript Parser 1.0.0 Is OutI’m very proud to share that we are finally there, release 1.0.0 is out in the wild.One month passed since the last release candidate, and no one reported any blockers for our first major release.AsyncAPI JavaScript Parser is an official library that validates AsyncAPI documents and returns a set of functions that make it much easier to access the document's contents. It works well both in the browser and in Node.js. We've been using it for very long in our React component to parse in the browser and in the AsyncAPI Generator to parse documents in the Node.js server and CLI.Please join us in the celebration. We do it in a typical asynchronous way. Everyone celebrates whenever they can...HTML Template ImprovementsHacktoberfest contributions brought many improvements and bug fixes. Two weeks ago, during the last status update, the HTML template version was 0.12.2, and now it is 0.15.0.PDF GenerationThe template supports now an additional parameter calledpdf. You use it to get an additional PDF file generated, next to the index.html file. In the CLI, pass-p pdf=trueto get it. Thank youTalmiz Ahmed.Change Default Name of HTML FileThe template now supports an additional parameter calledoutFilename. You use it to change the default index.html file to something different, like for example, asyncapi.html. In the CLI, pass-p outFilename=asyncapi.htmlto get it. Thank youMitchell Sawatzky.Display of Schema UIDDue to suggestions from different community members, we now display the UID of the schema. UID is displayed only if it is provided. An anonymous UID assigned by the AsyncAPI Parser to schemas without UID is not shown.Notice how it is displayed in the below example, next to the first twomixedTypeArrayproperty schemas.Java Spring Template ImprovementsOur great contributorSemen Tenischevcame back and kicked off the work on the Java template. Most important is a new feature to supportanyOfandoneOf. There are also bug fixes for enums generation and how schemas without UID are handled. The current version is 0.20.1.Hacktoberfest StatusFor us, the Hacktoberfest celebration has been a great success so far. The first day of the event started with two spam pull requests, but then...well, see for yourself:We had 24 contributorsWe merged 58 pull requests!Only around 20 issues left on ourlist. Hurry up and become our star!Generator Release Candidate 13We releasedanotherrelease candidate with several security fixes. Important to notice in this RC is that we changed the way we build the docker image. Now it doesn’t contain the generator's sources but we install Generator CLI as a global application. This means the entrypoint is not “node ./cli.js” but “ag”, just like you would use it without Docker. Also, keep in mind that this release candidate now uses the official major release of the JavaScript Parser.AsyncAPI Special Interest Group (SIG) open meetingThe last meeting took place on Tuesday, 13th of October, 4PM UTC. Meeting notes and recording are availablehere.The next meeting is scheduled for nextTuesday, 27th of October 8AM UTC.We work on the agenda for the next meetinghere. At the moment, there is nothing on the agenda so you can easily sneak your topic in.We host the meeting onZoom. Do not forget about future meetings and always have up to date invitations in your calendar by adding your email tothismailing list.Cover photo bySpaceXonUnsplash
"""
--------------------------------------------------------------------------------


Post 105
ID: https://www.asyncapi.com/blog/status-update-41-20?utm_source=rss
Title: AsyncAPI Initiative Status Update (week 41, 2020)
Link: https://www.asyncapi.com/blog/status-update-41-20?utm_source=rss
Summary: New Website

I'm super excited to share with you that last week we released a new AsyncAPI website:

On a home page, we now promote Studio more and put much more emphasis on the different ways you can
Content:
"""
New WebsiteI'm super excited to share with you that last week we releaseda new AsyncAPI website:On a home page, we now promoteStudiomore and put much more emphasis on the different ways you can engage with AsyncAPI Community,Documentation view got additional navigation per document so, for example, it is now much better to navigate through different sections ofthe specification document,The tools section is now dedicated to AsyncAPI's official tools to clarify the AsyncAPI initiative is not just the spec. Just have a look how much detailed is, for example, thegenerator view,Don't worry, all the other tools are still there, underthe Tools sectionThe cherry on the cake is a much more appealingBlog viewFran Méndezdid all this fantastic job. Well done, Bro! Sources of the website arehere. Feel free to use it as a template for your website and let us know if you need help reusing it.HacktoberfestAsyncAPI Initiative joined Hacktoberfest. We decided to join the event at the end of August when nobody even thought this would happen. The first day of Hacktoberfest felt like a false start. Because of the enormous amount of spam pull requests, some open-source community people went too far in the #cancelculture trend. They opted on Twitter for the Hacktoberfest cancelation and DigitalOcean boycott. Luckily, not everyone is a hater, and Hacktoberfest stays. Anyway, this is a topic for another post.Do we regret we engaged with event participants? Hell no! So far, we got only 2 spam PRs, but we also got many issues addressed (26 in 7 days) that we listed for the event.We had two primary goals to join the event:Show the community that AsyncAPI Initiative is not just the spec but a lot of great tooling.Help out people to take their first baby steps in open-source contributions with a welcoming community. We not only prepared issues with different levels of difficulty but also created a set of videos that explain how to contribute and what the issues are about.Anyway. We share the summary of how Hacktoberfest ended up for us in the next status update. So far, so good though.Remember that throughout the entire October me and Fran, we'll be hosting office hours so anyone can join and ask for help or even do a pair programming session with us. Feel invited! More details in the blog post about the event. We will stream to our official media accounts:https://www.twitch.tv/asyncapihttps://www.youtube.com/asyncapihttps://twitter.com/AsyncAPISpecLook intothiscalendar for the schedule.Apidays Live Hong KongThe AsyncAPI founder,Fran Méndez, was invited to present at Apidays Live Hong Kong. It is a free event that we recommend you to join. Fran's talk is scheduled for tomorrow at 8:10 AM CEST (2:10 PM Hong Kong timezone). He'll talk aboutAsyncAPI and the Future of API specs.Our regular community member, Paul Taylor from Mulesoft, will talk aboutGetting Started with AsyncAPI. His talk is scheduled for tomorrow, 6:10 AM CEST (12:10 PM Hong Kong timezone).To join the event, registerhere.React Component ImprovementsThe latest version of the component is 0.13.1. Since the last status update, we had three releases, where one was a feature to display descriptions of channels and operations correctly. We can see more interest in the component and more people asking about a client side's documentation rendering. External contributors pushed all recent changes to the component. Thanks a lot toDominik Henneke,Oliver Sand, andJakub Iwanowski.Don't think that server-side docs generation dies. So far generation of docs usingHTML Templateis most popular. We had a few bug fixes added to it, and the current release is 0.13.0. The latest release has a feature that few people asked for. Now you can add-p outFilename=customName.htmlparameter to modify the name of the output HTML file.AsyncAPI Special Interest Group (SIG) open meetingThe last meeting took place on Tuesday, 15th of September, 4PM UTC. Meeting notes and recording are availablehere.The next meeting is scheduled for nextTuesday, 13th of October, 4PM UTC.We work on the agenda for the next meetinghere. At the moment, there is nothing in the agenda so you can sneak in your topic easily.We host the meeting onZoom. Do not forget about future meetings and always have up to date invitations in your calendar by adding your email tothismailing list.Some Good Read3 Experts on How the API Industry Is Changingarticle byThomas BushGoing AsyncAPI: The Good, The Bad, and The Awesomevideo byBen GambleAsyncAPI @Hacktoberfestarticle byLukasz GornickiCover photo byPineapple Supply Co.onUnsplash
"""
--------------------------------------------------------------------------------


Post 106
ID: https://www.asyncapi.com/blog/hacktoberfest-2020?utm_source=rss
Title: AsyncAPI @Hacktoberfest
Link: https://www.asyncapi.com/blog/hacktoberfest-2020?utm_source=rss
Summary: What is AsyncAPI

AsyncAPI is a specification for describing your
Content:
"""
HacktoberFest 2020 has finishedCheck out oursummary blog post. There are lots of good insights!What is AsyncAPIAsyncAPI is a specification for describing yourevent-driven architecture. You are probably using alreadyOpenAPI/Swagger specificationfor describing your synchronous RESTful APIs. AsyncAPI is something that supplements OpenAPI. As an example, you should use AsyncAPI when your services do not talk to each other directly but through a message broker.In contrast to the OpenAPI Initiative, AsyncAPI Initiative is focused not only on creating and evolving the AsyncAPI specification but also on its tooling. It is a vendor-neutral space for the community to work together on the spec and its tools. We work on tools like specification parsers or docs and code generators.What Is Hacktoberfest And Why AsyncAPI Initiative Joins ItHacktoberfestis a well-known event that promotes open source contributions. In short, you have the entire October to submit four pull requests to any project you want, and in exchange, you get a super cool t-shirt. Is that it? Is it just for a t-shirt? Nah, the t-shirt is nice but what you also get is easy access to open source world. Maintainers of many projects open up for contributions, and it is a great chance to make your first step to joining this fantastic world.AsyncAPI Initiative joins the Hacktoberfest for two main reasons:Promote AsyncAPI Initiative as a place where we don't work on the specification only but also build a lot of great toolsMake it much easier for the community to make the first contribution to one of the AsyncAPI repositoriesIn the past, we were also there where you are now, shy and uncertain if we can impact open source community. We want to give you an easy path to take the first baby steps in the world of open source in a welcoming and friendly environment.Don't forget tosign upto the HacktoberfestHow Can You HelpThere is always a lot of work waiting out there. For the sake of this special event, we prepared around 75 GitHub issues that you can pick up. They represent different areas (for example, JavaScript or HTML), different difficulty (for example, 50 issues are easy), and different repositories. No matter if they are trivial or demanding, all of them are important for us. Even with trivial ones where you, for example, need to remove a semicolon, we will still be super happy because this will improve the quality of the project (SonarCloud reports). In other words, every single issue fromthislist is important.1. Pick The Right IssueHereyou can find a list of all the issues that you can work on. Most of the issues are about code contribution, but not all of them. There are also issues about documentation or CI/CD configuration (we use GitHub Actions). Just pick the issues you want to work on, one at a time, and let us know in the comments section that you want to work on it.2. Setup Your Environment And Create A First Pull RequestOnce youinstall Giton your machine and get aGitHub account, you need first to decide if you are here just for Hacktoberfest or longer, and make sure if your issue is easy and maybe you can complete it in the GitHub UI.In case you are here just for the Hacktoberfest, and you picked easy issues that involve changes only to a single file, there is no need to install Git and complicate your life. GitHub UI enables you tomake changes to a single file online.In case you:want to stay with us longer,you picked up an issue where you need to make changes to more than just one file,you also need to run the project locally to check if it worksThen followthisshort instruction on how to fork the repository and set it up locally.Once you are ready with your changes, submit a pull request. Be nice and follow ourcode of conductand make sure your pull request isdescribed properly.Office HoursDo you feel overwhelmed? No need. You can do it. Just take this blog post seriously.Trust me when I write that every pull request is crucial for us.
Trust me when I write that we are a welcoming community.
Don't be afraid that you will waste our time. If we would think about it this way, we would not even join the Hacktoberfest.Still not sure if you can make it? Don't worry. We want to host office hours throughout the event, 2x a week, 1h long, and different time zones. You can join whenever you want and ask us anything, or do pair programming with us. We start with the first meeting onTuesday 6th, 8AM UTCand then on the following days:Tuesday 6th, 8AM UTCThursday 8th, 4PM UTCTuesday 13th, 8AM UTCThursday 15th, 4PM UTCTuesday 20th, 8AM UTCThursday 22nd, 4PM UTCTuesday 27th, 8AM UTCThursday 29th, 4PM UTCWe stream to our official media accounts:https://www.twitch.tv/asyncapihttps://www.youtube.com/asyncapihttps://twitter.com/AsyncAPISpecYou can also join us in a more asynchronous discussion onSlack. For updates and latest news, the best is to follow ourTwitter account.Blooper ReelBefore you jump to your first contribution, have a look at the making of the videos. It was quite fun.Enjoy the Hacktoberfest!
"""
--------------------------------------------------------------------------------


Post 107
ID: https://www.asyncapi.com/blog/status-update-39-20?utm_source=rss
Title: AsyncAPI Initiative Status Update (week 39, 2020)
Link: https://www.asyncapi.com/blog/status-update-39-20?utm_source=rss
Summary: Circular References Supported in HTML and Markdown Templates

After recent efforts into circular references support in the AsyncAPI JavaScript Parser, now we started using these features in HTML and M
Content:
"""
Circular References Supported in HTML and Markdown TemplatesAfter recent efforts into circular references support in the AsyncAPI JavaScript Parser, now we started using these features in HTML and Markdown docs generators. With the latest releases of those two templates, you can generate documentation for schemas containing circular references. Below you can see an example specification file and how its payload and payload generated example looks like in generated HTML. You can also give it a try on your own in ourPlayground.1asyncapi:2.0.02info:3title:Example4version:0.1.15channels:6recursive:7subscribe:8message:9payload:10$ref:'#/components/schemas/Recursive'11components:12schemas:13Recursive:14type:object15properties:16children:17type:array18items:19$ref:'#/components/schemas/Recursive'20something:21type:stringMessage payload presentation.Generated payload example.Generate HTML Docs into a Single FileThanks to the contribution fromGordeev Artem, you can now generate HTML documentation into a single file. Like what?To generate HTML documentation for AsyncAPI files, you can use ourHTML generator template. It generates an index.html file with correctly rendered content of the AsyncAPI file. In addition, it also references additional files necessary for nice display of the HTML, JavaScript, and CSS files.From time to time, the community asked that it would be nice if the template could generate only one index.html file with all the JavaScript and CSS inline inside the HTML file.Now it is possible! There is a new parameter added to the template called singlePage. Just pass it for example, in the CLI like this -p singlePage=true.Parser with More Helpers and Better API docsWe releasedParser release candidate 5with features you want to have in a library before you announce the 1.0.0 release. Thanks to generous support from our community memberMaciej Urbanczyk, this release candidate contains the following additions:Missing externalDocs field in AsyncAPIDocument modelNew functions to all models that need it: hasBindings, bindingProtocols, hasBinding(name), binding(name), extensionKeys, extKeys, hasExtension, hasExt, tagNames, tag, hasTag, hasDescriptionMuch better API documentation. In the past, it was not only missing functions that were not available but also functions that were not documented because of the wrong usage of JSDocs. Now see on your own how significant is the change by looking just on the list of functions available for ChannelParameter model:ChannelParameter Docs before release.ChannelParameter Docs after release.Hacktoberfest PreparationHacktoberfestis a great event for people to start contributing to open source. It runs throughout October, and we want AsyncAPI Initiative to join the event. Why?Enable different communities to jump into the AsyncAPI projects with simple tasks, so they can get familiar with what we have, where to find things, and how easy it is to kick off with the first contributionShow to the community something that might not be so obvious, that the AsyncAPI Initiative is not only working on the specification but also a lot of great tools to make it easy to work with the specificationIf you are interested in how we plan to join the Hacktoberfest, look at ourplan.The Highlight of Interesting DiscussionsWAMP Protocol BindingsThere are community efforts to define bindings forWeb Application Messaging Protocol (WAMP). In case you are experienced with the protocol, please join and supporthere.Go Code GenerationThere are community efforts to create a template for generating Go code using the AsyncAPI generator. The initial pull request is opened. You can help even if you are not familiar with AsyncAPI, as you can help with just the review of the generated code. Please join and supporthere.AsyncAPI Special Interest Group (SIG) open meetingThe last meeting took place on Tuesday, 15th of September, 4PM UTC. Meeting notes and recording are availablehere.The next meeting is scheduled for nextTuesday, 29th of September, 8AM UTC.We work on the agenda for the next meetinghere. At the moment, there is nothing in the agenda so you can sneak in your topic easily.We host the meeting onZoom. Do not forget about future meetings and always have up to date invitations in your calendar by adding your email tothismailing list.Cover photo byNeil ThomasonUnsplash
"""
--------------------------------------------------------------------------------


Post 108
ID: https://www.asyncapi.com/blog/status-update-37-20?utm_source=rss
Title: AsyncAPI Initiative Status Update (week 37, 2020)
Link: https://www.asyncapi.com/blog/status-update-37-20?utm_source=rss
Summary: We canceled the previous status update due to the vacation cucumber season, so this status update covers the last four and not two weeks. Please familiarize yourself with many things we worked on and
Content:
"""
We canceled the previous status update due to the vacation cucumber season, so this status update covers the last four and not two weeks. Please familiarize yourself with many things we worked on and the exciting discussions we had.Template for templates developmentWe’ve spent a lot of time recently on tooling development. Now it is time to start working on some docs! Last few weeks, we worked on a template, a boilerplate that one can use to create a new repository to start writing their template for the AsyncAPI Generator.The work is still in progress and will take a few weeks more, but you can already see a previewhere. All the Generator features are showcased there already. We are missing only example tests and readme there.The next steps are writing a set of interactive tutorials that can explain all the features step by step, help create a super basic template, and then a more complex one.In case you have some ideas, or maybe you want to help write those, please let us know.Avro 1.8.2 supportAvro schema parser now supportsAvro 1.8.2and not only 1.9.0. The AsyncAPI Generator and the Playground already support the new version of the parser.Parser v1.0.0-rc.4The latest release candidate includes few bug fixes, but most important is that it also introduces proper tests for the browser to make sure we avoid any future mistakes in the project that could cause browser-incompatible release.React component improvementsThe AsyncAPI React component for rendering documentation on the client-side just reached release v0.12.1. Among all the other improvements, the most important are:Custom schema parsers for RAML, OpenAPI, and Avro are now also used by this componentBetter handling and rendering ofadditionalPropertiesSchemas are not presented in the tables anymoreThe Highlight of Interesting DiscussionsProposal for more formal examplesAsyncAPI 2.0 specs allow you to specify an example of the message. You can have many examples stored in an array of maps, where the key is the name of the example, and value can be of any type.Laurent BroudouxfromMicrocksproject created a proposal for better representation of examples where you can provide an example of the message payload and the headers. It means we will end up with more formal Examples object in the spec.Please have a look atthisproposal and share your opinion. At the moment, it is a part of our AsyncAPI 2.1 milestone.Native support for projects like CloudEventsCloudEventsis a specification for commonly describing event data. AsyncAPI is a specification for describing an application's API related to asynchronous communication. In the end, users should not decide which spec is better cause they serve a different purpose. Through discussions with the community, we learned that many want to use AsyncAPI + CloudEvents + Avro.Before AsyncAPI 2.0.0 we releasedan articlewhere we discussed how CloudEvent could be used in an AsyncAPI document. Long story short, it was about presenting a payload of messages wrapped with CloudEvents in AsyncAPI Payload object, and how to leverage AsyncAPI custom schema format. Such an approach can lead to a lot of duplications.CloudEvents is like an envelope for your letter. The message may include some non-business related data instead of having them separated in the headers. You do not want to mix this technical information with business information in the AsyncAPI document under one Payload field, even if this is possible.One possible option could be to reuse AsyncAPI bindings functionality, but so far, they were used only for describing information related to specific protocols.Please have a look atthisissue or talk to us on Slack. In short, we discuss there an option to introduce an object called Envelope.AsyncAPI Special Interest Group (SIG) open meetingThe last meeting took place on Tuesday, 1st of September, 8AM UTC. Meeting notes and recording are availablehere.The next meeting is scheduled for nextTuesday, 15th of September, 4PM UTC.We work on the agenda for the next meetinghere. At the moment, there is nothing in the agenda so you can sneak in your topic easily.We host the meeting onZoom. Do not forget about future meetings and always have up to date invitations in your calendar by adding your email tothismailing list.Curated ContentMicrocks 1.0.0 release with AsyncAPI supportbyLaurent BroudouxEvent-Streaming: An Additional Architectural Style to Supplement API DesignbyJames HigginbothamChoosing Between Web APIs and Message StreamingbyJames Higginbotham
"""
--------------------------------------------------------------------------------


Post 109
ID: https://www.asyncapi.com/blog/status-update-33-20?utm_source=rss
Title: AsyncAPI Initiative Status Update (week 33, 2020)
Link: https://www.asyncapi.com/blog/status-update-33-20?utm_source=rss
Summary: Parser First Release Candidate is Alive

Since the last update, we jumped from release 0.28.0 to 0.33.1. In the last two weeks we fixed a few bugs, in the parser and in the AsyncAPI JSON Schema that t
Content:
"""
Parser First Release Candidate is AliveSince the last update, we jumped from release 0.28.0 to 0.33.1. In the last two weeks we fixed a few bugs, in the parser and in theAsyncAPI JSON Schemathat the parser is using for most of the validations. In case you have a Node.js application, you can also easily access the schema througha dedicated dependency. It was important not only to fix all those bugs but also to stop relying on our fork of thejson-schema-ref-parser. Now we use the latest version of the upstream so it will be easier to bump into the latest versions.Because of all those recent fixes, now was the moment to release our first release candidate for the parser. Give it a try and let us know what is missing!Generator release candidateWe just released another release candidate for theGenerator. The only new thing is the latest Parser release candidate to make it available to a broader audience. Say hello the release candidate number 8. Any bets we won’t go higher than 10?AsyncAPI React ImprovementsOur React component for rendering AsyncAPI files on a client-side has some improvements:Regex pattern of a given property is not displayedDisplayed information that payload can or cannot have additional propertiesThis component also uses the latest parser release candidate. Try it out withthispreview.The Highlight of Interesting DiscussionsHTML Generator vs React Component aka How to Stay DRYAt the moment, AsyncAPI organization has two components for rendering HTML out of the AsyncAPI document:HTML Templateis based on theGeneratorand therefore, can be used only on a server.  You can use it through its CLI in your CI/CD pipelines or host them as a Node.js application,AsyncAPI Reactis a component that can be used in a client-side application without an application server. Its limitation at the moment is that it can be used only with React.js as a dependency.None of the above solutions is perfect, yet we still have to maintain both to support as many use cases as possible. That is why we want to make a change here and stay DRY. Join the discussion inthisissue. We would like to replace current HTML template logic entirely and reuse the React component. There are two possible solutions we see:We could produce a kind of a bundle that would contain the React component, and there would be a simple index.html that would use it.We could try the approach of projects like Gatsby or Next.js that already use React to generate static sites.AsyncAPI Special Interest Group (SIG) open meetingThe last meeting was canceled. It felt like the center of the holiday season.The next meeting is scheduled for nextTuesday, 18th of August, 4PM UTC.We work on the agenda for the next meetinghere. At the moment, there is nothing in the agenda so you can sneak in your topic easily.We host the meeting onZoom. Do not forget about future meetings and always have up to date invitations in your calendar by adding your email tothismailing list.Curated ContentHow CloudEvents and AsyncAPI can help enable Event Driven Architecture- byPaul TaylorOpenAPI is the HTTP Binding in AsyncAPI- byKin LaneAvro Schema Parser and others in AsyncAPI Initiative Status Update (week 31, 2020)- our last update where we discuss Avro schema parser.
"""
--------------------------------------------------------------------------------


Post 110
ID: https://www.asyncapi.com/blog/status-update-31-20?utm_source=rss
Title: Avro Schema Parser and others in AsyncAPI Initiative Status Update (week 31, 2020)
Link: https://www.asyncapi.com/blog/status-update-31-20?utm_source=rss
Summary: Avro Schema Parser

Short Intro to Schema Types in AsyncAPI

There are many different schema formats that one might use to describe the message payload. Not everyone uses JSON Schema. There are multip
Content:
"""
Avro Schema ParserShort Intro to Schema Types in AsyncAPIThere are many different schema formats that one might use to describe the message payload. Not everyone uses JSON Schema. There are multiple formats out there, like RAML 1.0 Data Types, Avro, or even OpenAPI 3.0. When you write your AsyncAPI file, you should not manually convert schemas that you already store somewhere in a format different from AsyncAPI Schema. The best practice is to reuse existing schemas by referring to them in your AsyncAPI file and making sure that the Message object has information about the schema format within the schemaFormat parameter.AsyncAPIlists schema typesthat are a MUST but is not limited to this list only. RAML Data Types is not a MUST HAVE, yet we already have a custom parser for it.From the AsyncAPI tooling perspective, we have abasic JavaScript Parsercapable of parsing schema of the payload provided with AsyncAPI schema format or JSON schema format. Other schema parsers are plugins that you can register with a parser, likeOpenAPI 3.0orRAML 1.0 Data Types. You could provide such plugins as well for your custom formats.Avro ParserThe 3rd plugin that we now officially support is related to Avro schema type. The first minor version is already out there, and you can give it a try, even if your schemas are in the Confluent Schema Registry. Have a look at the docs ofthe Avro schema parser. The Avro parser is also part of the latest release candidate ofthe Generator. Please help us make it work for you.Circular References in AsyncAPINow JavaScript Parser can handle circular references that you might have in your AsyncAPI files. The current implementation fully dereferences circular references, and you cannot change this behavior. We also extended the API to help you out to deal with circular references:The core AsyncAPI model now contains the hasCircular() function that you can use to determine at the very beginning if a given AsyncAPI document contains some circular references or not. An example use case for it is to throw a proper error message to the user with a clear message that circular references are not supported by your tool at the moment,The Schema model contains isCircular() function to check if a given schema is circular, so you do not have to detect it on your own and adequately reactHave a look atthispull request for implementation details. The work is still in progress as nice features in the Parser do not mean now all the Generator’s templates will support it. Have a look atthiscomment if you need more details.TypeScript Support in ParserSince Parser 0.27 we will now always generateTypeScript typesto make it much easier for TypeScript developers to use Parser in their tools.Generator Release Candidate 7 is outWe just released another release candidate that contains a lot of improvements that we added to the Parser. It also includes the above mentionedavro-schema-parserso it is easier for you to test it out. Give it a try.The Highlight of Interesting DiscussionsPublish vs Subscribe Discussion ContinuesWe noticed that people that interact with AsyncAPI for the first time are confused about the meaning of those two words, publish and subscribe. Without going much into detail and oversimplifying things, we can say that this is the part of the community that considers using AsyncAPI to describe their internal broker-centric architecture. In such cases, you want to describe the application's behavior and not what others can do with it. You want to use the Publish verb to specify that your application publishes to a given channel. What if your application is exposed to the outside world where others can interact with it? You want Publish to mean something different, like it is now, that it means your application is subscribed to a given channel, so that you can publish to it, and the application will receive a message.Event-driven architectures are complex beasts with many patterns, and we should try to make AsyncAPI a single home for all of them. Please engage in this discussion, share your thoughts, and help us out to find the best solution:Proposalto solve the above challenge with a view property that will not require 3.0 release. There is also an idea to introduce more verbs.Recordingof the last open SIG meeting where there was a discussion about publish/subscribe confusion.AsyncAPI Special Interest Group (SIG) open meetingThe last meeting took place on Tuesday, 21st of July, 4PM UTC. Meeting notes and recording are availablehere.The next meeting is scheduled for nextTuesday, 4th of August, 8AM UTC.We work on the agenda for the next meetinghere. At the moment, there is nothing in the agenda so you can sneak in your topic easily.We host the meeting onZoom. Do not forget about future meetings and always have up to date invitations in your calendar by adding your email tothismailing list.Curated ContentPulsar vs. Kafka — Part 1 — A More Accurate Perspective on Performance, Architecture, and Features-StreamNativeview on Apache Pulsar vs Apache KafkaKafka vs. Pulsar vs. RabbitMQ: Performance, Architecture, and Features Compared-Confluentview on Apache Kafka vs Apache PulsarHow to Write Your First AsyncAPI Specification- byThomas Bush
"""
--------------------------------------------------------------------------------


Post 111
ID: https://www.asyncapi.com/blog/status-update-29-20?utm_source=rss
Title: AsyncAPI Initiative Status Update (week 29, 2020)
Link: https://www.asyncapi.com/blog/status-update-29-20?utm_source=rss
Summary: Increasing the quality of tools with SonarCloud

We enabled SonarCloud for the most critical AsyncAPI tools that are reaching or already reached 1.0.0 release. Luckily this amazing software is availab
Content:
"""
Increasing the quality of tools with SonarCloudWe enabledSonarCloudfor the most critical AsyncAPI tools that are reaching or already reached 1.0.0 release. Luckily this amazing software is available for free for open-source projects.1.0.0 release is something serious, and we wanted to make sure that we have an automated way of checking the code quality and security. Now every pull request is validated for the following projects:GeneratorParserCustom schema parsers for OpenAPI schema and RAML data typesThe quality of those projects is visiblehere. We additionally validate code withESLint plugin from SonarCloud.With the Parser we went even one step further, and we now statically check the security of the code also with theESLint security plugin.Looking at the quality of SonarCloud we will roll it out to the rest of the project under AsyncAPI GitHub organization.Parser 1.0.0 right behind the cornerRecent releases in the JavaScript Parser, brought many new features to the parser:Server variables validation. Parser throws an error if you forgot to specify a Variable object for a variable used in the server URL likeurl: api.streetlights.smartylighting.com:{port}where{port}is a variable.Channel parameters validation. Parser throws an error if you forgot to specify a Parameter object for a parameter used in the channel name likeevent/{streetlightId}/lighting/measuredwhere{streetlightId}is a parameter.We added missing validation of the payload provided with the AsyncAPI schema format. In the past, when you provided a message payload information in Components object, it was correctly validated, but not if you provided this information directly under the channel.Parser throws an error if OperationId is duplicated across the whole AsyncAPI document. This is an essential property for code generation, and specification is precise that duplicates of this information are not allowed.Parser throws an error if you provided server security information in a wrong format and has a corresponding Security Schema object.For today, except forhandling circular references issueI mentioned in my last update, there are no other serious tasks we want to solve before the 1.0.0 release. Keep your fingers crossed.The Highlight of Interesting DiscussionsThere are some interesting discussions/topics where it would be great to hear your opinion.Add view property in the specificationThis proposal addresses the confusion around the semantics of Publish and Subscribe channel operations. At the moment, the specification should be used to describe how users can interact with an application. In other words, if the AsyncAPI document of the application says that ithas a publish channel, it means that this application issubscribed to this channel, and application users can publish an event to this application by publishing an event to this channel. Community proposal behind theviewproperty is to enable you to decide if you want the specification to tell you how you can interact with an application, or how the application behaves. You could say that publish means that the application published events to the channel and not the other way around.Please have a look atthe corresponding issueand share your opinion.Allow $schema property in the specificationWith$schemaproperty you can specify a location of the JSON Schema file and most of the IDEs will make your life much easier by adding auto-completion and other super useful functionalities. In the issue we discuss how we could allow maybe not only$schemabut any property starting with$, and also we talk about the opportunity to measure the adoption of the specification.Please have a look atthe corresponding issueand share your opinion.AsyncAPI Special Interest Group (SIG) open meetingThe last meeting took place on Tuesday, 7th of July, 8AM UTC. Meeting notes and recording are availablehere.The next meeting is scheduled for next Tuesday, 21st of July, 4PM UTC.We work on the agenda for the next meetinghere. At the moment, there is nothing in the agenda so you can sneak in your topic easily.We host the meeting onZoom. Do not forget about future meetings and always have up to date invitations in your calendar by adding your email tothismailing list.Curated ContentSome articles you might want to read to learn something new:Event-Streaming: An Additional Architectural Style to Supplement API DesignbyJames HigginbothamHow to mitigate unhappy paths with an event-driven architecture at scaleby Paul TaylorUnderstanding Event Driven ArchitecturebyCraig Godden-Payne
"""
--------------------------------------------------------------------------------


Post 112
ID: https://www.asyncapi.com/blog/event-streaming-an-additional-architectural-style-to-suplement-api-design?utm_source=rss
Title: Event-Streaming: An Additional Architectural Style to Supplement API Design
Link: https://www.asyncapi.com/blog/event-streaming-an-additional-architectural-style-to-suplement-api-design?utm_source=rss
Summary: This post originally appeared on Capital One Tech



The growth and adoption of web-based APIs is key to the transformational technology journey of any enterprise. Those APIs, whether they are RESTful
Content:
"""
This post originally appeared onCapital One TechThe growth and adoption of web-based APIs is key to the transformational technology journey of any enterprise. Those APIs, whether they are RESTful or not, remain synchronous. They, like the web, utilize the pattern of HTTP to implement a request-response interaction approach.To illustrate, assume we have a project management API with the following interactions:Create a project (e.g. POST /projects)Create a new task (e.g. POST /projects/{projectId}/tasks)Assign the task to someone on our team (e.g. POST /tasks/{taskId}/assignees)The assignee marks the task as complete (e.g. PUT /tasks/{taskId})An API following this design works if design of the user interface closely mirrors those endpoints. But suppose an additional application requirement is to ‘automatically’ update a task’s status when marked complete by another user. With a request/response web-API, an option is to incessantly poll a status API on the chance a status might have changed. This is both cumbersome and error-prone.
Instead of polling, we can introduce anevent-driven architecture.Introduction to Event-Driven ArchitectureIn an event-driven architecture (or EDA), an application is composed of independent components that react to events published by other components. EDA is popular for distributed applications, as new components may be introduced into a solution to solve emerging problems — without the knowledge of previously developed components. Message brokers are used as an intermediary for communication, producing a loosely coupled design by preventing components from directly communicating with one another.If you are familiar with service-oriented architecture (SOA), you have experienced EDA. Most service-oriented architectures used an enterprise service bus (ESB) for service communication rather than a message broker. Events were published to the ESB, where they were then routed to other services to integrate two or more software systems. However, ESBs proved problematic as they were used as “integration glue”, causing integration code to become scattered across services, apps, and the ESB; fragile systems were created. This fragility produced a greater need for coordination between teams, slowing software delivery.The Emergence of a Microservice and Event-Driven ArchitectureTo overcome this increased coordination, the microservice architecture was introduced as a replacement for traditional SOA. This newer distributed architecture, built on APIs and microservices, encourages “dumb pipes, smart endpoints.” Integration logic is pushed to the consumers and producers. Message brokers, rather than ESBs, are used for message routing, not integration logic. Services and APIs talk to one another while hiding implementation details. This loose coupling makes software more resilient to evolution as new requirements emerge.As enterprises shift to APIs backed by a microservice architecture, the number of published events has grown considerably. Message brokers are typically transactional in nature, ensuring once-and-only-once delivery of messages. While useful for traditional software development, the transactional nature of message brokers limits the scalability of service communication.Distributed streaming data platforms, such as Apache Kafka, now offer enterprises higher throughput than traditional message brokers. Kafka removes the need for transactional messaging found in message brokers, opting instead for turning events into message streams. These streams are accessible by any authorized subscriber and may be accessed real-time or processed sequentially from a predetermined location or at the start of the stream.API Design with Event StreamingEvent streams help software extend beyond the request-response approach common to web API styles such as REST, GraphQL, and gRPC. Software can communicate bi-directionally, removing the need for API consumers to continually poll for state changes. Instead, APIs publish events to an event stream for notification of data changes or important business events to any number of subscribed services for further processing.Let’s revisit our previous example. We needed to solve two separate requirements:Notification when a task is marked as completed. Our only option without a message-driven architecture is to require interested parties to constantly make API calls to see if the task has been completed (aka polling)Alerting a project owner when a task has been modified or marked as completed. Our only option is to mix our user interface concerns with our API by making the API send an email. The API is no longer responsible for managing projects and tasks — it is now responsible for the content and look-and-feel for email alertsIf we introduce a message-driven architecture to our solution, we can develop an API that delivers project and task resources that offer the necessary capabilities (create, read, update, delete, and mark as complete). Our API doesn’t need to know about how the task completion event notification will be used, including that an email will be sent. All it needs to do is publish event messages when those events occur and allow other services to take action as appropriate. Events this API may publish include:Interested parties can then subscribe to the event(s) they are interested in and safely ignore the rest. In our example, we may end up with three components:Projects API— Manages the Projects and Project Tasks resources via a REST-based API. The API may be comprised of one or more microservices that implement the capabilities offered by the REST API. When any event, from the list in the table above, occurs then the API publishes an event into the appropriate message stream for consumption by event subscribersTask Completed Email Microservice— Subscribes to the Task.Completed event, notifying project manager(s) via email when any task has been marked as completedTask Modified Email Microservice— Subscribes to the Task.Updated event, notifying all team members via email when any task has been editedThe API has no awareness of the two microservices subscribed to the specific events; it just publishes the events to the appropriate message stream. The solution is considered loosely coupled and therefore capable of evolving over time as new requirements emerge, perhaps with new types of notifications (e.g. SMS, web dashboard alerts) or integrations (e.g. synching to JIRA).ConclusionThe demand for more robust methods of software communication is pushing the limits of today’s interface solutions. Request/response-based APIs are essential. However, today’s technical problems are now demanding event-driven support — in addition to request/response — to improve an API’s capability offerings.As API designers, we must strive to use all available tools to offer a better developer experience. As you enhance your existing APIs and new APIs emerge, ask yourself:How can my solution architecture be improved by moving beyond standard REST APIs and into a loosely-coupled event-driven architecture?What events should my API publish that would benefit API consumers?How will my API consumers benefit from the addition of these events and how do they take advantage of them?Let’s shift our approach from strictly request-response to thinking in terms of how our APIs can not only offer endpoints for requests, but events that enable the API to push to other services. The result will be increased innovation and more transformative APIs both within and across our LOBs.
"""
--------------------------------------------------------------------------------


Post 113
ID: https://www.asyncapi.com/blog/status-update-27-20?utm_source=rss
Title: AsyncAPI Initiative Status Update (week 27, 2020)
Link: https://www.asyncapi.com/blog/status-update-27-20?utm_source=rss
Summary: AsyncAPI is innovation and you should assess it

ThoughtWorks and InfoQ clearly point out this is the best moment to have a closer look at AsyncAPI specification. Specification brings standardization
Content:
"""
AsyncAPI is innovation and you should assess itThoughtWorks and InfoQ clearly point out this is the best moment to have a closer look at AsyncAPI specification. Specification brings standardization into event-driven architectures and makes space for building great tools to solve problems like testing, documentation, code generation, and many others. Read more:ThoughtWorks Technology Radar - ToolsSoftware Architecture and Design InfoQ Trends Report—April 2020Generator and Parser 1.0 releasesWe are going in the right direction with the first major releases forthe Generatorandthe Parser. The lastrelease candidatewe produced for the Generator is pretty much stable, and all tasks were completed. We also tried it in ourGitHub ActionandAsyncAPI Studio, and it works like a charm.Then why are you not promoting the last release candidate to 1.0.0?Good question, I’m glad you asked :)Generator depends a lot on the Parser. Parser did not reach a major release yet. As you may have guessed, I'm now focused on the Parser 1.0.0 release, and the issues we want to complete before the release are listed inthis milestone. The good news is that most of the issues are either in progress, and some have pull requests already opened.What’s the plan then?Release the Parser with 1.0.0 and then Generator 1.0.0 as we already know that Parser 1.0.0 introduces some breaking changes.It is taking way too long.Fair point. We just need more hands on the board. If you are a JavaScript developer and you thought about joining AsyncAPI as a contributor, but you never knew the right moment, now is the time. I'm now entirely focused on the Parser and would be happy to onboard some more people. Just let me know, and I'll onboard you.New Website Right Behind The CornerThe time has come to do some refreshment of the AsyncAPI website. We also change the engine used to generate the website, from Hugo to Next.js. Have a look atthe previewof the work and feel free to share your feedback to Fran inthis pull request. Greatest things you can see there:Better exposure of community-related channels on the landing pageMore prominent promotion of AsyncAPI maintained tools, likethe GeneratorA more unobstructed view of theBlogsectionRight-hand side page navigation with scroll spy ondocumentation view.There are many other significant changes. You'll see them immediately on the main landing page.The Highlight of Interesting DiscussionsThere are some interesting discussions/topics where it would be great to hear your opinion.Circular ReferencesHow would you expect those are handled by the Parser and also by the Generator? Should such references be ignored or resolved, and if resolved, then how? Should generated docs indicate circular reference or ignore this info as irrelevant? These are all the questions we face now, and it would be awesome to get your inputhere.React Wrapper Redoc styleAsyncAPI Initiative provides two ways of generating docs from AsyncAPI specification:HTML templatefor the AsyncAPI generator. The classical server-side generation you perform in your CI pipelines or in an application with Node.js server.React componentthat you can use for dynamic docs rendering client-side. This one is great, but only if you want to use React in your application.We are thinking about how we could consolidate both into one project that is maintained just once. In the meantime, the community createdthis wrapperfor our React component inspired by ReDoc approach to OpenAPI. It would be great to know what you think about this and what are your expectations toward AsyncAPI Initiative. Join thediscussion.React for Template Engine for the GeneratorWe are getting a bit tired of Nunjucks and how hard it is to debug and read the templates. Fran came up with an idea to use React as a template engine for our docs and code generator. He got inspired by the emerging popularity of solutions like Gatsby or Next.js (supporting pre-rendering of React components). Before you say out loud "you are crazy" join the discussionhere.AsyncAPI Special Interest Group (SIG) open meetingThe last meeting took place on Tuesday, 23rd of June, 4PM UTC. Meeting notes are availablehere.The next meeting is scheduled for next Tuesday, 7th of July, 8AM UTC.The agenda for the meeting is builthere. There is nothing on the agenda, so you can easily sneak your topic in.The meeting is hosted onZoom. Do not forget about future meetings, and always have up to date invitations in your calendar. Add your email tothismailing list.Curated ContentSome articles you might want to read to learn something new:Choosing Between Web APIs and Message StreamingbyJames HigginbothamHow event-driven architecture solves modern web app problemsbyBogdan SucaciuWebSockets for fun and profitbyMax Pekarsky
"""
--------------------------------------------------------------------------------


Post 114
ID: https://www.asyncapi.com/blog/choosing_between_web_apis_and_message_streaming?utm_source=rss
Title: Choosing Between Web APIs and Message Streaming
Link: https://www.asyncapi.com/blog/choosing_between_web_apis_and_message_streaming?utm_source=rss
Summary: When faced with a variety of options, how are developers building APIs supposed to know which is the right one for their solution? In this article, I’m going to outline the common characteristics for both REST APIs and message streaming so developers can better understand when (and when not) to use each one.
Content:
"""
This post originally appeared onCapital One TechWhen faced with a variety of options, how are developers building APIs supposed to know which is the right one for their solution? In this article, I’m going to outline the common characteristics for both REST APIs and message streaming so developers can better understand when (and when not) to use each one.Characteristics of REST-Based Web APIsREST-based web APIs create a conversation between a client (the API consumer) and an API server (the backend). When we build REST-based APIs within Capital One, we use HTTP as our protocol. Our designs depend heavily on HTTP, from the methods (e.g. GET, POST, PUT, PATCH, DELETE) to the headers that help us communicate between client and server (e.g. Authorization, Accept, Content-Type).1GET/projects2Accept:application/json34200OK5Content-Type:application/json67[8{"projectId":"...","name":"..."},9{"projectId":"...","name":"..."},10{"projectId":"...","name":"..."},11...12]1POST/projects2Content-Type:application/json34{"name":"...",...}56201Created7Content-Type:application/json89{"projectId":"...","name":"...",...}10The client (or API consumer) is the app, which sends a message (i.e. an HTTP request) to the API whenever it needs something. The server then replies with the response, including a status code that indicates if the request was processed successfully (2xx error code), failed due to client error (4xx error code), or failed due to server error (5xx error code). All communication flows from the consumer to the API backend.When we add in hypermedia links, we extend the conversation with some additional information that may be helpful to the client:1GET/projects/123452Accept:application/json34200OK5Content-Type:application/json67{8"name":"...",...,9"_links":{10{"self":"/projects/1234"},11{"related_projects":[12{"4567":"/projects/4567"},13{"8901":"/projects/8901"},14{"9012":"/projects/9012"}15]},16{"members":[17{"1":"/users/1"},18{"2":"/users/2"},19{"3":"/users/3"},20{"4":"/users/4"},21{"5":"/users/5"}22]}23}REST-based APIs have a specific set of characteristics that are summarized below:Request/response model— API consumers send requests to an API server and receive a response.Pull-based interaction— API consumers send an API request when data or functionality is required (e.g. user interface, at a pre-scheduled time).Synchronous— API consumers receive the response after a request is sent.Multiple content types— since REST APIs are built upon HTTP, responses may be JSON, XML, or other content types as necessary to support consumer needs (e.g. CSV, PDF).Flexible interactions— Building upon the available HTTP verbs, consumers may interact with REST-based APIs through resources in a variety of ways: queries/search, creating new resources, modifying existing resources, and deleting resources. We can also build complex workflows by combining these interactions into higher-level processes.Caching and concurrency protocol support— HTTP has caching semantics built-in, allow for caching servers to be placed between the consumer and API server, as well as cache control of responses and eTags for concurrency control to prevent overwriting content.Internal and external access— REST APIs may be restricted for internal use or for external use by partners or public developers.For most solutions, offering a REST-based API is a great starting point, allowing any application or automation script to interact with your API over HTTP.Characteristics of Message StreamingUnlike REST APIs, message streaming is better at providing notifications when new messages arrive. Once subscribed, the client will be notified when new messages are available:1POST/subscriptions2Content-Type:application/json34{"callbackUrl":"https://my.callback/path",...}56201Created7Content-Type:application/json8Now that the client is subscribed to a topic, it will receive notifications when new messages are available. This may be the result of a REST API processing incoming requests from a web or mobile app, then adding messages into the message stream topic to notify anyone that is interested:1POSThttps://my.callback/path2<<projectcreatedevent>>34POSThttps://my.callback/path5<<projectarchivedevent>>67POSThttps://my.callback/path8<<projectupdatedevent>>Notice how our conversation became more interesting. We now can be notified when things change or critical business events occur; without needing to modify and redeploy the API to support a new integration that emerges in the future. This is called loose coupling, and it helps our systems be used in new ways without the originator of the messages even knowing about current and future subscribers.Those familiar with message brokers will realize that this is familiar. The difference between a message broker and message streaming is thatmessage streaming allows us to revisit past messages in sequence as well:1<<requestlast12messagesfromproject_messagestopic>>23<<retrieveandsendlast12messagesfromproject_messagestopic>>This feature is useful when we need to go aggregate values or perform a new calculation we previously didn’t realize we needed.Note — we can’t filter messages or perform other aggregate queries when requesting the messages — only the client can do this after requesting the messages from the topic. REST APIs are better suited for performing ad hoc queries than message streams.As you are discovering, message streaming is a different style of interaction than REST-based APIs. Additional characteristics of message streaming are summarized below:Publish/subscribe model— Apps or APIs publish messages to a topic which may have zero, one, or many subscribers rather than a request/response model.Subscriber notification interaction— Apps receive notification when a new message is available, such as when data is modified or new data is available.Asynchronous— Unlike REST APIs, apps cannot use message streams to submit a request and receive a response back without complex coordination between parties.Single content-type— At Capital One, our message streaming is built upon Avro, a compact binary format useful for data serialization. Unlike HTTP, Avro doesn’t support other content types (e.g. CSV, PDF).Replayability— At Capital One, our message streaming is built on Kafka, subscribers may revisit and replay previous messages sequentially.No caching or concurrency protocol support— Message streaming doesn’t offer caching semantics, cache-control, or concurrency control between publisher and subscriber.Internal access only— Subscribers must be internal to the organization, unlike HTTP which may be externalized to partner or public consumers.Message streaming offers some additional communication options that REST-based APIs do not — push-based notifications when new data or state changes occur, and the option of revisiting past messages in the stream to perform new calculations or re-execute logic that failed previously. When combined together, REST-APIs enable consuming apps to integrate easily with an HTTP API, while message streaming allow consumers to be notified of changes without needing to check with the REST API first. This can be a powerful combination that can satisfy use cases that exist today, while allowing emerging use cases to be handled in the future — all without modifying existing systems to accommodate new solutions.SummaryAs you may have realized, choosing between a web API and message streaming isn’t difficult, as long as you understand the characteristics of each one. REST APIs are best suited to request/response interactions where the client application sends a request to the API backend over HTTP. Message streaming is best suited to notification when new data or events occur that you may want to take action upon. Just be sure to match the needs of the consumer with one or more approaches to offer a robust interface to your solution’s capabilities.
"""
--------------------------------------------------------------------------------


Post 115
ID: https://www.asyncapi.com/blog/asyncapi_codegen_scst?utm_source=rss
Title: AsyncAPI Code Generation: Microservices Using Spring Cloud Stream
Link: https://www.asyncapi.com/blog/asyncapi_codegen_scst?utm_source=rss
Summary: Code generation is no simple feat. There are a lot of complexities when it comes to generating useful application code. In this post, I am going to walk you through generating your own microservices u
Content:
"""
Code generation is no simple feat. There are a lot of complexities when it comes to generating useful application code. In this post, I am going to walk you through generating your own microservices using Spring Cloud Stream and the AsyncAPI Code Generator. These tools should help to simplify things when defining and implementing your asynchronous applications. I explained the same idea in a video you canwatch here, and all of the artifacts areavailable in GitHub.This postAsyncAPI Code Generation: Microservices Using Spring Cloud Streamappeared first onSolace.AsyncAPI: What Is It?Before we dive into code generation let’s start with the basics – what is AsyncAPI? Over the past few years,AsyncAPIhas emerged as the industry standard for defining asynchronous, event-driven APIs; you can think of it as OpenAPI for the asynchronous world. It is an open source initiative that providesbotha specification to describe and document your asynchronous applications in a machine-readable format, and tooling (such as code generators) to make life easier for developers tasked with implementing them.I’m not going to go into great detail about the specification, but for context you should know that it defines metadata about your asynchronous API, the channels available for sending/receiving messages, and components – such as schemas – that define the messages that are being exchanged. For more information about the specification you can read about ithere.Defining the Application That You Want to Develop: The  AsyncAPI DocumentThe first step in doing code generation with AsyncAPI is obtaining an AsyncAPI document that defines the application that you want to develop. Per the specification, this document is represented as JSON objects and must conform to the JSON standards. YAML, being a superset of JSON, can also be used. There are two main ways of going about obtaining this document: manually create the document or use an event portal.If you decide to manually create the document after familiarizing yourself with the specification, don’t worry – you won’t be starting with a blank slate. The AsyncAPI initiative has provided a handy, interactive tool called theAsyncAPI Studioto make this easier. On the left side of the Studio you can familiarize yourself with the specification and make changes to a real AsyncAPI document, and as you do so the right side of the screen updates to show how the document is parsed into a more human-readable format.The second way is to use an event portal. Solace PubSub+ Event Portal, for example, allows for architects and developers to collaborate using a GUI to design your event-driven architecture. The team would define the applications that exist in the system, as well as the events that are exchanged and the schemas which define them. Having a catalog of well-organized channels and events for reuse will also save you both time and headaches while collaborating, instead of having to comb through a bunch of files in various locations.Once the design is in place, PubSub+ Event Portal allows the developer to choose the application they are responsible for developing and download the AsyncAPI document in JSON or YAML.Create Event-Driven Microservices Using Spring Cloud Stream Without Learning Messaging APIsNow that we have our AsyncAPI document that describes our application it’s time to develop the application. The AsyncAPICode Generatorsupports templates to generate code for a variety of different languages and protocols, but for this example we’re going to use theSpring Cloud Stream template. One should note that the template generates a Maven project.The Spring Cloud Stream framework provides an easy way to get started with event-driven microservices by providing binders that allow the developer to create their microservices without having to learn messaging APIs.Download and Run the AsyncAPI GeneratorThe first step is of course to install the AsyncAPI generator itself. If you have NodeJS installed this takes just one easynpmcommand as seen below. You can find the required versions in theCode Generatoron github.npm install -g @asyncapi/generatorOnce you have the generator installed you can run it using theagcommand. At a minimum you must specify the AsyncAPI document to run it against and the template to use as shown below.ag https://raw.githubusercontent.com/asyncapi/asyncapi/2.0.0/examples/2.0.0/streetlights.yml @asyncapi/java-spring-cloud-stream-templateIn most cases you’ll want to take advantage of the parameters and specification extensions that are specified by the template being used. For example, the Spring Cloud Stream template that I’m using in this example allows me toconfigure many options, including the Spring Cloud Stream binder I want to use – for example, the Solace binder.Other parameters include:Maven information:artifactIdandgroupIdJava package:javaPackageBroker connection Info:host,username,passwordandmsgVpnUsing these options, myagcommand might look something like this, where-ospecifies the output directory:ag -o ExpenseIntegration -pbinder=solace -pview=provider -pactuator=true-partifactId=ExpenseIntegration -pgroupId=acme.rideshare -pjavaPackage=acme.rideshare.expense -phost=localhost:55555 -pusername=default -ppassword=default -pmsgVpn=default ~/Downloads/ExpenseIntegration.yaml @asyncapi/java-spring-cloud-stream-templateAfter running, the output will look something like this:Add Your Business LogicAt this point the generator has created anExpenseIntegrationdirectory that contains the Maven project. We can use the IDE of choice and import the Maven project to add business logic.As seen in the image below, once imported, the project looks like a regular Spring Boot Java project with generated classes under thejavaPackagethat was defined earlier and anapplication.ymlfile for configuration. Generated classes underjavaPackageinclude Plain Old Java Objects (POJOs) defined from the schemas in the AsyncAPI document andApplication.javawhich contains the actual Spring Cloud Functions where we’ll add our business logic.The generated POJOs, likeRideReceiptin the image above, define your data model per the schemas included in the AsyncAPI document. These POJOs contains variables with getters and setters for each attribute defined to allow both for developers to get coding quickly without having to manually create the objects themselves, but also for Spring Cloud Stream to automatically convert messages directly to POJOs.Then we have theApplication.javaclass, which can be renamed using thejavaClassparameter. The generator will add functions to handle messages delivered on the channels defined in the AsyncAPI documentas described in the template.In the example below we can see a singlejava.util.function.Consumerbean since our AsyncAPI document describes our application as a subscriber to messages whose payload is defined by theRideReceiptschema. Note the comment that states // Add business logic here; this is where the developer can add their business logic.1@SpringBootApplication2publicclassApplication{3privatestaticfinalLogger logger = LoggerFactory.getLogger(Application.class);4publicstaticvoidmain(String[] args){5SpringApplication.run(Application.class);6}78@Bean9publicConsumer<RideReceipt>acmeRideshareBillingReceiptCreated001Consumer(){10// Add business logic here.11returnnull;12}13}You might say: “Marc, that’s great, but how the heck is that function actually binding to the messaging channels!?” This is where theapplication.ymlfile comes into play.The generatedapplication.ymlfile defines several things as specified in the AsyncAPI document or from the parameters passed into the generator. First, it defines the list of functions it wants Spring Cloud Stream aware of underspring.cloud.stream.function.definition. Second, it tells Spring Cloud Stream which channels to bind those functions to underspring.cloud.streams.bindings. Lastly, it contains connection information to the messaging system. The connection info is specified by different parameters depending on the binder you choose but, in this case, it’s defined undersolace.java.1spring:2cloud:3stream:4function:5definition:acmeRideshareBillingReceiptCreated001Consumer6bindings:7acmeRideshareBillingReceiptCreated001Consumer-in-0:8destination:acme/rideshare/billing/receipt/created/0.0.1910solace:11java:12host:'localhost:55555'13msgVpn:default14clientUsername:default15clientPassword:default1617logging:18level:19root:info20org:21springframework:infoNote that all of this was done for the developer so they didn’t have to track down which SCSt parameters needed to be set, map the functions to the bindings, etc. They just have to add their business logic in place of the project and hit run! In this case since it’s a Spring Boot project you can “run as a Spring Boot app” in your IDE or even run from the command line usingmvn spring-boot:run.Helpful Parameters and Specification Extensions for Creating Microservices Using the AsyncAPI Spring Cloud Stream TemplateAs I mentioned, there are a lot of complexities when it comes to generating useful application code from a microservice. Because of these complexities, I thought I’d call out some tips, tricks, and painpoints of using the AsyncAPI Spring Cloud Stream template.There are a bunch of different parameters and specification extensions that you should consider when generating your code. All of them can be foundhere, but I’ll go over a few of the parameters that I use quite often:Thebinderparameter allows you to specify the Spring Cloud Stream binder that you’d like to use. Currently the generator supportskafka,rabbitandsolace.Theinfo.x-viewspecification extension can be set at the info level in your AsyncAPI document. This extension allows for you to define how the document should be viewed from an application perspective. By default an AsyncAPI specification takes aclientview where operations (publish/subscribe) defined in a document represent what an application accepts (or how you would communicate with that application). However, for code generation you may want to  generate what an application actually does. This is where setting theviewparameter comes in. If you setviewto a value ofproviderthe operations defined in the document will be treated as what an application actually does. Note that this extension can also be set using theviewparameter on some generator templates, such as the Java Spring Cloud Stream one.Theoperation.x-scs-function-namespecification extension can be set on yourpublishorsubscribeoperations in the AsyncAPI document, allowing you not only to name the generated function, but also tie two operations together to form a function that subscribes to one channel and publishes to another when the same name is used. For example, if your AsyncAPI document looked like the image below ajava.util.function.Functionbean called “calculatePercentage” would be generated which subscribes to the input channel and publishes to the output channel.1channels:2'input':3subscribe:4x-scs-function-name:calculatePercentage5message:6$ref:'#/components/messages/CovidTracking_SingleStateCurrentDataUpdate'7'output':8publish:9x-scs-function-name:calculatePercentage10message:11$ref:'#/components/messages/CovidTracking_SingleStateTestPercentagesUpdate'Thex-scs-destinationspecification extension can be specified on asubscribeoperation, allowing you to override the default destination value which usually matches the channel. This is useful when you are using the Solace binder and you are following the Solace pattern of publishing to topics and consuming from queues. In this case thex-scs-destinationvalue would be treated as the name of the queue which your microservice will consume from and the channel name in the AsyncAPI document will be added as a topic subscription to that queue.Thex-scs-groupspecification extension can also be specified on asubscribeoperation, allowing for the addition of agroupto the generated Spring Cloud Streambinding. This allows for the use of consumer groups and will end up in adurable queuebeing created when using the Solace binder.Tips For Using The Code Generator To Create Event-Driven Microservices Using Spring Cloud StreamBesides configuration options there are a few more things to keep in mind when using the generator to create event-driven microservices using Spring Cloud Stream.Make sure generated POJOs have the Java types you would expect for generated variables! For example, if your JSON schema defines an attribute type as anumberorintegerthose are being mapped to aDoubleorIntegerin Java respectively. If you would like another type, such as a float or long, you’ll want to make that change. It is also important to make sure you pay close attention to data that represents dates and/or times as those will likely end up just being represented by aStringby default.Dynamic topics are not yet supported by the AsyncAPI SCSt Code Generator. We’ll be looking to enhance them both to support dynamic topics in the future but for now you’ll want to remove dynamic pieces of the topic from your channels in the AsyncAPI document and add them into the code afterwards.When creating a Spring Cloud Stream microservice that doesnotcontain ajava.util.function.Supplierinclude a web server so the microservice continues running and listening for messages to process. This can be done by including the-p actuator=trueparameter to include Spring Actuator functionality which itself requires a web server, and also provides some cool management and monitoring capabilities. Alternatively, you can just add thespring-boot-starter-webstarter to your pom after it’s been generated. Note this is not an issue with the AsyncAPI generator template, but just a bug with the Solace Spring Cloud Stream binder which will be relevant to people using the generator.I hope those tips are helpful and save you some troubleshooting time!ConclusionI hope this post was useful and you’re able to quickly dive in to generating your own event-driven microservices using Spring Cloud Stream and the AsyncAPI Code Generator after exploring the example described above.You can get started right away and use the Solace PubSub+ Event Portal to generate your AsyncAPI document for FREE by signing up for anew cloud account!If you have more questions or want to share your experience with the tools, you can let us know in theSolace Community Forumor consider joining us in contributing directly to the AsyncAPI initiative.
"""
--------------------------------------------------------------------------------


Post 116
ID: https://www.asyncapi.com/blog/doc-event-driven-api?utm_source=rss
Title: API documentation in event-driven applications
Link: https://www.asyncapi.com/blog/doc-event-driven-api?utm_source=rss
Summary: We live in an era of distributed systems. Airlines and hotels communicate with each other to offer us a better experience in our travels; shops work with shipping companies, so we have our new product
Content:
"""
We live in an era of distributed systems. Airlines and hotels communicate with each other to offer us a better experience in our travels; shops work with shipping companies, so we have our new products in our homes in a matter of hours. All of these integrations across services are done using APIs. Those APIs must be well documented so the consumers can integrate with them easily. This is not only a technical matter but also a business-related one.Currently, the most used API protocols areRESTandGraphQL. You can document your REST API using theOpenAPIinitiative. In the case of GraphQL, you can use tools like GraphiQL, which makes supported operations visible throughintrospection query.Both protocols are essentially synchronous: you make a request against the API and wait for a response. But what happens when you are to design an asynchronous event-oriented API? OpenAPI has been designed to document request/response APIs, and GraphQL has its own specific mechanism, so they are not applicable in this case.AsyncAPIto the rescue.Let's imagine you work on a book shopping website calledSuperFunnyBooks. Your team is responsible for theCatalog Service. Book publishers can register new books to the platform through your service.SuperFunnyBooksproduct team needs a new feature to be added: when a new book is registered on the platform, it has to be recommended to users interested in that genre. To do this, a brand new service,Recommendation Service, is created and a new team is assigned to.The new service needs to know when a new book is registered in the platform, soCatalog Servicewill publish aBookRegisteredevent to a message queue every time this happens. This event will contain information about the new book. But, where is the message queue located? and what does exactly "information about the new book" mean? It sounds a little bit abstract and vague.Recommendation Serviceteam needs to know every single field that will be included in the event's payload, as well as how to connect to the message queue to start listening for new events. In other words, they need the API documentation.This is how this event-oriented API would look like with AsyncAPI:1asyncapi:2.0.02info:3title:CatalogService4version:'1.0.0'56servers:7production:8url:catalog.superfunnybooks.com:90929protocol:kafka10description:ProductionKafka1112channels:13book/registered:14description:BookRegisteredTopic15subscribe:16summary:Receiveinformationaboutnewbookregisteredincatalog17message:18name:BookRegistered19contentType:application/json20payload:21type:object22properties:23bookId:24type:string25title:26type:string27author:28type:string29genre:30type:string31publisherId:32type:string33registeredAt:34type:string35format:datetimeThe first part contains API metadata information. Then,serversinformation is declared; in this case, there is a Kafka server running oncatalog.superfunnybooks.comat port9092.channelsobject groups all the operations that the API supports. This one allows consumers to subscribe tobook/registeredchannel to be notified when a new book is registered. Also, the concrete event's payload schema is defined.With this document, API is properly defined and it provides a contract betweenCatalog Serviceand its consumers. Now,Recommendation Serviceknows where the message queue is located in the network and how exactly an event's payload looks like.To sum up, having nice API documentation improves communication between teams in a company as well as between external stakeholders. Also, using a machine-friendly format (like YAML) in API documentation enables it to be integrated into the development lifecycle and the possibility of taking advantage of techniques like server stubbing or automatic testing.This has been a simple example of how to use AsyncAPI specifications to document event-oriented APIs.AsyncAPI specprovides a lot of options that allow to define clearly many aspects of an API. It is worth keeping it in mind.I hope you enjoyed this post.(Original content fromhttps://hvalls.dev/posts/doc-event-driven-api)
"""
--------------------------------------------------------------------------------


Post 117
ID: https://www.asyncapi.com/blog/automated-releases-part-two?utm_source=rss
Title: (Part 2) Full automation of release with GitHub Actions and Conventional Commits for non-JS projects
Link: https://www.asyncapi.com/blog/automated-releases-part-two?utm_source=rss
Summary: This post and the previous one come from our experience we gained when working on full automation for all tools maintained by AsyncaPI Initiative.
Content:
"""
tl;drHereyou can find the first blog post about automated releasing. The purpose of this blog post is to show how you can do the same automation in non-JavaScript projects. Even if JavaScript community created tooling, you can still use it in other projects and don't freak out.This post and theprevious onecome from our experience we gained when working on full automation for all tools maintained byAsyncaPI Initiative.AsyncAPIis a specification that you use to create machine-readable definitions of your event-driven APIs.The previous post focused on JavaScript as the first library that we automated was ourgenerator. It covered publishing to NPM and usage of the JavaScript community ecosystem. Now we have automation rolled out to all our libraries, Go-written too.What I need to automate release?To automate a release efficiently, you need two things:Machine-readable information that allows you to identify if a given commit should trigger a release or not.Tooling that you can easily plug in and configure without the need to write everything from scratch.This automation is possible thanks to the following:TheConventional Commitsspecification. The purpose of Conventional Commits is to make commits machine-readable but also human-readable. It defines a set of commit prefixes that can be easily parsed and analyzed by tooling and looks good to the human eye too.TheSemantic Releasepackage and related plugins that support Conventional Commits and publishing to different channels like GitHub, NPM, Slack, and others.Where's the catch?This blog post is about the automation of releases for non-JavaScript projects. Let me be honest though, solutions I mentioned in the previous chapter come from the JavaScript community.The problem is, there are people whoHate JavaScript, they trulyhate itlike it is a living thing. Although, I'm personally proud to be an idiot that has a programming language that I can use.Conventional Commits specification is heavily inspired byAngular Commit Guidelines. The Semantic Release package and its plugins ecosystem are all Node.js packages.If you have Java or Go project, you can still use these tools. You do not have to keeppackage.jsonin your repository, so don't worry, you can keep your repository clean. The great folks from Semantic Release thought about you too.Using Semantic Release with GitHub Action in Go projectOne of the projects where we use this JavaScript tools is our parser for AsyncAPI documents. It is aGo parser.Semantic Release configurationThe Semantic Release package supports configuration files in different formats and file types. You are not bound topackage.json. We chose to use.releasercfile in YAML format but there areother optionstoo.1---2branches:3-master4plugins:5--"@semantic-release/commit-analyzer"6-preset:conventionalcommits7--"@semantic-release/release-notes-generator"8-preset:conventionalcommits9--"@semantic-release/github"10-assets:11-path:asyncapi-parser.darwin.amd6412label:Binary-DarwinAMD6413-path:asyncapi-parser.linux.amd6414label:Binary-LinuxAMD6415-path:asyncapi-parser.windows.amd64.exe16label:Binary-WindowsAMD64Our configuration uses plugins to:Analyze Git commits with Conventional Commits specification.Create a Git tag and generate changelog for release notes.Publish a release with additional assets. We compile our parser as binaries that are compatible with many platforms and we want to have them easily accessible with each release.We place the configuration under.github/workflows/, next to our GitHub Action release workflow file:release.yml. It indicates that it is for release only, nothing else.Release workflowLet us have a look at the differences between this workflow and the workflow I described for a typical JavaScript projecthere.First, you define atestjob with the Go environment to trigger tests with different versions of Go.1test:2name:'Testing'3runs-on:ubuntu-latest4strategy:5matrix:6go:7-'1.14'8-'1.13'9-'1.12'10steps:11-name:Checkoutrepo12uses:actions/checkout@v213-name:SetupGo14uses:actions/setup-go@v1.1.215with:16go-version:'${{ matrix.go }}'17-name:Invokinggotest18run:gotest./...The next step is thereleasejob, where you can differentiate two core steps. The first part is the generation of the binaries that you want to expose in the GitHub release.1-name:SetupGo2uses:actions/setup-go@v1.1.23with:4go-version:'1.14'5-name:Invokinggovetandbinariesgeneration6run:|7go vet ./...8GOOS=darwin GOARCH=amd64 go build -o=.github/workflows/asyncapi-parser.darwin.amd64 ./cmd/api-parser/main.go9GOOS=linux GOARCH=amd64 go build -o=.github/workflows/asyncapi-parser.linux.amd64 ./cmd/api-parser/main.go10GOOS=windows GOARCH=amd64 go build -o=.github/workflows/asyncapi-parser.windows.amd64.exe ./cmd/api-parser/main.goSo far, it is all Go-related operations. How about the release? For the release, you need to set up a Node.js environment to run Semantic Release. Node.js community has this excellent package,npx, that allows you to run a package without installing it, and this is what you can do here in the workflow.1-name:SetupNode.js2uses:actions/setup-node@v13with:4node-version:135-name:Addpluginforconventionalcommits6run:npminstallconventional-changelog-conventionalcommits7working-directory:./.github/workflows8-name:ReleasetoGitHub9working-directory:./.github/workflows10env:11GITHUB_TOKEN:${{secrets.GH_TOKEN}}12GIT_AUTHOR_NAME:asyncapi-bot13GIT_AUTHOR_EMAIL:info@asyncapi.io14GIT_COMMITTER_NAME:asyncapi-bot15GIT_COMMITTER_EMAIL:info@asyncapi.io16run:npxsemantic-releaseYou only have to installconventional-changelog-conventionalcommitsexplicitly if you want to useconventionalcommitspreset when analyzing Git commits and generating the changelog:1plugins:2--"@semantic-release/commit-analyzer"3-preset:conventionalcommits4--"@semantic-release/release-notes-generator"5-preset:conventionalcommitsTake a look at full release workflow for reference:1name:Release23on:4push:5branches:6-master78jobs:9test:10name:'Testing'11runs-on:ubuntu-latest12strategy:13matrix:14go:15-'1.14'16-'1.13'17-'1.12'18steps:19-name:Checkoutrepo20uses:actions/checkout@v221-name:SetupGo22uses:actions/setup-go@v1.1.223with:24go-version:'${{ matrix.go }}'25-name:Invokinggotest26run:gotest./...2728release:29name:'Release to GitHub'30runs-on:ubuntu-latest31needs:32-test33steps:34-name:Checkoutrepo35uses:actions/checkout@v236-name:SetupGo37uses:actions/setup-go@v1.1.238with:39go-version:'1.14'40-name:Invokinggovetandbinariesgeneration41run:|42go vet ./...43GOOS=darwin GOARCH=amd64 go build -o=.github/workflows/asyncapi-parser.darwin.amd64 ./cmd/api-parser/main.go44GOOS=linux GOARCH=amd64 go build -o=.github/workflows/asyncapi-parser.linux.amd64 ./cmd/api-parser/main.go45GOOS=windows GOARCH=amd64 go build -o=.github/workflows/asyncapi-parser.windows.amd64.exe ./cmd/api-parser/main.go46-name:SetupNode.js47uses:actions/setup-node@v148with:49node-version:1350-name:Addpluginforconventionalcommits51run:npminstallconventional-changelog-conventionalcommits52working-directory:./.github/workflows53-name:ReleasetoGitHub54working-directory:./.github/workflows55env:56GITHUB_TOKEN:${{secrets.GH_TOKEN}}57GIT_AUTHOR_NAME:asyncapi-bot58GIT_AUTHOR_EMAIL:info@asyncapi.io59GIT_COMMITTER_NAME:asyncapi-bot60GIT_COMMITTER_EMAIL:info@asyncapi.io61run:npxsemantic-releaseYou see, you can still have your project "clean" from any JavaScript-specific files and references. Everything you need for running your release with the JavaScript community tooling is only in the release-related configuration.ConclusionI don't think I can ever understand this "hate" towards JavaScript. I think, though, that you can "hate" the language, but if you see some amazing tooling built with it, that can increase your productivity, grit your teeth, put bias aside, and enjoy life. Especially, if in exchange you get this excellent feature, notification about release under the Issue and Pull Request:In case you want to have more explanation on the release automation subject, I recommend readingthe first part of the automation story. You can alsojoin our Slackfor further discussion.* Cover photo byRock'n Roll Monkeyon Unsplash
"""
--------------------------------------------------------------------------------


Post 118
ID: https://www.asyncapi.com/blog/asyncapi-conference-kick-off?utm_source=rss
Title: AsyncAPI Online Conference scheduled for 22.04 11 AM UTC
Link: https://www.asyncapi.com/blog/asyncapi-conference-kick-off?utm_source=rss
Summary: It is happening, a first-ever AsyncAPI Online conference. We start on 22 of April, at 11 AM UTC. The event is going to take 7 hours with 12 talks from all over the world. We start in sunny Sydney and finish in cloudy Vancouver. The event is for free, online, in your favorite quarantine room.
Content:
"""
It is happening, a first-ever AsyncAPI Online conference. We start on 22 of April, at11 AM UTC. The event is going to take 7 hours with 12 talks from all over the world. We start in sunny Sydney and finish in cloudy Vancouver. The event is for free, online, in your favorite quarantine room.How do you organize an event like this in such a short timeThere are two requirements you should fulfill behind you start organizing a conference:Gather a few people that like to walk off the beaten tracks. Best would be to involve your whole core team, as we did in AsyncAPI. All three of us got involvedFran Méndez- Project Director.Eva Morcillo Rodríguez- Marketing and Video Content Manager.Łukasz Górnicki- Maintainer and Dev Community Keeper.Make sure you have a fantastic community behind your back that supports your effortsFirst baby steps to kick off the eventConsult your community if what you plan to do makes senseSet a conference date and call for proposals deadlineGet your community involvedWe decided on a tight schedule. Our community had only three days to submit proposals. Oh boy, they exceeded our expectations. In total, we got 18! proposals. We were happy and proud but also afraid that we can't accept all talks.Talks selectionWe wanted to establish as many fair rules as possible in such a short timeframe. We decided to form a committee of people that could join Fran and vote for talks that they found most interesting:They could give 1-10 points per talk.They had no idea who is behind the talk. They knew only a title and an abstract of every proposal.After voting, we applied the following additional rules:We did not accept more than one talk from the same company. We choose the one that was most popular among voters.We did not accept talks that were either not related to the theme or other talks accepted for the conference.In other words, we did not want to favor any company and wanted to have a schedule with talks around a similar area.As a result, we accepted11 talksfrom the community. We did it thanks to the support of this amazing group of people:Waleed AshrafMike RalphsonJonas LagoniAndrzej JarzynaSponsoringWe decided toenable companies and individualsto support the event financially.How to collect money? Do it transparently with tools that you already know. We decided to use Open Collective because we use it already tocollect money for AsyncAPIWe created a dedicatedeventusingOpen Collective events. This approach allows us to collect money and share expenses explicitly for the event only. The sponsors in exchange get much more than just being listed in ourconference sponsors list, and it is clearly described under our event page.What is the money for? We want to spend it mainly on:Prizes for the community involved in the event.Paid event marketing. We are doing our best to promote eventon our own, but we know that we could do much better using paid channels too. More people know about the event and indirectly about AsyncAPI, better profits for the community, and the sponsors.Logistics aka connectivity issues can kill your eventThese are coronavirus times. ISPs are having stress tests. Netflix is probably hitting view records. Kids are running around the house all the time. We took it all into account, and this is how we want to solve those challenges:First of all, we asked our presenters to record their sessions upfront and send them to us. We want to stream them live to YouTube, and we are exploring platforms that might make it easy to stream not only to YouTube but also Twitter and others. Presenters still join their sessions, and they are going to engage with the audience in conference chat in real-time during the whole presentation. What is so great about it?The audience doesn't have to wait until the end of the presentation with questions as it works in traditional conferencesPresenters have much more time to engage with their audience, to exchange thoughts, and get more questions. They can also ask their teammates, organization members, or experts in their field to provide support during the talk.ConclusionDon't be afraid to organize your event; just find some freaks that follow you to organize it. I'm a proud freak that bought the idea immediately. It is worth it, even if you do not know the outcome yet, the experience you always gain profits in the future.In the name of the whole AsyncAPI community and the core team, I'd like to invite you to join our event on 22 of April, at11 AM UTC. The conference line-up suggests that the AsyncAPI Online conference is going to be epic!#stayhome #staysafe #staycurious
"""
--------------------------------------------------------------------------------


Post 119
ID: https://www.asyncapi.com/blog/asyncapi-github-actions?utm_source=rss
Title: Automate AsyncAPI workflows with GitHub Actions
Link: https://www.asyncapi.com/blog/asyncapi-github-actions?utm_source=rss
Summary: AsyncAPI community got rich with two GitHub Actions that you can use for validation and generation.
Content:
"""
tl;dr
AsyncAPI community got rich with two GitHub Actions that you can use forvalidationandgeneration.GitHub organized ahackathon for GitHub Actions. There is no better reason to work on a solution if there is a bag of swags waiting for youThe hackathon was only a trigger, the right moment to decide that we should engage. The primary motivation was to write a GitHub Action that can help the AsyncAPI community in specification adoption.Two AsyncAPI related actions we crafted in March are:Our community member,Waleed Ashrafcreatedan actionto validate AsyncAPI documents with ourparserWe also createdofficial AsyncAPI actionfor ourgenerator.Writing a GitHub ActionOur actions are bothwritten in JavaScript. The other way of writing action is to do aDocker container action. The best way to start writing your action is to:Followthistutorial to create a simple action to understand its components.Get familiar with theofficial toolkitthat you can use to simplify writing an action.Create your custom action withthis templatethat has many things plugged in already, like eslint, testing, and most important, distro generation, so you do not have to commitnode_modulesdirectory to your repository.These are all the resources I used to write my first action, and to master it, I only had to read the official docs, like thereference docs for the "action.yml" file. Well done GitHub!What I can do today with AsyncAPI GitHub ActionsThose two actions can help you a lot already, together or separately. I present in this post only two possible workflows, and you can take it from here and think about your ideas.Validation of AsyncAPI files in a Pull RequestYou can make sure that whenever someone makes a Pull Request to propose a change in the AsyncAPI document, you can validate it automatically usingWaleed'sactionWaleedAshraf/asyncapi-github-action@v0.0.3.Actions can be triggered bymultiple types of events. In this example, we will trigger the action on anypull_requestevent.1name:ValidateAsyncAPIdocument23on:4pull_request:56jobs:7validation:8runs-on:ubuntu-latest9-name:asyncapi-github-action10uses:WaleedAshraf/asyncapi-github-action@v0.0.311with:12filepath:'my-directory/asyncapi.yaml'Generating HTML and publishing it to GitHub PagesOne of the AsyncAPI use cases is to define your application and generate docs out of this definition, best in HTML. The typical workflow here would be to have a GitHub Action that your trigger on every push to themasterbranch.1name:AsyncAPIdocumentationpublishing23on:4push:5branches:[master]To generate HTML from your AsyncAPI definition, you need to useasyncapi/github-action-for-generator@v0.2.0action. You also need to specify a few more things:The template you want to use for generation. In this example, you can see the officialAsyncAPI HTML Template. You can also write your custom template but hosting it on npm is not mandatory.Path to the AsyncAPI file, in case it is not in the root of the working directory and its name is notasyncapi.ymlThe template specific parameters. The crucial part here is thebaseHrefparameter. When enablingGitHub Pagesfor a regular repository, the URL of the Web page ishttps://{GITHUB_PROFILE}.github.io/{REPO_NAME}/. SpecifyingbaseHrefparameter helps the browser to properly resolve the URLs of relative links to resources like CSS and JS files. You do not have to hardcode the name of the repo in workflow configuration. Your workflow has access to information about the repository it is running in. You could do this:${baseHref=/{github.repository}}/The output directory where the generator creates files. You might access those files in other steps of the workflow.1-name:GeneratingHTMLfrommyAsyncAPIdocument2uses:asyncapi/github-action-for-generator@v0.2.03with:4template:'@asyncapi/html-template@0.3.0'#In case of template from npm, because of @ it must be in quotes5filepath:docs/api/my-asyncapi.yml6parameters:baseHref=/test-experiment/sidebarOrganization=byTags#space separated list of key/values7output:generated-htmlNow you have a trigger and you can generate a Web page. The next step is to publish the generated HTML documentation to GitHub Pages. For this, you can use one of the actions created by the community, likeJamesIves/github-pages-deploy-action@3.4.2. You can also use other hosting solutions than GitHub Pages, like, for example, Netlify andone of their actions.1-name:DeployGHpage2uses:JamesIves/github-pages-deploy-action@3.4.23with:4ACCESS_TOKEN:${{secrets.GITHUB_TOKEN}}5BRANCH:gh-pages6FOLDER:generated-htmlHere is how a full workflow, with embedded validation, could look like:1name:AsyncAPIdocumentationpublishing23on:4push:5branches:[master]67jobs:8generate:9runs-on:ubuntu-latest10steps:11#"standard step" where repo needs to be checked-out first12-name:Checkoutrepo13uses:actions/checkout@v21415#Using another action for AsyncAPI for validation16-name:ValidatingAsyncAPIdocument17uses:WaleedAshraf/asyncapi-github-action@v0.0.318with:19filepath:docs/api/my-asyncapi.yml2021#In case you do not want to use defaults, you, for example, want to use a different template22-name:GeneratingHTMLfrommyAsyncAPIdocument23uses:asyncapi/github-action-for-generator@v0.2.024with:25template:'@asyncapi/html-template@0.3.0'#In case of template from npm, because of @ it must be in quotes26filepath:docs/api/my-asyncapi.yml27parameters:baseHref=/test-experiment/sidebarOrganization=byTags#space separated list of key/values28output:generated-html2930#Using another action that takes generated HTML and pushes it to GH Pages31-name:DeployGHpage32uses:JamesIves/github-pages-deploy-action@3.4.233with:34ACCESS_TOKEN:${{secrets.GITHUB_TOKEN}}35BRANCH:gh-pages36FOLDER:generated-htmlConclusionFirst of all, huge thank you toWaleed Ashraffor creating an action to validate AsyncAPI documents.Please try out the above-described actions and let us know what you think. Feel free to leave an issue to suggest improvements or ideas for other actions.In case you are interested with other GitHub Actions related posts you might have a look at:Full automation of release to NPM and Docker Hub with GitHub Actions and Conventional CommitsGitHub Actions - When Fascination Turns Into Disappointment
"""
--------------------------------------------------------------------------------


Post 120
ID: https://www.asyncapi.com/blog/automated-releases?utm_source=rss
Title: Full automation of release to NPM and Docker Hub with GitHub Actions and Conventional Commits
Link: https://www.asyncapi.com/blog/automated-releases?utm_source=rss
Summary: Repetitive tasks are tedious. If what you do manually can be automated, then what are you waiting for!
Content:
"""
tl;dr
from now on, we releasegeneratorin an automated way. We roll-out this setup to the rest when we see it is needed.Repetitive tasks are tedious. If what you do manually can be automated, then what are you waiting for!But these tasks take only a couple of minutes from time to time, gimme a breakA couple of minutes here, a couple of minutes there and all of a sudden you do not have time on more important things, on innovation. Automation makes it easier to scale and eliminates errors. Distractions consume time and make you less productive.We kick ass atAsyncAPI Initiativeat the moment. We started to improve our tooling regularly. We are now periodically sharing project status in ournewsletter, and hostbi-weekly open meetings, but most important is that we just recently updated our roadmap.Am I just showing off? It sounds like, but that is not my intention. I wish to point out we are productive, and we want to continue this trend and automation helps here a lot. If you have libraries that you want to release regularly and you plan additional ones to come, you need to focus on release automation.What full automation meansFull automation means that the release process if fully automated with no manual steps. What else did you think?Your responsibility is just to merge a pull request. The automation handles the rest.You might say:but I do not want to release on every merge, sometimes I merge changes that are not related to the functionality of the library.This is a valid point. You need a way to recognize if the given commit should trigger the release and what kind of version, PATCH, or MINOR. The way to do it is to introduce in your projectConventional Commitsspecification.Conventional CommitsAtAsyncAPI Initiativewe useSemantic Versioning. This is why choosingConventional Commitsspecification was a natural decision.Purpose of Conventional Commits is to make commits not only human-readable but also machine-readable. It defines a set of commit prefixes that can be easily parsed and analyzed by tooling.This is how the version of the library looks like when it follows semantic versioning:MAJOR.MINOR.PATCH. How does the machine know what release you want to bump because of a given commit? Simplest mapping looks like in the following list:Commit message prefixfix:indicatesPATCHrelease,Commit message prefixfeat:indicatesMINORrelease,Commit message prefix{ANY_PREFIX}!:so for examplefeat!:or evenrefactor!:indicateMAJORrelease.It other words, assume your version was 1.0.0, and you made a commit likefeat: add a new parameter to test endpoint. You can have a script that picks upfeat:and triggers release that eventually bumps to version 1.1.0.Workflow designAtAsyncAPI Initiativewhere we introduced the release pipeline for the very first time, we had to do the following automatically:Tag Git repository with a new versionCreate GitHub ReleasePush new version of the package toNPMPush new version of Docker image toDocker HubBump the version of the package inpackage.jsonfile and commit the change to the repositoryThis is how the design looks like:There are two workflows designed here.The first workflow reacts to changes in the release branch (masterin this case), decides if release should be triggered, and triggers it. The last step of the workflow is a pull request creation with changes inpackage.jsonandpackage-lock.json. Why are changes not committed directly to the release branch? Because we use branch protection rules and do not allow direct commits to release branches.You can extend this workflow with additional steps, like:Integration testingDeploymentNotificationsThe second workflow is just for handling changes inpackage.json. To fulfill branch protection settings, we had to auto-approve the pull request so we can automatically merge it.GitHub ActionsEven though I havemy opinion about GitHub Actions, I still think it is worth investing in it, especially for the release workflows.We used the GitHub-provided actions and the following awesome actions built by the community:Create Pull RequestAuto ApproveMerge Pull RequestRelease workflowRelease workflow triggers every time there is something new happening in the release branch. In our case, it is themasterbranch:1on:2push:3branches:4-masterGitHub and NPMFor releases to GitHub and NPM, the most convenient solution is to integratesemantic releasepackage and related plugins that support Conventional Commits. You can configure plugins in yourpackage.jsonin the order they should be invoked:1"plugins": [2[3"@semantic-release/commit-analyzer",4{5"preset":"conventionalcommits"6}7],8[9"@semantic-release/release-notes-generator",10{11"preset":"conventionalcommits"12}13],14"@semantic-release/npm",15"@semantic-release/github"16]Conveniently, functional automation uses atechnical bot rather than a real user. GitHub actions allow you to encrypt the credentials of different systems at the repository level. Referring to them in actions looks as follows:1-name:ReleasetoNPMandGitHub2id:release3env:4GITHUB_TOKEN:${{secrets.GH_TOKEN}}5NPM_TOKEN:${{secrets.NPM_TOKEN}}6GIT_AUTHOR_NAME:asyncapi-bot7GIT_AUTHOR_EMAIL:info@asyncapi.io8GIT_COMMITTER_NAME:asyncapi-bot9GIT_COMMITTER_EMAIL:info@asyncapi.io10run:npmrunreleaseAside from automation, the bot also comments on every pull request and issue included in the release notifying subscribed participants that the given topic is part of the release. Isn't it awesome?DockerFor handling Docker, you can use some community-provided GitHub action that abstracts Docker CLI. I don't think it is needed if you know Docker. You might also want to reuse some commands during local development, like image building, and have them behind an npm script likenpm run docker-build.1-name:ReleasetoDocker2if:steps.initversion.outputs.version!=steps.extractver.outputs.version3run:|4echo ${{secrets.DOCKER_PASSWORD}} | docker login -u ${{secrets.DOCKER_USERNAME}} --password-stdin5npm run docker-build6docker tag asyncapi/generator:latest asyncapi/generator:${{ steps.extractver.outputs.version }}7docker push asyncapi/generator:${{ steps.extractver.outputs.version }}8docker push asyncapi/generator:latestBump version in package.jsonA common practice is to bump the package version inpackage.jsonon every release. You should also push the modified file to the release branch. Be aware though that good practices in the project are:Do not commit directly to the release branch. All changes should go through pull requests with proper peer review.Branches should have basic protection enabled. There should be simple rules that block pull requests before the merge.Release workflow, instead of pushing directly to the release branch, should commit to a new branch and create a pull request. Seems like an overhead? No, you can also automate it. Just keep on reading.1-name:CreatePullRequestwithupdatedpackagefiles2if:steps.initversion.outputs.version!=steps.extractver.outputs.version3uses:peter-evans/create-pull-request@v2.4.44with:5token:${{secrets.GH_TOKEN}}6commit-message:'chore(release): ${{ steps.extractver.outputs.version }}'7committer:asyncapi-bot<info@asyncapi.io>8author:asyncapi-bot<info@asyncapi.io>9title:'chore(release): ${{ steps.extractver.outputs.version }}'10body:'Version bump in package.json and package-lock.json for release [${{ steps.extractver.outputs.version }}](https://github.com/${{github.repository}}/releases/tag/v${{ steps.extractver.outputs.version }})'11branch:version-bump/${{steps.extractver.outputs.version}}Conditions and sharing outputsGitHub Actions has two excellent features:You can set conditions for specific stepsYou can share the output of one step with anotherThese features are used in the release workflow to check the version of the package, before and after the GitHub/NPM release step.To share the output, you must assign anidto the step and declare a variable and assign any value to it.1-name:Getversionfrompackage.jsonafterreleasestep2id:extractver3run:|4version=$(npm run get-version --silent)5echo "version=$version" >> $GITHUB_OUTPUTYou can access the shared value by theidand a variable name likesteps.extractver.outputs.version. We use it, for example, in the condition that specifies if further steps of the workflow should be triggered or not. If the version inpackage.jsonchanged after GitHub and NPM step, this means we should proceed with Docker publishing and pull request creation:if:steps.initversion.outputs.version!=steps.extractver.outputs.versionFull workflowBelow you can find the entire workflow file:1name:Release23on:4push:5branches:6-master78jobs:9release:10name:'Release NPM, GitHub, Docker'11runs-on:ubuntu-latest12steps:13-name:Checkoutrepo14uses:actions/checkout@v215-name:SetupNode.js16uses:actions/setup-node@v117with:18node-version:1319-name:Installdependencies20run:npmci2122-name:Getversionfrompackage.jsonbeforereleasestep23id:initversion24run:npmrunget-version--silent2526-name:Setoutput27run:echo"version=$(npm run get-version --silent)">>$GITHUB_OUTPUT2829-name:ReleasetoNPMandGitHub30id:release31env:32GITHUB_TOKEN:${{secrets.GH_TOKEN}}33NPM_TOKEN:${{secrets.NPM_TOKEN}}34GIT_AUTHOR_NAME:asyncapi-bot35GIT_AUTHOR_EMAIL:info@asyncapi.io36GIT_COMMITTER_NAME:asyncapi-bot37GIT_COMMITTER_EMAIL:info@asyncapi.io38run:npmrunrelease39-name:Getversionfrompackage.jsonafterreleasestep40id:extractver41run:echo"::set-output name=version::$(npm run get-version --silent)"42-name:ReleasetoDocker43if:steps.initversion.outputs.version!=steps.extractver.outputs.version44run:|45echo ${{secrets.DOCKER_PASSWORD}} | docker login -u ${{secrets.DOCKER_USERNAME}} --password-stdin46npm run docker-build47docker tag asyncapi/generator:latest asyncapi/generator:${{ steps.extractver.outputs.version }}48docker push asyncapi/generator:${{ steps.extractver.outputs.version }}49docker push asyncapi/generator:latest50-name:CreatePullRequestwithupdatedpackagefiles51if:steps.initversion.outputs.version!=steps.extractver.outputs.version52uses:peter-evans/create-pull-request@v2.4.453with:54token:${{secrets.GH_TOKEN}}55commit-message:'chore(release): ${{ steps.extractver.outputs.version }}'56committer:asyncapi-bot<info@asyncapi.io>57author:asyncapi-bot<info@asyncapi.io>58title:'chore(release): ${{ steps.extractver.outputs.version }}'59body:'Version bump in package.json and package-lock.json for release [${{ steps.extractver.outputs.version }}](https://github.com/${{github.repository}}/releases/tag/v${{ steps.extractver.outputs.version }})'60branch:version-bump/${{steps.extractver.outputs.version}}Automated merging workflowYou may be asking yourself:Why automated approving and merging is handled in a separate workflow and not as part of release workflowOne reason is that the time between pull request creation and its readiness to be merged is hard to define. Pull requests always include some automated checks, like testing, linting, and others. These are long-running checks. You should not make such an asynchronous step a part of your synchronous release workflow.Another reason is that you can also extend such an automated merging flow to handle not only pull requests coming from the release-handling bot but also other bots, that, for example, update your dependencies for security reasons.You should divide automation into separate jobs that enable you to define their dependencies. There is no point to run theautomergejob until theautoapproveone ends. GitHub Actions allows you to express this withneeds: [autoapprove]Below you can find the entire workflow file:1name:AutomergereleasebumpPR23on:4pull_request:5types:6-labeled7-unlabeled8-synchronize9-opened10-edited11-ready_for_review12-reopened13-unlocked14pull_request_review:15types:16-submitted17check_suite:18types:19-completed20status:{}2122jobs:23autoapprove:24runs-on:ubuntu-latest25steps:26-name:Autoapproving27uses:hmarr/auto-approve-action@v2.0.028if:github.actor=='asyncapi-bot'29with:30github-token:'${{ secrets.GITHUB_TOKEN }}'3132automerge:33needs:[autoapprove]34runs-on:ubuntu-latest35steps:36-name:Automerging37uses:pascalgn/automerge-action@v0.7.538if:github.actor=='asyncapi-bot'39env:40GITHUB_TOKEN:'${{ secrets.GH_TOKEN }}'41GITHUB_LOGIN:asyncapi-bot42MERGE_LABELS:''43MERGE_METHOD:'squash'44MERGE_COMMIT_MESSAGE:'pull-request-title'45MERGE_RETRIES:'10'46MERGE_RETRY_SLEEP:'10000'For a detailed reference, you can look intothis pull requestthat introduces the above-described workflow in thegenerator.ConclusionsAutomate all the things, don't waste time. Automate releases, even if you are a purist that for years followed a rule of usingimperative moodin commit subject and now, after looking on prefixes from Conventional Commits you feel pure disgust.In the end, you can always use something different, custom approach, like reacting to merges from pull requests with the specific label only. If you have time to reinvent the wheel, go for it.Cover photo byFranck V.taken from Unsplash.
"""
--------------------------------------------------------------------------------


Post 121
ID: https://www.asyncapi.com/blog/using-nunjucks-with-asyncapi?utm_source=rss
Title: Nunjucks templating explained on the basis of AsyncAPI specification
Link: https://www.asyncapi.com/blog/using-nunjucks-with-asyncapi?utm_source=rss
Summary: Edit 14.04.2021



In this post, I explain how you can use Nunjucks to template information extracted from an AsyncAPI file. I also write how you can make it even easier using Nunjucks inside the Asyn
Content:
"""
Edit 14.04.2021In this post, I explain how you can use Nunjucks to template information extracted from an AsyncAPI file. I also write how you can make it even easier using Nunjucks inside the AsyncAPI Generator. Now, we also have aReact-basedrender engine inside the generator, and it is far more developer-friendly. I encourage you to try it out.Specifications exist for a reason. Among other things, they help to bring quality, consistency, and standardize a given area. They are a great use case for templating engines. You can prepare a template that generates something from any document that follows a particular specification. You can generate whatever you want, docs, code, and diagrams. The sky is the limit.Templating is a vast topic that is impossible to cover in a single post. In JavaScript alone, there is a zoo of differenttemplating engines. This is why I focus here only on one engine for JavaScript, which isNunjucks. Why? Soon you'll figure that out.tl;drIn case you don't want to read and prefer to jump right into code. Go to this CodeSandbox project, but keep in mind you'll miss the important context and explanation.What is AsyncAPI?AsyncAPIis a specification that you use to create machine-readable definitions of your event-driven APIs:It focuses on the application from the API user perspective. You describe what the user can do with the API, subscribe or publish to it.It is protocol-agnostic so that you can use it for APIs using Kafka or MQTT, and many others.It supports many different schema formats, so you can describe messages payload schema in a format that you already use like, for example, Avro.What is Nunjucks?Nunjucksis a templating engine for JavaScript, inspired byJinja. It has many nifty features that make templating really nice:Variables declarationBuilt-in filtersWay to create custom filtersChaining filtersIncludesMacrosNunjucks basics by exampleAll examples shown in this post can be explored in action in below CodeSandbox project.In this learning project, I created a simple Express app that handles super short documentation generated from the AsyncAPI file. It is just a small sample of things that you can get from AsyncAPI using Nunjucks.I picked Nunjucks here for a reason. AsyncAPI community maintainsa tool for generatingdifferent things from the specification document, and it is using Nunjucks as a templating engine. This basically means, use my CodeSandbox to experiment with Nunjucks, but if you plan to build some serious template for AsyncAPI, do it with thegeneratoror reuse existing templates.Variables declarationYou can declare inside the template a variable, that helps you in cases like loops. Their great use case is the same as in programming. If you have a value that you use more than once, assign it to a variable.I used it to keep the name of the API:{%setapiName = asyncapi.info().title() %}Then I could use it multiple times, for example in these sentences:1{/* Sentence 1 */}2The{{apiName}}is licensed under{{asyncapi.info().license().name() }}.34{/* Sentence 2 */}5<p>6Here you can find a list of channels to which you can publish and7<strong>{{apiName}}</strong>is subscribed to:8</p>Built-in filtersUnlike other engines, Nunjucks comes with many built-in helpers, called filters. There are around 40 different. You can for example easily make a value all uppercase:1{/* server.protocol() value comes as all lowercase */}2using {{ server.protocol() | upper }} protocolCreating custom filtersBuilt-in filters are awesome, but sometimes you need to create your filters. In my example, I had to build a filter that helps me to modify theserver.url()value.In the AsyncAPI document, you can specify a server that the application uses to publish and consume messages from. In the URL, you are allowed to use variables like this:test.mosquitto.org:{port}. Such a variable can be described with different levels of detail. You can provide a default value and even an enum of values.In my example, instead of a URL liketest.mosquitto.org:{port}, I wanted to get a fixed URL with a proper port number taken from the document:1//replace is performed only if there are variables in the URL and they are declared for a server2function replaceVariablesWithValues(url, serverVariables) {3const urlVariables = getVariablesNamesFromUrl(url);4const declaredVariables = urlVariables.filter((el) =>5serverVariables.hasOwnProperty(el[1])6);78if (urlVariables.length!==0&& declaredVariables.length !==0) {9let value;10let newUrl = url;1112urlVariables.forEach((el) => {13value = getVariableValue(serverVariables, el[1]);1415if (value) {16newUrl = newUrl.replace(el[0], value);17}18});19return newUrl;20}21return url;22}2324function getVariablesNamesFromUrl(url) {25let result = [],26array;27const regEx = /{([^}]+)}/g;2829while ((array= regEx.exec(url)) !== null) {30result.push([array[0], array[1]]);31}3233return result;34}3536function getVariableValue(object, variable) {37const keyValue = object[variable]._json;3839if (keyValue) return keyValue.default || (keyValue.enum&& keyValue.enum[0]);40}Such a filter is very handy to use, the same as the built-in filters. You can additionally enrich its context. Take a look below where you can see that my filter gets not onlyserver.url()value as a context but alsoserver.variables():{{server.url() | replaceVariablesWithValues(server.variables()) }}Chaining filtersBuilt-in filters, custom filters...that is not all. Chaining of the filters is like an icing on the cake.The same case with URL. The URL after replacing variables with values, I want to transform it into a clickable element and make it part of the DOM. All of it made easy thanks to chaining:1{{server.url() | replaceVariablesWithValues(server.variables()) | urlize | safe2}}IncludesYou can share static parts of the template. This allows you to decrease the size of templates and make maintenance easier. My example here is not very complex, and I've added it to the template to make the point that it is possible:1{/*contentof space.html file */}2<hr/>3<br/>I can include it as many times as I want across the templates like this:{%include"space.html" %}MacrosYou can share not only static but also dynamic parts of the template. What does it mean? Let's take an HTML list as an example. From the syntax/structure perspective, it always looks the same, but the displayed values of the list are different. Macros are here to help you out to define a list element once. It is like a mixture of the include and a filter.In the AsyncAPI document, I have a case where I want to list all the channels that the application uses. Actually, I want to have two lists: one list that has channels where the application is subscribed (publishoperation) to receive messages and the other one where the application publishes (subscribeoperation) messages to.First you define a macro:1{%macrolistEl(value) %}2<li><strong>{{ value }}</strong></li>3{%endmacro%}Then you can import macros in your template:{%import"macros.html"ashelpers %}You call macros like you typically call functions:{{helpers.listEl(channelName) }}ConclusionDon't build tools from scratch if there are others already available, and they are open for contributions. Trying something from scratch, as I did with the templating CodeSandbox for AsyncAPI, makes sense only for learning purposes.Keep in mind thatAsyncAPIis an open community. We do not work on the specification only, but tools too. Join us onSlackand help us build awesome tools ordonate.Take time to look into theparser-js. I used it in my CodeSandbox to parse the AsyncAPI document to pass it to templates as a context.
"""
--------------------------------------------------------------------------------


Post 122
ID: https://www.asyncapi.com/blog/v2-important-dates?utm_source=rss
Title: AsyncAPI 2.0.0 important dates
Link: https://www.asyncapi.com/blog/v2-important-dates?utm_source=rss
Summary: Hey folks! After some time thinking about it, I've decided it's time to define some important dates for AsyncAPI 2.0.0. So here we go!
Content:
"""
Hey folks! After some time thinking about it, I've decided it's time to define some important dates for AsyncAPI 2.0.0. So here we go!End of review period (July 1, 2019)After some time, many people have reviewed the specification and they've identified someissues that need to be addressedbefore we launch the version 2.0.0. Actually, this process will never finish but we have to decide on a date to stop reviewing and move forward. This date is July 1. After this day, reviews are still welcome but they will not make into version 2.0.0, and will have to wait for the next version.Beta testing program (July-September)Right after we're clear on what's going to be the final version 2.0.0, we'll start working on improving all the tooling and make sure they support version 2.0.0 well. Tools are going to be open source as always so feel free to test them with your own use cases and let us know how it works! Either it sucks or it's amazing :)I'll personally track some of these tests to make sure everything is smooth. If you want to participate in the Beta testing program, feel free to reach out to me on ourSlack channelor send me an email tofmvilas@gmail.com.Official announcement (Late September-Early October)We'll announce the final version of AsyncAPI 2.0.0 during September-October timeframe. This doesn't mean you'll have to wait until then to use it. Remember everything is open source.We're planning on announcing it in a great conference. Stay tuned!Hope this helps clarify the roadmap a little bit. I'll update the exact dates here as we decide on them. Thanks for reading!Until next time!👋
"""
--------------------------------------------------------------------------------


Post 123
ID: https://www.asyncapi.com/blog/an-api-strategist-explores-event-driven-apis?utm_source=rss
Title: An API Strategist Explores Event-Driven APIs
Link: https://www.asyncapi.com/blog/an-api-strategist-explores-event-driven-apis?utm_source=rss
Summary: If you’re like me and have experience with web services and the paradigm of RESTful, web services, and SOAP APIs, but curious about event-driven, message based, or streaming APIs, this article is for you.
Content:
"""
An API Strategist Explores Event-Driven APIsIf you’re like me and have experience with web services and the paradigm of RESTful, web services, and SOAP APIs, but curious about event-driven, message based, or streaming APIs, this article is for you.I virtually sat down with these experts:Fran Mendez, Founder ofAsyncAPIJonathan Schabowsky, Chief Architect,SolaceDavid McKenna, SVP, Research & Development,AxwayEric Horesnyi, General Manager, APIs & Integration, Axway (CEO ofStreamdata.io acquired by Axway)Question 1:What do you think is the most important value proposition of event-driven architecture and event-driven/messaging APIs?Question 2:What is the consumption experience of messaging APIs and how much does it differ from RESTful APIs?For example, at the time of writing can’t just mock up the API and run it in a Postman collection and transform it (convert the technical specification to the version I want such as YAML to RAML or JSON, for example) and consume it.Tryhttp://editor.asyncapi.orgto understand the sister spec to OpenAPI (OAS).Question 3:Today, how can I test drive event-driven APIs out in the wild?My frame of reference with REST APIs: I can inspect HTTP calls in a browser and mock up the API. I can run the API calls in API Builder or Stoplight or Postman and get an InVision conceptual app to consume the API, for example. I can use Stoplight to lint or APIMatic to create starter SDKs to test drive.Question 4:How do you measure event-driven APIs?I was thinking about how you measure theeffectsof event-driven APIs. For example, how can various types of calls live within dashboards for the sake of analytics and measurement? Future Trend: Is there a way to get wholistic data from webhooks, RESTful/JSON, SOAP/WSDL/WADL/XML, GraphQL, gRPC, etc.?POV: The future of APIs is the unified catalog having a matching data-driven view.lifewingmateFor the greater API CommunityRecommendations are the most important piece of the event-driven architecture value proposition. Business leaders only care about event-driven architecture as much as the end result produces the business-driving experience that specifically this type of architecture can produce.Technology and consulting organizations need to know when and how to recommend event-driven architecture, APIs and microservices, and corresponding methods of implementation.
How they impact my current product engine? What business results justify the spend? —lifewingmateHere we go!Question 1: What do you think is the most important value proposition of event-driven architecture?Fran: I’d say most interesting for me are:loose coupling between services (if a downstream service breaks the others just work fine),they’re fault-tolerant since events are queued or stored somewhere, and processed once the service is up and running again, andthey allow you to build real-time products easily.Jonathan: 1)Loose Coupling— As Fran states, apps do not have to know how many different apps they are consuming data from. Rather they just care about what data they are consuming. This [scenario] is extremely powerful.Also, data today is RARELY consumed only once, rather, it goes into big data and analytics platforms. The loose coupling described allows you to have this for free.Reactive to Change— Instead of polling, consumers can register their their interest (subscribe) and react to changes in real-time. The producer just sends events, and does not care if anyone is interested… fire and forget… Meanwhile clients that are subscribed get the data in realtime and can react. This is useful where you want to service customers in real-time.Scale— Want to be able to consume events, in order, across millions of devices? How about do 500k messages per second guaranteed of capital market trades?Asynchronous interactions enable enterprises to do things which are nearly impossible to do synchronously.
—JSchabowskyDavid, Eric: Event-driven architecture brings comfort to end users and efficiency to the web at individual component level and at system level:UX in FrontendsNetworkAPIsBackendsBehind the API: Application languages, data plane, and DevOpsEntire SystemUX in FrontendsThemost popularreactive frameworks (AngularJS, ReactJS, VueJS) react to streams of events presented to theirobservables, a data plane presenting events to the UI.Why is that? Because, we -mobile and desktop human users- want to be presented data in real-time:Where is my cab?
What is the price of my favorite share, now?At what time will my train arrive at destination ?Yes, our life is real-time: we do not want to waste any time and we do not want to miss anything that happens in the world (FOMO— Fear Of Missing Out).Good news: Events improve latency of the UI by factor x20 according to ourbenchmark, and avoids for users to have to refresh their UI to get the latest from their newsfeed, stocks or favorite transportation, as ourreptilian brainis naturally used to [understanding].NetworkSince 2011, with the advent of social networks and to support reactive UI, the web has RFCed protocols for low-volume bidirectional/peer-to-peer traffic (Websockets) and server to client push over HTTP (SSE). For lower volume of events, typically for alerts,webhookshave become popular.APIsMost API calls are useless: up to 98.5% according toZapierwho created the concept of Polling Madness. That is because the API client does not know when data will change, so would keep polling an API to make sure it does not miss any update. Event-Driven Architecture in APIs reverses the paradigm: why don’t we have the component who know when data change to take charge, instead of answering to useless calls?This [situation] leads to the API server pushing streams of events to the API client who have subscribed to a topic. Traffic hence goes north-south only when necessary, rather than south-north-south to hit updates randomly. Augmenting a REST API with a streaming API typically brings90% efficiencyin CPU and network use for most demanding traffic.BackendsIn some industries, backends have been using evented architecture for a while.Behind the API: Application Languages, data plane, and DevOpsBackend architectures have relied on events for a while, before REST was created. In my Flashboy days inHigh Frequency Trading, we were pushing events from exchanges to hedge funds to allow them to stay in front of the market (making big money at low risk, I’m repentant), using IP-based tweaks (IP multicast and their famous storms), and proprietary middleware.Since then, message buses have evolved to open standards adopted outside finance (thanks Linkedin forKafka), and -as already noted- the web has made it possible to transport events over HTTP. Additionally, and almost at the same time, people -likemyself- having advocated microservices for years without seeing convergence of best practices are now contented:Kubernetesis here, and has instantly been adopted by all architects and DevOps to prepare their ideal microservices architecture.And when you dig into Kubernetes and associated frameworks Istio and Envoy, what do you find? REST APIs of course, but that was expected by definition of microservices. What you also find is Async APIs for each microservice. Kaboom! Backends now have a blueprint for quite a few years: Kafka and Kubernetes to orchestrate data flows, control and scale them. And this blueprint is entirely event-driven.To top it all and not surprisingly, languages traditionally used to create application layers linked to databases have also gone through their event revolution with reactive extensions such asRxJavawidely adopted by the Java community. Now the entire backend dev, DevOps, and IT community can focus on what will make them able to compete with agility over the web.Entire SystemIf we take a helicopter view to look at the entire system, what does the event-driven revolution?The entire chain from data plane, app, API, network down to the frontends are event-driven: Event flow between IoT devices (eg GPS), mobile apps, and ML without any barrier, people can all align thinking in terms of data streams of events rather than databases, considering intensity and relevance of feeds rather than states and calls.As all components have embraced the EDA revolution (I prefer evolution -revolution is always violent- as this is happening with live clients to be supported at the same time, hence slowly, but based on a Darwinian selection of design). This newend-to-end chain of eventsbrings simplicity and efficiency to components individually and collectively.Question 2: What is the consumption experience of event-driven APIs? How much does it differ from RESTful APIs?Fran: You usually connect to a broker to start sending and/or receiving messages. Examples of brokers are RabbitMQ, Kafka, Solace, etc. The difference with synchronous patterns like REST, gRPC, and GraphQL is that you don’t ask for information. You don’t make requests.Just connect to the broker and subscribe to a channel of your interest. Eventually (no pun intended), you’ll get this information, such as when the events occur. Similarly, you’ll send events to the broker whenever they occur to you. (replace you with your service)Jonathan: Today, the consumption experience generally sucks! This is a gap in the market AsyncAPI is solving and Solace [and several other companies, organizations, and individuals] is looking to help solve too… help make the experience as pleasant as with RESTful APIs.David, Eric: There are many different technologies for providing event driven APIsServer-Sent Events (SSE) for pushing data to the client to provide reactive user experienceWebhooks for making HTTP callbacks on state changeHTML5 Websockets providing full-duplex communication channels over a single TCP connection between client and server.MQTT and AMQP for IoT use casesQuestion 3: Today, how can I test drive event-driven APIs out in the wild?Fran: You can’t or is not easy. Part of the reason for the existence of AsyncAPI is precisely to enable that.Jonathan: Check outcloud.solace.com… Sign up for an account (free) and play around. Create an event broker (think of that like an API gateway) and look at our runnable code pen examples. This is all more infrastructure based…. Now imagine AsyncAPI and you layer that on top, it becomes more like API management. Also, check out this bloghttps://solace.com/blog/api-management-event-management/(Emmelyn) I can inspect HTTP calls in a browser and mock up the API and run it in Postman and get an InVision conceptual app to consume the API, for example.You can kind of do this atcloud.solace.com… Again its more how do you send/receive messages… with no app context, but its a start and the most useful I have ever found.(Emmelyn) I can use Stoplight to lint or APIMatic to create starter SDKs to “try it”See previous comment and try it out and give me feedback!David, Eric: Many of the traditional testing tools do not natively support event- driven protocols and are built for standard HTTP request/response found in REST based services. In order to help support the testing of SSE a client SDK is provided to help build automated clients to test both functional and non-functional aspects of SSE services.Question 4: How do you measure event-driven APIs?Fran: You don’t have “calls” because you don’t ask for anything. You just show your interest in certain types of events and wait for them to happen. That’s a subscriber/consumer. If you’re building a publisher/producer then you’ll send events to the broker when certain events occur. The consumers interested in your type of event will receive them.Jonathan: I think effectiveness is a direct correlation between consumption. An event that is consumed 0 times was actually worth 0… an event consumed 100 times is valuable. Yes, you do this via dashboards. Today, nobody deals with BOTH events and synchronous apis in one platform.David, Eric: The enhanced user experience in the client can be tracked by NPS of the service.Traditional monitoring tools are optimized for request-response scenario, asynchronous scenarios bring in additional complexity where by a single request could result in N number of responses been relayed to the client. Adoption of OpenTracing can help to see the spans of distributed transactions.Value Proposition of Event-Driven ArchitectureBusiness leaders only care about event-driven architecture as much as the end result produces the business-driving experience that specifically this type of architecture can produce. What would you explain to this type of audience?Fran’s takeReal-time experiences are built with event-driven architectures. You can’t build something real-time with REST APIs or any of the aforementioned styles.Solace has an interesting concept called “event mesh” andJonathanSchabowsky can explain better and point to existing documentation.And then you have the cool thing about event-driven microservices, which allows you to build products faster. It allows you to spend less time worrying about the systems and more about your business logic.Eric’s takeAs a CEO myself, I do not invest in any feature of any technology until I can see proven track records and numbers. Well, EDA actually brings sizeable benefits in terms of topline, customer satisfaction, cost base, competitive differentiation and even HR attractiveness and retention:ToplineCustomer SatisfactionOutsmart your Competitors with Machine Learning MLIT Cost Base ReductionHRToplineThe main benefits of the EDA mindset is to optimize the time it takes between the occurrence of an event in the universe, and the reaction by the company to that event. Each industry has its own metrics for assessing such benefit. In capital markets, 1 millisecond is worth$8m(!)In marketplace/ecommerce/retail/logistics business where players make as much money as they can reduce the time between an order is placed to them, and such order is shipped to the end user, each second count. I did a quick calculation of how much a second is worth for Amazon, by dividing revenue by the number of seconds in a year:$50m(!)Customer SatisfactionAs already noted, reactive interfaces are not only the coolest but also the most natural for our human brain. Well, we can put a number on this:100 ms is worth 1%additional revenue on any mobile or desktop app, from mobile banking to eCommerce.For developers using your API, when you can provide your most important customer the ability to consume your API without limit, they are happy to pay a premium for it as it means they have more data to make decision upon, and it helps streamlining their data ingestion chain.Outsmart your Competitors with MLA major way for technology to bring value to customer interactions (chatbots), optimize processes and make best-possible decisions in an ever-changing world is Machine Learning. And Machine Learning thrives on data. In the past, data architectures were based on tables and data lakes. Well, for practitioners, data lakes actually became data swamps.With some experience, the key is to master data ingestion so that data sources are consumed upstream, as close as possible to the source, and turned into value as soon as possible by Machine Learning. Machine Learning consumes streams of data conveyed by Kafka from third party streaming APIs, such asXignite Cloudstreaming, learn from them as they come and learns from its errors against what it had predicted.And the closer you are from data sources (acting as senses for the ML brain), the smarter your ML brain will be, faster than your competition. There is even a family of ML updating their model for each, calledMassive Online Analysisor Streaming Algorithms. EDA has even invaded ML.IT Cost Base ReductionWith the 90%+ gains in efficiency that we have mentioned earlier, an API vendor servicing clients with events can not only make them happier, but also reduce its cloud bill on CPU and network by 90% on these use cases. As cloud bills have become so high and critical to become visible to executive desks, they should understand the impact.HRI believe we would agree that developers and DevOps like new and efficient [tools]. And events are fun while bringing efficiency. Working with events makes your organization more attractive to new developers, and help keeping them happy while working on cutting-edge technology. As developers cannot meet the demand while “software is eating the world” this [circumstance] alone could be a driver for considering and EDA and API and Microservices first approach in your organization.Question: How and when should companies actively choose event-driven architecture?For example, how is discovery performed? Which APIM catalogs can showcase event-driven APIs so that companies can decide to consume rather than build it themselves? What kind of guidance and best practices can we provide?David and Eric adviseIoT— Many companies are looking to leverage IoT in their offering such as car insurance (pay as you drive), healthcare (health monitoring).A vast variety of low-price devices (sensors, thermostats, robots, etc.) with internet connectivity is flooding the market. Their value does not lie in the hardware but in the services that are/will be attached to it. The infrastructure that support these services must have a real-time processing capability to provide real value back to the consumer.MQTTis becoming the de-facto standard to exchange data with IoT devices because it is simple and efficient on low memory devices. It is also based on a Publish/Subscribe model that will force the companies to adopt an EDA in order to process all the generated events.Cloud— Adaption of cloud-based services in Enterprise adds more integration patterns (Cloud-to-cloud, Cloud-to-ground, Ground-to-Cloud, ..) thus more complexity. The different systems needs to exchange data to keep a coherent state across the applications. Using a point-to-point integration strategy can quickly become a trap because of the exponential complexity and tight coupling between the different systems.EDA enables a loose coupling between the components/apps in order regain agility, increases innovation pace and reduces time-to-market for new features/services.In general, I’m studying API Design Patterns and how various kinds of APIs expedite R&D adoption. What business results are accelerated from these kinds of patterns?Thanks for suggesting topics and connecting with feedback. You can also reach me via Twitter @lifewingmate DM or via the AsyncAPI community via ourGitHuborSlack channel.Disclaimer: The professional opinions of those interviewed do not necessarily reflect the organizations they represent. These interviewees volunteered their time and contributions to support the AsyncAPI initiative and community.
"""
--------------------------------------------------------------------------------


Post 124
ID: https://www.asyncapi.com/blog/asyncapi-cloud-events?utm_source=rss
Title: AsyncAPI and CloudEvents
Link: https://www.asyncapi.com/blog/asyncapi-cloud-events?utm_source=rss
Summary: There is the belief by many people that AsyncAPI and CloudEvents are competing for the same thing. This can't be less true, and I'd like to explain you why. Read on!
Content:
"""
I've been receiving the same question for a long time now: Should I use CloudEvents or AsyncAPI? — And my response has always been the same: it depends!There is the belief by many people that AsyncAPI and CloudEvents are competing for the same thing. This can't be less true, and I'd like to explain you why. Read on!What is CloudEvents?Fromcloudevents.io:Enter CloudEvents, a specification fordescribing event data in a common way. CloudEvents seeks to ease event declaration and delivery across services, platforms and beyond!The purpose of CloudEvents is to establish a common format for event data description. And it makes a lot of sense when you realize they are part of theCNCF’s Serverless Working Group.If you are doing serverless or FaaS (Function as a Service), then CloudEvents is your best friend because the event is the only information you will have in your function during runtime. No topics or channels, no servers, no subscribers. Just the event and some extra information you may need to make your function work.CloudEvents is focused on the eventand defines an envelope for your application's data. See an example from their repo:1{2"specversion":"0.2",3"type":"com.github.pull.create",4"source":"https://github.com/cloudevents/spec/pull/123",5"id":"A234-1234-1234",6"time":"2018-04-05T17:31:00Z",7"comexampleextension1":"value",8"comexampleextension2": {9"othervalue":510},11"contenttype":"text/xml",12"data":"<much wow=\"xml\"/>"13}Here your event is actually<much wow=\"xml\"/>and the rest is meta information about your event. This envelope is what CloudEvents defines with the purpose of making event declaration reusable across services and platforms.What is AsyncAPI?From theAsyncAPI repo:Create machine-readable definitions of your event-driven APIs.The purpose of AsyncAPI is to provide a way for you to define how your event-driven applications (or APIs) communicate with the rest of the world.AsyncAPI is focused on the application and the channels it uses to communicate. Similar to whatOpenAPIandRAMLdo for REST APIs. Unlike CloudEvents —who focuses on the message— AsyncAPI does not impose how your event must look like but, instead, allows you to strictly define its shape. See an example:1asyncapi:2.0.0-rc12id:urn:com.asyncapi.examples.user3info:4title:Userservice5version:1.6.36channels:7user/signedup:8publish:9message:10payload:11type:object12properties:13fullName:14type:string15email:16type:string17format:emailLooking at the example above, one can rapidly say this is the AsyncAPI definition of a User service, which its API version is 1.6.3 and it publishes to theuser/signedupchannel an event that is an object containing two properties:fullNameandemail.We can define the event payload but its structure is totally free and user-defined. And that's what makes AsyncAPI so powerful! Since our event payload can be anything, it can also be a CloudEvents event.AsyncAPI + CloudEventsLet's see an example of the two combined:1asyncapi:2.0.0-rc12id:urn:com.asyncapi.examples.user3info:4title:Userservice5version:1.6.36channels:7user/signedup:8publish:9message:10payload:11type:object12properties:13specversion:14type:string15enum:['0.2']16type:17type:string18example:com.github.pull.create19source:20type:string21format:uri22example:urn:com.asyncapi.examples.user23id:24type:string25example:'A234-1234-1234'26time:27type:string28format:date-time29example:2018-04-05T17:31:00Z30contenttype:31type:string32example:'application/json'33data:34type:object35properties:36fullName:37type:string38email:39type:string40format:emailLooking at the example above, one can say this is the AsyncAPI definition of a User service, which its API version is 1.6.3 and it publishes to theuser/signedupchannel a CloudEvents event whose data is a JSON object containing two properties:fullNameandemail.Leveraging AsyncAPI Custom Schema FormatsThere's only one concern with the approach above: every single CloudEvents definition is going to be exactly the same from line 11 to 33 — except for the examples that were added in this blog for clarity.The default format for defining events (messages) in AsyncAPI 2.0 is JSON Schema. Thankfully, AsyncAPI provides a way to define events in your own custom format —like Avro and Protobuf — or a hypothetical CloudEvents one in this case. See example:1asyncapi:2.0.0-rc12id:urn:com.asyncapi.examples.user3info:4title:Userservice5version:1.6.36channels:7user/signedup:8publish:9message:10schemaFormat:'application/cloudevents+json; version=0.2; charset=utf-8'11payload:12type:object13properties:14fullName:15type:string16email:17type:string18format:emailThis results in a much shorter and nicer way of defining the usage of CloudEvents inside an AsyncAPI document.Ok, it's possible but, does it makes sense?It really depends on your use case but it makes sense in scenarios where some kind of FaaS is involved. Consider the following example:Reading the diagram from the bottom up, we see an overly simplified diagram of a sign up process. Theuser/signedupevent flows from the REST API to the monitoring service and the FaaS API through the broker. The event could have the CloudEvents format so that both, the FaaS API and the monitoring service, understand it. Obviously, one may argue that the Faas API could be wrapping the event data in CloudEvents format and leave the rest of the events untouched, in plain JSON. Fair.So, does it really makes sense? It certainly does in some situations. Do you have to use AsyncAPI and CloudEvents together? As always that's up to you.You have the tools. Choose them wisely.ConclusionWe've learned how AsyncAPI differs from CloudEvents. Before I finish these lines, I'd like to make something clear again: AsyncAPI focuses on the application and how it is connected; and CloudEvents focuses on the message. Both things are compatible and complementary. Evaluate what are your needs and decide which one suits them better. There's no one-size-fits-all solution.I hope you learned something new, if so, please consider donating to theAsyncAPI Initiative.Until next time!👋
"""
--------------------------------------------------------------------------------


Post 125
ID: https://www.asyncapi.com/blog/status-update-week-17-2019?utm_source=rss
Title: Status update (week 17, 2019)
Link: https://www.asyncapi.com/blog/status-update-week-17-2019?utm_source=rss
Summary: Alas güenas tardis! This week we've made significant progress on the documentation and the parser. The goal is to make AsyncAPI 2.0.0 easy and quick to learn at the same time we provide you the necessary tools to start playing with it.
Content:
"""
Alas güenas tardis! This week we've made significant progress on the documentation and the parser. The goal is to make AsyncAPI 2.0.0 easy and quick to learn at the same time we provide you the necessary tools to start playing with it. Check out the progress so far:The parserCompile for all platforms: One of the hardest things to solve, before we continue moving forward, was the compilation process. We had to make sure we can compile the Go parser to C shared objects for Linux, Mac, and Windows. To make thing easier, we moved the compilation process to Travis CI, so now we don't have to configure our computers for cross-compilation.JSON Schema dereferencing: When we decided to choose Go as our main language for the parser development we knew there were less libraries than in the Node.js universe. One of the missing pieces was a JSON Schema dereferencer, i.e., a library that takes a JSON Schema document and replaces all the appearances of$refwith the value they point to.Rubéncame up with an initial solution and he's now working on polishing it, extracting the code to a separate library so the Go community can benefit from it, and adding support for circular references.The documentationNew Getting Started guide: This week we just launched our new getting started guide for AsyncAPI 2.0.0. The guide targets new users of AsyncAPI and event-driven architectures. Also, if you're coming from OpenAPI (Swagger), don't miss the comparative chart.New blog: Enough with Medium. There's no point on hosting the blog on a service that puts very low limits on how much you can read for free. We'll keep posting there as a distribution channel but the full articles will live in our self-hosted blog, powered byHugo.TalksJoin us tomorrow forAPI days Madridif you're in the city. I'll be talking all things AsyncAPI, past, present, and future. And also having some beers and tapas🍻. Let's connect!DonateAnd last but not least, we’re running a sponsorship campaign. We’ve got different tiers so that everybody can show their love!❤️Donate here. Help Open Source projects.“Victorious warriors win first and then go to war, while defeated warriors go to war first and then seek to win.”
— Sun TzuSee you next week, folks!👋
"""
--------------------------------------------------------------------------------


Post 126
ID: https://www.asyncapi.com/blog/getting-started-with-event-driven-architectures?utm_source=rss
Title: Getting started with event-driven architectures
Link: https://www.asyncapi.com/blog/getting-started-with-event-driven-architectures?utm_source=rss
Summary: All developers, architects, and product managers are used to REST APIs and the synchronous paradigm of communication. You make a request and wait for the response. This is exactly how the web works. Y
Content:
"""
All developers, architects, and product managers are used to REST APIs and the synchronous paradigm of communication. You make a request and wait for the response. This is exactly how the web works. You enter a URL (e.g., google.com) in the address bar of your favorite browser and it sends a request to the server. Following, the server sends the response with the content of the website.The web is the greatest implementation of a REST API.However, there are certain situations when you don't really need a response from the server. At least no other than the confirmation the request has been received. This is also called"fire and forget", and it's really useful when you just want to communicate or inform that "something happened." It is, you're not requesting or asking for anything, thus you don't need a response.  Examples of this are:A user just signed up.You have a new follower.Your fridge is getting empty.Along with the event, you may also want to sendextra information. For instance:A user just signed up: here's the user information (e.g., name, email, age, etc.)You have a new follower: here are the details of the follower (e.g., username, name, picture, etc.)Your fridge is getting empty: here's the percentage of "emptiness" (e.g., 23%)This extra information is often referred to asevent payloadormessage payload.Core conceptsIn most cases, Event-Driven Architectures (EDAs) are broker-centric, like in the diagram above. In it you can find some new concepts, so let's go through them now.Message brokerA message broker (or"broker") is a piece of infrastructure in charge of receiving messages and delivering them to those who have shown interest. They often store messages until they are delivered, what makes EDAs very resilient to failures. Examples of brokers areRabbitMQ,Apache Kafka,Solace, etc.Publisher/SubscriberA publisher (a.k.a.producer) is an application that sends messages to thebroker.A subscriber (a.k.a.consumer) is an application that connects to thebroker, manifests interest in certain type of messages, and leaves the connection open so thebrokercan push messages to them.MessageA message is a piece of information that's sent by the publishers to the broker, and received by all the interested subscribers. The content of the message can be anything but they are frequently catalogued aseventsandcommands. As we saw above,eventscommunicate a fact that occurred. Instead,commandsare very much likerequestsin REST APIs: they tell the subscribers "do this".Technically speaking,eventsandcommandsare the same. The only difference is in their semantics.ChannelsOne detail that might pass unnoticed from the diagram above is the existence ofchannels. All thebrokerssupport communication through multiple channels. The industry doesn't have a common term though so you may find them astopics,routing keys,event types, and probably other ones I'm missing.They're usually assigned a name or identifier (e.g.,user_signed_up) and it's often a good practice to send a single type of message through them. Think about TV or radio channels: the BBC only broadcasts its information through an assigned channel. If the broadcasters (publishers) didn't respect that rule you (the subscriber) would only see and hear interferences.Why "event-driven" and not "message-driven"?You will find both used interchangeably, although they are not exactly the same. You will even find"message-based"and"event-based". In practice, chances are they all refer to the same thing.Theoretically,"message-driven"is the most generic term, meaning you may use events and commands, whileevent-drivenmeans that it's purely about events. However, that's not always the case, as Martin Fowler explains in his talk"the many meanings of event-driven architecture":ConclusionWe've seen what an event-driven architecture is, how it works, and what are their components. AsyncAPI is all about defining and documenting each of these components.Check out ourgetting started guideto learn more.
"""
--------------------------------------------------------------------------------


Post 127
ID: https://www.asyncapi.com/blog/status-update-week-15-2019?utm_source=rss
Title: Status update (week 15, 2019)
Link: https://www.asyncapi.com/blog/status-update-week-15-2019?utm_source=rss
Summary: Kaixo lagunak! This week we continued working on the parser as it’s a top priority for us. We made significant progress and plan to release a simple but functional version soon.

Building the parser
Content:
"""
Kaixo lagunak! This week we continued working on the parser as it’s a top priority for us. We made significant progress and plan to release a simple but functional version soon.Building the parserWe’ve added support for AsyncAPI 1.x/OpenAPI schemas. This is the first step before we dive into Avro and Protobuf support.Updated the Node.js to automatically test itself on Linux, Mac, and Windows. We’re still struggling to debug some failures on Windows so we encourage people who work on this operating system to join and help us test.TalksI’ll be speaking about AsyncAPI and event-driven architectures in a few conferences. Let’s connect!API Days Madrid (April 26):http://apidaysmad.apiaddicts.org/schedule/#session-2Gartner AADI (May 20–21):https://www.gartner.com/en/conferences/emea/applications-ukKubeCon Europe (Barcelona, May 22–23). Not speaking but let’s meet there!REST Fest Europe (Wrocław, May 31):http://2019.restfest.org/eu/scheduleAPI Days Finland (Helsinki, June 4–5):https://www.apidays.fi/DonateAnd last but not least, we’re running a sponsorship campaign. We’ve got different tiers so that everybody can show their love!❤️Donate here. Help Open Source projects.“People who think they know everything are a great annoyance to those of us who do.”
— Isaac Asimov😄See you next week, folks!👋
"""
--------------------------------------------------------------------------------


Post 128
ID: https://www.asyncapi.com/blog/replicating-success-rest-event-driven-architecture?utm_source=rss
Title: Replicating the Success of REST in Event-Driven Architecture
Link: https://www.asyncapi.com/blog/replicating-success-rest-event-driven-architecture?utm_source=rss
Summary: Jonathan explained in his last blog post how the loose coupling of applications associated with event-driven architecture and publish/subscribe messaging is both a strength and a weakness.
Content:
"""
This post is a collaboration betweenFran Méndezof AsyncAPI and Solace’sJonathan Schabowsky. It was originally published atSolace’s blog.Jonathan explained in hislast blog posthow the loose coupling of applications associated with event-driven architecture and publish/subscribe messaging is both a strength and a weakness. As part of that, he touched on the fact that request/reply interactions using RESTful APIs are still the dominant application integration paradigm, even in hybrid cloud, machine learning and IoT use cases that benefit from event-driven interactions. There’s still tons of use cases for which RESTful request/reply interactions are perfect, but it’s important to be able to mix and match the right exchange pattern (Command, Query and Event) for the job especially where event-driven would be best suited.In many cases, exploring why one thing has established or maintained popularity can help you understand why something else isn’t quite as hot, even though it seems like it should be. With this post I’ll investigate why the use of RESTful APIs is still so prevalent, and see if the reasons for its persistent popularity might act as a blueprint for making event-driven popular and mainstream. So, how did REST come to be the most popular way to connect applications? And why does everyone think it’s so easy?How did REST get to be so hot?REST’s popularity arose out of the need for data exchange and interactions between the web browser and backend services. In that context it became a de facto standard because it integrated so well with JavaScript and was so much easier than SOAP (a decent protocol that became bloated and complicated over time). From there, developers started using REST to connect internal enterprise applications, IoT devices and even microservices. It might not have been the best fit for all those use cases, but it got the job done.AsMatt McLartymentions in his blog postOvercoming RESTlessness, a complete examination about why REST started to be used in places that it’s not ideal for “would ignore the power that comes from REST’s universality.” He’s referring to the fact that REST has become universal because developers “get it” and it’s surrounded by a thriving ecosystem of complementary technology and tools. Without this ecosystem that REST inherited from the web world, that universal adoption simply would not have happened.The Building Blocks of REST’s SuccessIf you look closely at this ecosystem (foreshadowing) you can see that it’s composed of some foundational components upon which the open source and vendor community have built what I’ll call “enablement tooling.” Here’s what I mean:Foundational ComponentsWeb serverswere the workhorse of the web for years before REST came into existence. They were much simpler than the application servers of the time and optimized to deal with large numbers of lightweight request/reply communications interactions like serving up a web page that somebody requests.Development frameworkslike Spring, JAX-RS, Restlet and Node.js reflect the fact that people invested time and energy to make the developer experience easy, i.e. keeping them from having to write boilerplate connection code so they could focus on the hard part of developing and refining business logic.Security frameworkslike OAUTH for authentication and authorization, and TLS for encryption, established the means by which interactions and information can be made secure.Enablement ToolingAPI Management: Companies like Apigee and MuleSoft built platforms that provide an API portal so developers can describe and discover APIs in design-time, API gateways to ensure security, management and API mediation, and finally usage analytics which inform which APIs are most and least used. These API management solutions are used increasingly for sophisticated API creation and design, and to act as API marketplaces.Runtime API Discovery: As APIs and applications have become increasingly dynamic and distributed due to continuous delivery, containerization, cloud-bursting, discovery tooling such as Netflix Eureka and Istio/Envoy (service mesh) have been created to reduce the complexity of API clients and enable them to connect to services anywhere.Specification for API Description: OpenAPI was created as a machine-readable metadata specification in order to document, design and consume APIs. This is incredibly valuable for use by testing tools, clients and document generation.Code Generation Tools: Swagger and its associated code generation tooling lets developers easily take an OpenAPI definition and generate either client or server code, drastically reducing the amount of work it takes development teams to use APIs.Without the foundational components, not only would the enablement tooling not have been possible, there wouldn’t have been any need or demand for it. This ecosystem of tools has facilitated REST’s ascension to its position as the de facto standard for application interactions today. While I lament the fact that event-driven hasn’t achieved this same level of adoption and devotion, I understand why, and know that without similar tooling it never will.How Event-Driven is Following in REST’s FootstepsThere is no reason why the event-driven world can’t learn from the RESTful API world by leveraging and developing similar foundational components and enablement tools. In fact, some very exciting initiatives are underway and picking up steam in the industry and within Solace:Foundational ComponentsEvent Brokers: This one is easy as many simple (RabbitMQ, ActiveMQ) and advanced event brokers (Solace PubSub+, Kafka) exist today. Many of them are battle-tested and used widely in organizations that are event-driven.Development Frameworks: Spring Cloud Stream makes writing event-driven microservices easy, and Paho for MQTT makes it easy to create event-driven IoT sensors in many programming languages.Security: Frameworks like OAuth enable authentication and authorization in the event-driven world along with TLS for encryption for confidentiality/integrity.Enablement ToolingEvent Management: Whileadvanced event brokersperform many functions similar to those of an API Gateway, no vendor offers a platform that does everything for events that API management platforms do for RESTful API interactions. There are no “event portals” for developers to use, for example, in order to design, document and discover events.Runtime Event Discovery: In the Eventing world, the ability to deliver events to consumers is even more complicated than with APIs because of the combination of 1-many event distribution, guaranteed and in-order quality of services along with event producers and consumers being just as dynamic and distributed as what is found with APIs. This has challenged infrastructure and operations teams for years all while client applications should not be burdened with these complexities. Theevent meshis an emerging architectural concept that provides similar functionality to theservice meshbut is targeted towards asynchronous interaction patterns. This removes the complexities previously described by enabling producers and consumers to exchange events regardless of where they are physically deployed all while maintaining event delivery qualities of service.API Description Specification:AsyncAPIis on a mission to standardize event-driven API interactions and support the wide variety of messaging systems available. This is a corollary toOpenAPI— a universal language for all the different messaging protocols and event schema formats. The purpose of AsyncAPI is to enable architects and developers to specify the event payload definition, channel name, application/transport headers and protocol– thus fully specifying the application’s event-driven interface. This was previously not available but, thanks to Fran Méndez and the AsyncAPI Initiative, event-driven applications will receive the same love as RESTful APIs.Code Generation Tools: AsyncAPI is also working in this direction. For instance, the ability to take an AsyncAPI definition and generate event-driven applications is underway for Spring Cloud Stream. This will drastically reduce the effort to create new applications!ConclusionEDA’s popularity has started to drastically increase as many companies are realizing they MUST react in real-time to their customers, decouple their systems and transform into event-driven organizations. However, for event-driven interactions to achieve the same level of adoption as REST, the build-out of tooling for eventing must continue. Now is the time to transform and support all the patterns modern applications need for interaction, i.e. commands, queries… and events!Solace is committed to helping organizations realize the advantages of being event-driven. We’re active on all these fronts by continuing to advance the state of the art with our PubSub+ event broker andevent mesh, enthusiastically supportingSpring Cloud Streams, and actively contributing expertise and financial support toAsyncAPI. Stay tuned for more information around how event management and API management are similar, how it is a key capability that organizations need, and what Solace is doing about it!
"""
--------------------------------------------------------------------------------


Post 129
ID: https://www.asyncapi.com/blog/status-update-week-14-2019?utm_source=rss
Title: Status update (week 14, 2019)
Link: https://www.asyncapi.com/blog/status-update-week-14-2019?utm_source=rss
Summary: Hallo meine Freunde! This week we’ve done great progress on tooling and documentation. It will be our main focus for the next month. In the meantime, check out what we did last week. Read on!

Improve
Content:
"""
Hallo meine Freunde! This week we’ve done great progress on tooling and documentation. It will be our main focus for the next month. In the meantime, check out what we did last week. Read on!Improvements on documentationCheck out version 2.0.0 of the specification in our website:https://www.asyncapi.com/docs/specifications/2.0.0/.Added a “Hello world” article to our getting started guide:https://github.com/asyncapi/asyncapi.github.io/pull/3.Added a “Servers” article to our getting started guide, explaining how the “servers” section of AsyncAPI works:https://github.com/asyncapi/asyncapi.github.io/pull/4.Improvements on toolingWe managed to compileour Go parserto Linux, Mac, and Windows C shared objects. This sets the base for an automated building process.As a result of the previous point, we managed to create a Node.js wrapper for the Go parser, making use of the C shared objects.AsyncAPI SIG meetingWe had our bi-weekly SIG meeting this week where we talked about future plans and how to improve onboarding. And it’s now uploaded toour Youtube channel.DonateAnd last but not least, we’re running a sponsorship campaign. We’ve got different tiers so that everybody can show their love!❤️Donate here. Help Open Source projects.“Great things in business are never done by one person. They’re done by a team of people.”
— Steve JobsSee you next week, folks!👋
"""
--------------------------------------------------------------------------------


Post 130
ID: https://www.asyncapi.com/blog/organizing-asyncapi-documents?utm_source=rss
Title: Organizing your AsyncAPI documents
Link: https://www.asyncapi.com/blog/organizing-asyncapi-documents?utm_source=rss
Summary: A recurring question that I get very often is: “how do I organize my AsyncAPI documents?”. Also, the related one: “I have two services, a publisher and a consumer, should I define both in the same Asy
Content:
"""
A recurring question that I get very often is: “how do I organize my AsyncAPI documents?”. Also, the related one: “I have two services, a publisher and a consumer, should I define both in the same AsyncAPI document?”.Let’s break down some best practices and tips to avoid ending up in a hell of unmanageable documents.Organizing MicroservicesI’m using the term microservices here because it’s the most common type of distributed architecture that you can find nowadays.The best practice for organizing AsyncAPI files in your microservices architecture is to have a file per microservice. This way, you end up with multiple independent files that define your application.One publisher and one subscriber, both sharing the UserSignUp message.Microservices are meant to do a single thing and to do it well and, very importantly, they must be independently deployable. However, if you have a publisher and multiple consumers, you quickly end up having something like the following:One publisher and various subscribers. All of them sharing the UserSignUp message.It’s clear there’s a dependency between all of them: theUserSignedUpmessage. If at some point to want to change it, you’ll have to go through all of the files and change it. It’s a tedious task we want to avoid, so we can make use of the$refcapability of AsyncAPI to simplify things:The value of $ref should be “common/messages.json#UserSignedUp”.Now, if you have to add something to theUserSignedUpmessage, it’s just a matter of changing one file. Depending on your setup, you may have to restart your services to get the new definition. However, as simple and straightforward as it may seem, you must take care not to introduce breaking changes in the message definition. Otherwise, you’ll have inconsistent states while some services got the new message definition and some didn’t yet. Here comes the importance of versioning your messages, but that makes for another blog post alone.Common mistakesSince microservices tend to be small in scope, most probably their AsyncAPI document will not be very extensive too. And I found out this is one of the reasons people tend to re-use the same file for many services. They think the file is very small and because the publisher and the subscriber share the same message, why not putting everything there? It’s tempting at first, but the reason why you should avoid doing this is that you lose context and semantics, and it causes problems:If a single document contains publish and subscribe for the same channel (topic), how do you know which one is defining what your application does?Since your document may contain many channels, how do you know if your application is publishing or subscribing to each channel or just a subset of them? That itself causes more problems, for instance, when you want to generate the documentation for a single service but you have a single file defining your whole architecture and thus a single documentation page describing all the services without any clue which one is doing what.An AsyncAPI file is meant to define the behavior of a single application. You can obviously break the rules and use it to define the whole architecture but expect all sorts of problems to appear because you’re using a hammer to saw a piece of wood. The same way you don’t use a single OpenAPI (Swagger) file to define many of your REST APIs, you shouldn’t use a single AsyncAPI document to define many of your message-driven APIs.Organizing Client-ServerSay, for instance, you have a WebSockets API and front-end application using it. The paradigm is very similar to the one we’re used to with HTTP APIs, with the subtle difference that the communication isfull duplex, i.e., the client can send and receive messages over the same channel, at any time.This case is not very different from the microservices one. If you think about it, we can look at it as a small distributed architecture, where you only have two services: the client and the server. So the recommended best practice is to follow the same approach and have one document for each of the applications — one for the server and another for the client or front-end.SummaryI want to reinforce the point that an AsyncAPI file is meant to definethe behavior of a single application. Keep this always in mind, and everything will make sense to you.Happy coding!✌️AsyncAPI is an open source project running on donations sopleaseconsider donating🙌
"""
--------------------------------------------------------------------------------
